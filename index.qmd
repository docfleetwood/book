---
description-meta: |
  This textbook is an introduction to the fundamental concepts and practical programming skills from Data Science that are increasingly employed in a variety of language-centered fields and sub-fields applied to the task of quantitative text analysis. It is geared towards advanced undergraduates, graduate students, and researchers looking to expand their methodological toolbox.
execute: 
  cache: false
---

<!--

Content:

- [ ] Add a further reading section to each chapter!
- [ ] In addition to "Consider this" sections, include "Dive deeper" sections which point readers to more advanced topics.
- [ ] Use ChatGPT for quotes to the beginnings of chapters
- [ ] [plausible](https://plausible.io/) is a privacy-conscious alternative to Google Analytics (paid service, or self-hosted)

Exercises:

- [ ] Change lab names to reflect the task in a more inviting hands-on way. For example, "Dataset manipulation: tokenization and joining datasets" could become "Consumer Reviews of Amazon Products for sentiment analysis".
- [ ] Change recipe and lab numbering to mimic the chapter numbering. That is instead of Preface (Ch. 0) Recipe #1 and Lab #1 --change to Recipe #0 and Lab #0? Then chapter 1 will have Recipe and Lab #1 and so on.
- [ ] (ChatGPT prompt) Write some conceptual questions/ hands-on exercises for a textbook on quantitative text analysis for linguistics using R, specifically for a chapter entitled "understanding data" with the following chapter summary: 

Formatting:
- [x] Change callouts to greyscale (no color)
  - [x] Edit Latex output to include callout icons (used in HTML)
    - Possible solution: https://stackoverflow.com/questions/74647399/define-a-new-callout-in-quarto (Not sure if this will work for PDF output)
  - [x] Change code blocks to greyscale (no color)
- [ ] Change images and figures (plots) to greyscale (no color)
  - [ ] For plots, create a function that will change the default ggplot2 theme to greyscale (no color)
- [ ] Change tables and verbatim wrapping for latex output
- [ ] Add `fig-` and `tbl-` to all figures and tables and connect these to the text. The print book will not necessarily have these elements and the text coordinated in a linear fashion.
- [ ] Change hand-drawn figures to `ggplot2` figures or `mermaid` diagrams.
- [ ] Consider what to do with the hand-drawn visual summaries and the DIKI hierarchy.
  - [ ] Possible solution is draw.io (https://www.draw.io/) or mermaid (https://mermaid-js.github.io/mermaid/#/)
- [ ] Update images to high-res, greyscale, and add alt text (see @fig-summaries-boxplots-belc)
- [ ] Update any mermaid diagrams to greyscale, alt-text, and correct sizing
- [ ] Add indexing to the key terms in the book (can Quarto do HTML indexing?)
- [ ] Fix package info listing --for all packages used in the book.
- [ ] Add a section on how to cite the book.
- [ ] Add citations for data/ datasets used in the book.
- [ ] Add a section on how to report errors in the book.
- [ ] Add appropriate creative commons license for the web book.

 -->

## Welcome {.unnumbered .unlisted}

This textbook is an introduction to the fundamental concepts and practical programming skills from Data Science that are increasingly employed in a variety of language-centered fields and sub-fields applied to the task of quantitative text analysis. It is geared towards advanced undergraduates, graduate students, and researchers looking to expand their methodological toolbox.

::: {.content-visible when-format="html"}
The content is currently under development. Feedback is welcome and can be provided through the [hypothes.is](https://web.hypothes.is/) service. A toolbar interface to this service is located on the right sidebar. To register for a free account and join the "text_as_data" annotation group [follow this link](https://hypothes.is/groups/WkoaXnBX/text-as-data). Suggestions and changes that are incorporated will be [acknowledged](#acknowledgements).
:::

**About the author**

Dr. Jerid Francom is Associate Professor of Spanish and Linguistics at Wake Forest University. His research focuses on the use of large-scale language archives (corpora) from a variety of sources (news, social media, and other internet sources) to better understand the linguistic and cultural similarities and differences between language varieties for both scholarly and pedagogical projects. He has published on topics including the development, annotation, and evaluation of linguistic corpora and analyzed corpora through corpus, psycholinguistic, and computational methodologies. He also has experience working with and teaching statistical programming with R.

## License {.unnumbered}

<a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a><br />This work by [Jerid C. Francom](https://francojc.github.io/) is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.

## Credits {.unnumbered}

<div>
Icons made from <a href="http://www.onlinewebfonts.com/icon">Icon Fonts</a> are licensed by CC-BY-3.0
</div>

## Acknowledgements {#acknowledgements .unnumbered}

TAD has been reviewed by and suggestions and changes incorporated based on the feedback through [the TAD Hypothes.is group](https://hypothes.is/groups/Q3o92MJg/tad) by the following people: Andrea Bowling, Caroline Brady, Declan Golsen, Asya Little, Claudia Valdez, ...

## Build information {.unnumbered}

<!-- This may be a unique textbook compared to others you have seen. It has been created using R itself --specifically using an R package called `bookdown` [@R-bookdown]. This R package makes it possible to write, execute ('run'), and display code and results within the text. The website for this textbook is hosted with [GitHub Pages](https://pages.github.com/) and the complete source is available on [GitHub](https://github.com/lin380). -->

<!-- and automatically updated after every commit by [Travis-CI](https://travis-ci.org).  -->

```{r}
#| label: common
#| include: false
pacman::p_load(tidyverse, rmarkdown, here, knitr, webshot, tadr, tidytext) # default packages

ggplot2::theme_set(ggplot2::theme_minimal()) # set default ggplot2 theme

filter <- dplyr::filter # avoid conflict with `stats` package

options(digits = 3) # default to 3 decimal places

options(knitr.table.format = function() {
  if (knitr::is_latex_output()) {
    "latex"
  } else {
    "pipe"
  }
})
```


This version of the textbook was built with `r sessioninfo::platform_info()[[1]]` on `r sessioninfo::os_name()` with the following packages: 

```{r}
#| label: session-packages
#| echo: false
#| results: asis
#| eval: true
#| cache: false

pkgs <- sessioninfo::package_info(dependencies = FALSE, pkgs = "attached")
df <- tibble::tibble(
  package = pkgs$package,
  version = pkgs$ondiskversion,
  source = gsub("@", "\\\\@", pkgs$source)
)
knitr::kable(df, format = "markdown")
```


```{r}
#| label: bib-packages
#| include: false

# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), "bookdown", "knitr", "rmarkdown", "languageR", "infer", "rvest", "rsyntax", "rtweet", "tidymodels", "textrecipes", "tidytext", "quanteda.corpora"
), "packages.bib")
```

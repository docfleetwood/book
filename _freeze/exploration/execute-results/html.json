{
  "hash": "14ff9851b21f79c12e61e6b9121fb327",
  "result": {
    "markdown": "---\nexecute: \n  echo: true\n  cache: true\n---\n\n\n# Exploration {#sec-exploration}\n\n\n\n\n\n\n\n... Quote ...\n\n::: callout-note\n## Keys\n\n- ...\n:::\n\n\n::: {.cell layout-align=\"center\" hash='exploration_cache/html/exploration-data-packages_26ce8a99ed236a20ed6991b50408c572'}\n\n:::\n\n\nIn this chapter we examine a wide range of strategies for deriving insight from data in cases where the researcher does not start with a preconceived hypothesis or prediction, but rather the researcher aims to uncover patterns and associations from data allowing the data to guide the trajectory of the analysis. The chapter outlines two main branches of exploratory analysis: 1) descriptive analysis which statistically and/or visually summarizes a dataset and 2) unsupervised learning which is a machine learning approach that does not assume any particular relationship between variables in a dataset. Either through unsupervised learning or descriptive methods, exploratory data analysis employs quantitative methods to summarize, reduce, and sort complex datasets and statistically and visually interrogate a dataset in order to provide the researcher novel perspective to be qualitatively assessed.\n\n\nThis chapter provides an introduction to exploratory data analysis (EDA) for linguists, with a focus on descriptive methods such as frequency analysis and co-occurence analysis, as well as unsupervised learning approaches such as clustering, topic modelling, and word embedding. It will also discuss the use cases of these methods in linguistics. \n\nThe chapter is organized as follows: ...\n\nWe wil work with the State of the Union (SOTU) corpus, which contains the full text of all State of the Union addresses from 1790 to 2019. The corpus is available in the `quanteda.corpora` package, and can be loaded as follows:\n\n\n::: {.cell layout-align=\"center\" hash='exploration_cache/html/load-sotu_9589c08733860fdd9793b217ae4275af'}\n\n```{.r .cell-code}\nsotu_corpus <- \n  quanteda.corpora::data_corpus_sotu # load corpus\n```\n:::\n\n\n\n(to be continued/ edited)\n\n::: callout-tip\n## Swirl\n\n**What**: [Unsupervised Learning](https://github.com/lin380/swirl)\\\n**How**: In the R Console pane load `swirl`, run `swirl()`, and follow prompts to select the lesson.\\\n**Why**: To ...\n:::\n\n\n\n- Overview\n  - Research goals (discover, describe, posit)\n  - Use of data\n      - Reusable\n      - No outcome variable (only predictors/ covariates)\n      - Mutable variables/ features\n  - Methods\n      - Descriptive methods\n      - Unsupervised machine learning methods\n  - Data types/ structures\n      - Vectors\n      - Data frames\n      - Matrices\n  - Interpreting results (qualitative\n      - Summary statistics \n      - Visualizations\n- Descriptive analysis\n  - Methods: \n      - Frequency analysis: (L2 acquisition, Language and culture studies)\n          - Word/ term frequency (counting)\n              - Raw frequency (SOTU)\n                  - Zipf's law\n              - Relative frequency (normalization)\n                  - Compare sub-corpora (by 'party')\n          - Adjusted frequency (relevance)\n              - TF-IDF (term frequency-inverse document frequency)\n                  - Distinctive words (remove 'stopwords')\n                  - Compare sub-corpora (by 'party')\n              - Dispersion measures\n                  - ...\n      - Co-occurrence analysis: (grammaticalization, syntactic alternations, discourse analysis, etc.)\n          - Concordance (contextualization)\n              - KWIC (keyword in context)\n          - Collocation (co-occurrence)\n              - Pointwise mutual information\n              - Log-likelihood\n              - Chi-square\n- Unsupervised machine learning analysis\n  - Methods: \n      - Clustering (grouping)\n          - K-means (pre-defined number of clusters)\n          - Hierarchical clustering (dendrogram)\n      - Dimensionality reduction (feature selection)\n          - Principal component analysis (PCA)\n      - Topic modeling (latent semantic analysis)\n          - Latent Dirichlet allocation (LDA)\n      - Vector space modeling (word embeddings, semantic relatedness)\n          - Word2vec (skip-gram)\n          - GloVe (global vectors)\n\n\n\n<!--\n\nIntroduction to Exploratory Data Analysis for Linguists\n\nThis chapter provides an introduction to exploratory data analysis for linguists, with a focus on descriptive methods such as frequency analyses, keyword in context and keyword analyses, as well as unsupervised learning approaches such as clustering, topic modelling, word embedding, and sentiment analyses. It will also discuss the use cases of these methods in linguistics.\n\nOverview\n\nDescriptive Methods\n\nFrequency analyses\nThis section will provide an overview of frequency analyses and discuss the various ways to measure frequency, including absolute and relative frequency, as well as n-grams. It will also discuss the implications of these measures and their use cases in linguistics.\n\nKeyword in context\nThis section will discuss keyword in context (KWIC) analyses, which is used to identify meaningful keywords in a given text. It will discuss various ways to analyse a text and extract keywords, as well as discuss various practical applications of KWIC in linguistics.\n\nKeyword analyses\nThis section will discuss keyword analyses, which are used to identify the most relevant keywords in a given text. It will discuss various methods of keyword analysis, such as frequency-based and semantic-based approaches, and discuss their applications in linguistics.\n\nUnsupervised Learning Approaches\n\nClustering\nThis section will discuss clustering techniques, which are used to partition data into clusters based on similarity. It will discuss various approaches to clustering, such as k-means and hierarchical clustering, as well as discuss their use cases in linguistics.\n\nTopic modelling\nThis section will discuss topic modelling techniques, which are used to identify and group semantically similar topics in unstructured data. It will discuss various approaches to topic modelling, such as Latent Dirichlet Allocation (LDA), and discuss their applications in linguistics.\n\nWord embedding\nThis section will discuss word embedding techniques, which are used to represent words in a vector space. It will discuss various approaches to word embedding, such as Word2Vec and GloVe, and discuss their applications in linguistics.\n\nSentiment analyses\nThis section will discuss sentiment analysis techniques, which are used to identify the polarity (positive or negative) of a given text. It will discuss various approaches to sentiment analysis, such as Naive Bayes and Support Vector Machines (SVM), and discuss their applications in linguistics.\n\nConclusion\n\nUse Cases for Exploratory Data Analysis in Linguistics\n\n\n-->\n\n\n## Activities {.unnumbered}\n\n::: callout-tip\n## Recipe\n\n**What**: [Statistical inference: prep, assess, interrogate, evaluate, and report](https://lin380.github.io/tadr/articles/recipe_9.html)\\\n**How**: Read Recipe 9 and participate in the Hypothes.is online social annotation.\\\n**Why**: To illustrate some common coding strategies for preparing datasets for inferential data analysis, as well as the steps conduct descriptive assessment, statistical interrogation, and evaluation and reporting of results.\n:::\n\n::: callout-tip\n## Lab\n\n**What**: [Statistical inference: prep, assess, interrogate, evaluate, and report](https://github.com/lin380/lab_9)\\\n**How**: Clone, fork, and complete the steps in Lab 9.\\\n**Why**: To gain experience working with coding strategies to prepare, assess, interrogate, evaluate, and report results from an inferential data analysis, practice transforming datasets and visualizing relationships, and implement organizational strategies for organizing and reporting results in a reproducible fashion.\n:::\n\n## Questions {.unnumbered}\n\n::: callout-note\n## Conceptual questions\n\n1. What is exploratory data analysis?\n2. How can exploratory data analysis be used to uncover patterns and associations?\n3. Describe the workflow of exploratory data analysis?\n4. What are the advantages and disadvantages of descriptive analysis?\n5. What are the advantages and disadvantages of unsupervised learning?\n6. What is the difference between supervised and unsupervised learning?\n7. How does exploratory data analysis differ from traditional hypothesis testing?\n\n:::\n\n::: callout-note\n## Technical exercises\n\n1. Write a function in R to conduct a hierarchical cluster analysis on a dataset.\n2. Implement a k-means algorithm in R to identify clusters within a dataset.\n3. Implement a Principal Component Analysis (PCA) algorithm in R to identify patterns and associations within a dataset.\n4. Write a function in R to produce a descriptive summary of a dataset.\n5. Conduct a correlation analysis in R to identify relationships between variables in a dataset.\n6. Load a dataset into R and conduct a frequency analysis on the dataset.\n7. Load a dataset into R and conduct a keyword in context analysis on the dataset.\n8. Load a dataset into R and conduct a keyword analysis on the dataset.\n9. Load a dataset into R and conduct a sentiment analysis on the dataset.\n10. Load a dataset into R and conduct a topic modelling analysis on the dataset.\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
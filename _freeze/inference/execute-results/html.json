{
  "hash": "73588077d1876b736f4724f35ea05f68",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexecute:\n  echo: true\n---\n\n\n# Infer {#sec-inference}\n\n\n\n\n\n\n> People generally see what they look for, and hear what they listen for.\n>\n> --- Harper Lee, To Kill a Mockingbird\n\n::: {.callout}\n**{{< fa regular list-alt >}} Outcomes**\n\n- Identify the research goals of inferential data analysis\n- Describe the workflow for inferential data analysis\n- Indicate the importance of quantifying uncertainty in inferential data analysis\n:::\n\n\n::: {.cell}\n\n:::\n\n\nIn this chapter, we consider approaches to deriving knowledge from information which can be generalized to the population from which the data is sampled. This process is known as statistical inference. The discussion here implements descriptive assessments, statistical tests, and evaluation procedures for a series of contexts which are common in the analysis of corpus-based data. During our treatment of these contexts, we will establish a foundational understanding of the null hypothesis signficance testing (NHST) framework using a simulation-based approach.\n\n::: {.callout}\n**{{< fa terminal >}} Lessons**\n\n**What**: [Advanced Tables](https://github.com/qtalr/lessons) \\\n**How**: In an R console, load `swirl`, run `swirl()`, and follow prompts to select the lesson.\\\n**Why**: To explore how to enhance dataset summaries using the `janitor` package and present them effectively with the `kableExtra` package's advanced formatting options.\n:::\n\n## Orientation {#sec-ida-orientation}\n\nIn contrast to exploratory and predictive analyses, inference is not a data-driven endeavor. Rather, the goal of inferential data analysis (IDA) is to make theoretical claims about the population and assess the extent to which the data supports those claims. This implicates two key methodological restrictions which are not in play in other analysis methods.\n\nFirst, the research question and expected findings are formulated *before* the data is analyzed, in fact strictly speaking this should take place even before data collection. This helps ensure that the data is aligned with the research question and that the data is representative of the population and that the analysis has a targeted focus and does not run the risk of becoming a 'just-so' story[^hark] or a 'significance-finding' mission[^phack] both of which violate the principles of significance testing.\n\n[^hark]: \"Hypothesis After Result is Known\" (HARKing) involves selectively analyzing data, trying different variables or combinations until a significant p-value is obtained, or stopping data collection when a significant result is found [@Kerr1998].\n\n[^phack]: \"p-hacking\" is the practice of running multiple tests until a statistically significant result is found. This practice violates the principles of significance testing [@Head2015].\n\nSecond, the data used in IDA is only used once. That is to say, that the entire dataset is used a single time to statistically interrogate the relationship(s) of interest. In both EDA and PDA the data can be approached multiple times in different ways and the results of the analysis can be used to inform the next steps in the analysis. In IDA, however, the data is used to test a specific hypothesis and the results of the analysis are interpreted in the context of that hypothesis.\n\nThe methodological approach to inferential data analysis (IDA) is the most straightforward of the analysis types covered in this textbook. As the research goal is to test a claim, the steps necessary are fewer than in EDA or PDA, where the exploratory nature of these approaches includes various possible iterations. The workflow for IDA is shown in @tbl-ida-workflow.\n\n<!-- Workflow -->\n\n| Step | Name | Description |\n|:-----|:-----|:------------|\n| 1 | Identify | Identify and map the hypothesis statement to the appropriate response and explanatory variables |\n| 2 | Inspect | Assess the distribution of the variable(s) with the appropriate descriptive statistics and visualizations. |\n| 3 | Interrogate | Apply the appropriate statistical procedure to the dataset. |\n| 4 | Interpret | Review the statistical results and interpret them in the context of the hypothesis. |\n\n: Workflow for inferential data analysis {#tbl-ida-workflow tbl-colwidths=\"[5, 10, 85]\" .striped}\n\nBased on the hypothesis statement, we first identify and operationalize the variables. The response variable whose variation we aim to explain. In most statistical designs, one or more explanatory variables are included in the analysis in an attempt to gauge the extent to which these variables account for the variation in the response variable. For both response and explanatory variables, it is key to confirm that your operationalization of the variables is well-defined and that the data aligns.\n\n<!-- something about unit of analysis and observation in hypothesis statements and the mapping of variables? -->\n\n::: {.callout .halfsize}\n**{{< fa regular lightbulb >}} Consider this**\n\nWhat are the explanatory and/ or response variables in each of these statements? How are these variables operationalized? What key sampling features are necessary for the data to test these hypotheses?\n\n1. There will be statistically significant differences in the kinds of collocations used in English dialects spoken in urban areas compared to those spoken in rural areas.\n2. French L2 learners will make more vocabulary errors in oral production than in written production.\n3. The association strength between Mandarin words and their English translations will be a significant predictor of translation difficulty for novice translators.\n4. The prevalence of gender-specific words in German-speaking communities on distinct online forums will significantly reflect gender roles.\n5. The frequency of function words used by Spanish L2 learners will be a significant predictor of their stage in language acquisition.\n:::\n\nNext, we determine the informational values of the variables. The informational value of each variable will condition how we approach visualization, interrogation, and ultimately interpretation of the results. Note, that some informational types can be converted to other types, specifically higher-order types can be converted to lower-order types. For example, a continuous variable can be converted to a categorical variable, but not vice versa. It is preferable, however, to use the highest informational value of a variable. Simplifying data results in a loss of information --which will result in a loss of information and hence statistical power which may lead to results that obscure meaningful patterns in the data [@Baayen2004].\n\nWith our design in place, we can now inspect the data. This involves assessing the distribution of the variables using descriptive statistics and visualizations. The goal of this step is to confirm the integrity of the data (missing data, anomalies, etc.), identify general patterns in the data, and identify potential outliers. As much as this is a verification step, it also serves to provide a sense of the data and the extent to which the data aligns with the hypothesis. This is particularly true when statistical designs are complex and involve multiple explanatory variables. An appropriate visualization provides context for interpreting the results of the statistical analysis.\n\nInterrogating the data involves applying the appropriate statistical procedure to the dataset. In the Null Hypothesis Significance Testing (NHST) paradigm, this process includes calculating a statistic from the data, comparing it to a null hypothesis distribution, and measuring the evidence against the null hypothesis. The null hypothesis distribution is a distribution of statistic values that we would expect if the null hypothesis were true, *i.e.* that there is no difference or relationship between the explanatory and/ or response variables. By comparing the observed statistic to the null hypothesis distribution, we can determine the likelihood of observing the observed statistic if the null hypothesis were true. This likelihood is known as the p-value. When the p-value is below a pre-determined threshold, typically 0.05, the result is considered statistically significant. This means that the observed statistic is sufficiently different from the null hypothesis distribution that we can reject the null hypothesis.\n\nNow let's consider how to approach interpreting the results from a statistical test.  The p-value provides a probability that the results of our statistical test could be explained by the null hypothesis. When this probability crosses above the threshold of .05, the result is considered statistically significant, otherwise we have a 'null result' (i.e. non-significant).\n\nHowever, this sets up a binary distinction that can be problematic. On the one hand, what is one to do if a test returns a p-value of .051 or something 'marginally significant'? According to standard practice these results would not be statistically significant. On the other hand, if we get a statistically significant result, do we move on --case closed? To address both of these issues, it is important to calculate a confidence interval for the test statistic. The confidence interval is the range of values for our test statistic that we would expect the true statistic value to fall within some level of uncertainty. Again, 95% is the most common level of uncertainty. The upper and lower bounds of this range are called the confidence limits for the test statistic.\n\nUsed in conjunction with p-values, confidence intervals can provide a more nuanced interpretation of the results of a statistical test. For example, if we get a p-value of .051, but the confidence interval is very narrow, we can be more confident that the results are reliable. Conversely, if we get a p-value of .049, but the confidence interval is very wide, we can be less confident that the results are reliable. If our confidence interval contains the null value, then even a significant p-value will require a more nuanced interpretation.\n\nIt is important to underscore that the purpose of IDA is to draw conclusions from a dataset which are generalizable to the population. These conclusions require that there are rigorous measures to ensure that the results of the analysis do not overgeneralize (suggest there is a relationship when there is not one) and balance that with the fact that we don't want to undergeneralize (miss the fact that there is an relationship in the population, but our analysis was not capable of detecting it).\n\n## Analysis {#sec-ida-analysis}\n\n<!-- Goals of this section -->\n\nIn this section, we will discuss the practical application of inferential data analysis. The discussion will be divided into two sections based on the type of response variable: categorical and numeric. We will then explore specific designs for univariate, bivariate, and multivariate tests. We will learn and implement null significance testing using a simulation-based workflow. In contrast to theory-based methods, simulation-based methods tend to be more intuitive, easier to implement, and provide a better conceptual understanding of the statistical designs and analyses [@Morris2019; @Rossman2014a].\n\nThe steps for implementing a simulation-based approach to significance testing are outlined in @tbl-ida-simulation.\n\n<!-- Simulation-based approach -->\n\n| Step | Name | Description |\n|:-----|:-----|:------------|\n| 1 | Specify | Specify the variables of interest and their relationship |\n| 2 | Calculate | Calculate the observed statistic |\n| 3 | Hypothesize | Generate the null hypothesis distribution |\n| 4 | Get p-value | Calculate the p-value |\n| 5 | Get confidence interval | Calculate the confidence interval |\n\n: Simulation-based workflow for significance testing {#tbl-ida-simulation tbl-colwidths=\"[5, 25, 70]\" .striped}\n\n<!-- Setup: packages/ options/ data -->\n\nThe `infer` package [@R-infer] provides a Tidyverse-friendly framework to implement simulation-based methods for statistical inference. Designed to be used in conjunction with the `tidyverse` [@R-tidyverse], `infer` provides a set of functions that can be used to specify the variables of interest, calculate the observed statistic, generate the null hypothesis distribution, calculate the p-value, and calculate the confidence interval.\n\nLet's load the necessary packages we will use in this section, as seen in @exm-ida-setup.\n\n::: {#exm-ida-setup}\n```r\n# Load packages\nlibrary(infer)      # for statistical inference\nlibrary(skimr)      # for descriptive statistics\nlibrary(janitor)    # for cross-tabulation\n```\n\n\n::: {.cell}\n\n:::\n\n:::\n\n### Categorical {#sec-ida-categorical}\n\nHere we demonstrate the application of inferential data analysis (IDA) to categorical response variables. This will include various common statistical designs and analyses. In @tbl-ida-cat-design, we see common design scenarios, the variables involved, and the statistic used in the analysis.\n\n| Scenario | Explanatory variable(s) | Statistical test | `infer` |\n|:---------|:------------------------|:-----------------|:------------|\n| Univariate  | - | Proportion | `prop` |\n| Bivariate | Categorical | Difference in proportions | `diff in props` |\n| Bivariate (>2 levels) | Categorical (3+ levels) | Chi-square | `chisq` |\n| Multivariate  | Categorical or Numeric<br>(2+ variables) | Logistic regression | `fit()` |\n\n: Statistical test designs for categorical response variables {#tbl-ida-cat-design tbl-colwidths=\"[10, 35, 35, 20]\" .striped}\n\nWe will use a derived version of the `dative` dataset from the `languageR` package [@R-languageR]. It contains over 3k observations describing the realization of the recipient clause in English dative constructions. To familiarize ourselves with the dataset, let's consider the data dictionary in @tbl-ida-cat-data-dict.\n\n\n::: {#tbl-ida-cat-data-dict .cell tbl-cap='Data dictionary for the `dative_tbl` dataset.'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> variable </th>\n   <th style=\"text-align:left;\"> name </th>\n   <th style=\"text-align:left;\"> variable_type </th>\n   <th style=\"text-align:left;\"> description </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> realization_of_rcp </td>\n   <td style=\"text-align:left;\"> Realization of RCP </td>\n   <td style=\"text-align:left;\"> categorical </td>\n   <td style=\"text-align:left;\"> The realization of the recipient (NP/ PP) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> modality </td>\n   <td style=\"text-align:left;\"> Modality </td>\n   <td style=\"text-align:left;\"> categorical </td>\n   <td style=\"text-align:left;\"> The modality of the utterance (spoken/ written) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> length_of_rcp </td>\n   <td style=\"text-align:left;\"> Length of RCP </td>\n   <td style=\"text-align:left;\"> numeric </td>\n   <td style=\"text-align:left;\"> The length of the recipient (number of words) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> length_of_thm </td>\n   <td style=\"text-align:left;\"> Length of THM </td>\n   <td style=\"text-align:left;\"> numeric </td>\n   <td style=\"text-align:left;\"> The length of the theme (number of words) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nWe see that this dataset has four variables, two categorical and two numeric. In our demonstrations we are going to use the `realization_of_rcp` as the response variable, the variable whose variation we are investigating.\n\nFor a bit more context, a dative is the phrase which reflects the entity that takes the recipient role in a ditransitive clause. In English, the recipient (dative) can be realized as either a prepositional phrase (PP) as seen in (1) or as a noun phrase (NP) as seen in (2) @exm-ida-cat-dative-examples.\n\n::: {#exm-ida-cat-dative-examples}\nExample utterances:\n\n1. John gave the book [to Mary ~PP~].\n2. John gave [Mary ~NP~] the book.\n:::\n\nTogether these two syntactic options are known as the Dative Alternation [@Bresnan2007].\n\nLet's go ahead and load the dataset, as seen in @exm-ida-cat-read-dative.\n\n::: {#exm-ida-cat-read-dative}\n```r\n# Load datasets\ndative_tbl <-\n  read_csv(\"../data/dative_ida.csv\")\n```\n\n\n\n:::\n\n\n\n\n\n\nIn preparation for statistical analysis, I performed a statistical overview and diagnostics of the dataset. This included checking for missing data, outliers, and anomalies. I also checked the distribution of the variables using descriptive statistics and visualizations, noting that the `length_of_rcp` and `length_of_thm` variables are right-skewed. This is something to keep in mind. The results of this overview and diagnostics are not shown here, but they are important steps in the IDA workflow. In this process, I converted the character variables to factors as most statistical tests require factors. A preview of the dataset is shown in @exm-ida-cat-dative-preview.\n\n::: {#exm-ida-cat-dative-preview}\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 3,263 × 4\n>    realization_of_rcp modality length_of_rcp length_of_thm\n>    <fct>              <fct>            <dbl>         <dbl>\n>  1 NP                 written              1            14\n>  2 NP                 written              2             3\n>  3 NP                 written              1            13\n>  4 NP                 written              1             5\n>  5 NP                 written              2             3\n>  6 NP                 written              2             4\n>  7 NP                 written              2             4\n>  8 NP                 written              1             1\n>  9 NP                 written              1            11\n> 10 NP                 written              1             2\n> # ℹ 3,253 more rows\n```\n\n\n:::\n:::\n\n:::\n\nWe can see that the dataset includes 3263 observations. We will take a closer look a the descriptive statistics for the variables as we prepare for each analysis.\n\n#### Univariate analysis {#sec-ida-cat-univariate}\n\nThe univariate analysis is the simplest statistical design and analysis. It includes only one variable. The goal is to describe the distribution of the levels of the variable. The `realization_of_rcp` variable has two levels: NP and PP. A potential research question for a case like this may aim to test the claim that:\n\n- NP realizations of the recipient clause are the canonical form in English dative constructions, and therefore will be the most frequent realization of the recipient clause.\n\nThis hypothesis can be tested using a **difference in proportion test**. The null hypothesis is that there is no difference in the proportion of NP and PP realizations of the recipient clause. The alternative hypothesis is that NP realizations of the recipient clause are more frequent than PP realizations of the recipient clause.\n\nBefore we get into statistical analysis, it is always a good idea to cross-tabulate or visualize the question, depending on the complexity of the relationship. In @exm-ida-cat-univariate-tbl, we see the code the shows the distribution of the levels of the `realization_of_rcp` variable in a cross-table.\n\n::: {#exm-ida-cat-univariate-tbl}\n\n::: {#tbl-ida-cat-univariate .cell tbl-cap='Distribution of the levels of the `realization_of_rcp` variable.'}\n\n```{.r .cell-code}\n# Cross-tabulation of `realization_of_rcp`\ndative_tbl |>\n  tabyl(realization_of_rcp) |>\n  adorn_pct_formatting(digits = 2) |>\n  kable() |>\n  kable_styling()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> realization_of_rcp </th>\n   <th style=\"text-align:right;\"> n </th>\n   <th style=\"text-align:left;\"> percent </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> NP </td>\n   <td style=\"text-align:right;\"> 2414 </td>\n   <td style=\"text-align:left;\"> 73.98% </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> PP </td>\n   <td style=\"text-align:right;\"> 849 </td>\n   <td style=\"text-align:left;\"> 26.02% </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n:::\n\nFrom @tbl-ida-cat-univariate, we see that the proportion of NP realizations of the recipient clause is higher than the proportion of PP realizations of the recipient clause. However, we cannot conclude that there is a difference in the proportion of NP and PP realizations of the recipient clause. We need to conduct a statistical test to determine if the difference is statistically significant.\n\nTo determine if the distribution of the levels of the `realization_of_rcp` variable is different from what we would expect if the null hypothesis were true, we need to calculate the difference observed in the sample and compare it to the differences observed in many samples where the null hypothesis is true.\n\nFirst, let's calculate the proportion of NP and PP realizations of the recipient clause in the sample. We turn to the `specify()` function from the `infer` package to specify the variable of interest, step 1 in the simulation-based workflow in @tbl-ida-simulation. In this case, we only have the response variable. Furthermore, the argument `success` specifies the level of the response variable that we will use as the 'success'. The term 'success' is used because the `specify()` function was designed for binomial variables where the levels are 'success' and 'failure', as seen in @exm-ida-cat-specify.\n\n::: {#exm-ida-cat-specify}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Specify the variable of interest\ndative_spec <-\n  dative_tbl |>\n  specify(\n    response = realization_of_rcp,\n    success = \"NP\"\n  )\n\n# Preview\ndative_spec\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> Response: realization_of_rcp (factor)\n> # A tibble: 3,263 × 1\n>    realization_of_rcp\n>    <fct>             \n>  1 NP                \n>  2 NP                \n>  3 NP                \n>  4 NP                \n>  5 NP                \n>  6 NP                \n>  7 NP                \n>  8 NP                \n>  9 NP                \n> 10 NP                \n> # ℹ 3,253 more rows\n```\n\n\n:::\n:::\n\n:::\n\nThe `dative_spec` is a data frame with attributes which are used by the `infer` package to maintain information about the statistical design for the analysis. In this case, we only have information about what the response variable is.\n\nStep 2 is to calculate the observed statistic. The `calculate()` function is used to calculate the proportion statistic setting `stat = \"prop\"`, as seen in @exm-ida-cat-calculate.\n\n::: {#exm-ida-cat-calculate}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate the proportion statistic\ndative_obs <-\n  dative_spec |>\n  calculate(stat = \"prop\")\n\n# Preview\ndative_obs\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> Response: realization_of_rcp (factor)\n> # A tibble: 1 × 1\n>    stat\n>   <dbl>\n> 1 0.740\n```\n\n\n:::\n:::\n\n:::\n\nNote, that the observed statistic, proportion, is the same as the proportion we calculated in @tbl-ida-cat-univariate. In such a simple example, the summary statistic and the observed statistic are the same. But this simple example shows how choosing the 'success' level of the response variable is important. If we had chosen the 'PP' level as the 'success' level, then the observed statistic would be the proportion of PP realizations of the recipient clause. There is nothing wrong with choosing the 'PP' level as the 'success' level, but it would change the direction of the observed statistic.\n\nNow that we have the observed statistic, our goal will be to determine if the observed statistic is different from what we would expect if the null hypothesis were true. To do this, we simulate samples where the null hypothesis is true, step 3 in our workflow.\n\nSimulation means that we will randomly sample from the `dative_tbl` data frame many times. We need to determine how the sampling takes place. Since `realization_of_rcp` is a variable with only two levels, the null hypothesis is that both levels are equally likely. In other words, in a null hypothesis world, NP and PP we would expect the proportions to roughly be 50/50.\n\nTo formalize this hypothesis with `infer` we use the `hypothesize()` function and set the null hypothesis to \"point\" and the proportion to 0.5. Then we can `generate()` a number of samples, say 1,000, drawn from our 50/50 world. Finally, the `prop` (proportion) statistic is calculated for each of the 1,000 samples and returned in a data frame, as seen in @exm-ida-cat-null-hypothesis.\n\n::: {#exm-ida-cat-null-hypothesis}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate the null hypothesis distribution\ndative_null <-\n  dative_spec |>\n  hypothesize(null = \"point\", p = 0.5) |>\n  generate(reps = 1000, type = \"draw\") |>\n  calculate(stat = \"prop\")\n\n# Preview\ndative_null\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> Response: realization_of_rcp (factor)\n> Null Hypothesis: point\n> # A tibble: 1,000 × 2\n>    replicate  stat\n>        <int> <dbl>\n>  1         1 0.493\n>  2         2 0.517\n>  3         3 0.485\n>  4         4 0.497\n>  5         5 0.486\n>  6         6 0.508\n>  7         7 0.505\n>  8         8 0.495\n>  9         9 0.499\n> 10        10 0.504\n> # ℹ 990 more rows\n```\n\n\n:::\n:::\n\n:::\n\nThe result of @exm-ida-cat-null-hypothesis is a data frame with as many rows as there are samples. Each row contains the proportion statistic for each sample drawn from the hypothesized distribution that the proportion of NP realizations of the recipient clause is 0.5.\n\nTo appreciate the null hypothesis distribution, we can visualize it using a histogram. The `infer` package provides a convenient `visualize()` function for visualizing distributions, as seen in @exm-ida-cat-null-hypothesis.\n\n::: {#exm-ida-cat-null-hypothesis}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize the null hypothesis distribution\ndative_null |> visualize()\n```\n\n::: {.cell-output-display}\n![Null hypothesis distribution of the proportion of NP realizations of the recipient clause.](inference_files/figure-html/fig-ida-cat-null-hypothesis-1.png){#fig-ida-cat-null-hypothesis width=768}\n:::\n:::\n\n\n\n:::\n\nOn the x-axis is the proportion statistic of NP realizations of the recipient clause that we would expect if the null hypothesis were true. For the 1,000 samples, the proportion statistic ranges from 0.47 to 0.53. Importantly we can appreciate that the most of the proportion statistics are around 0.5, in fact, the mean is 0.5 with a standard deviation of 0.01, which is what we would expect if the null hypothesis were true. But there is variation, as we would also expect.\n\nWhy would we expect variation? Consider the following analogy. If we were to flip a fair coin 10 times, we would expect to get 5 heads and 5 tails. But this doesn't always happen. Sometimes we get 6 heads and 4 tails. Sometimes we get 7 heads and 3 tails, and so on. As the number of flips increases, however, we would expect the proportion of heads to be closer to 0.5, but there would still be variation. The same is true for the null hypothesis distribution. As the number of samples increases, we would expect the proportion of NP realizations of the recipient clause to be closer to 0.5, but there would still be variation. The question is whether the observed statistic we obtained from our data, in @exm-ida-cat-calculate, is within some level of variation that we would expect if the null hypothesis were true.\n\nLet's visualize the observed statistic on the null hypothesis distribution, as seen in @fig-ida-cat-null-hypothesis-obs, to gauge whether the observed statistic is within some level of variation that we would expect if the null hypothesis were true. The `shade_p_value()` function will take the null hypothesis distribution and the observed statistic and shade the sample statistics that fall within the alpha level.\n\n::: {#exm-ida-cat-null-hypothesis-obs}\n```r\ndative_null |>\n  visualize() + # note we are adding a visual layer `+`\n  shade_p_value(\n    obs_stat = dative_obs, # the observed statistic\n    direction = \"greater\" # the direction of the alternative hypothesis\n  )\n```\n\n::: {.cell}\n::: {.cell-output-display}\n![Null hypothesis distribution of the proportion of NP realizations of the recipient clause with the observed statistic.](inference_files/figure-html/fig-ida-cat-null-hypothesis-obs-1.png){#fig-ida-cat-null-hypothesis-obs width=768}\n:::\n:::\n\n:::\n\nJust from a visual inspection, we can see that the observed statistic lies far away from the null distribution, far right of the right tail. No shading appears in this case as the observed statistic is far from the expected variation. This suggests that the observed statistic is not within the level of variation that we would expect if the null hypothesis were true.\n\n::: {.callout .halfsize}\n**{{< fa regular hand-point-up >}} Tip**\n\nThe direction of the alternative hypothesis is important because it determines the p-value range. The \"two-sided\" direction means that we are interested in the proportion being different from 0.5. If we were only interested in the proportion of one outcome being greater than 0.5, then we would use the \"greater\" direction, or \"less\" in the opposite scenario.\n:::\n\nBut we need to quantify this. We need to calculate the probability of observing the observed statistic or a more extreme statistic if the null hypothesis were true. This is called the p-value, and calculating this estimate is step 4 in the workflow. The **p-value** is calculated by counting the number of samples in the null hypothesis distribution that are more extreme than expected within some level of uncertainty. 95% is the most common level of uncertainty, which is called the alpha level. The remain 5% of the distribution is the space where the likelihood that the null hypothesis accounts for the statistic is below This means that if the p-value is less than 0.05, then we reject the null hypothesis. If the p-value is greater than 0.05, then we fail to reject the null hypothesis.\n\nWith `infer` we can calculate the p-value using the `get_p_value()` function. Let's calculate the p-value for our observed statistic, as seen in @exm-ida-cat-p-value.\n\n::: {#exm-ida-cat-p-value}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate the p-value (observed statistic)\ndative_null |>\n  get_p_value(\n    obs_stat = dative_obs, # the observed statistic\n    direction = \"greater\" # the direction of the alternative hypothesis\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 1 × 1\n>   p_value\n>     <dbl>\n> 1       0\n```\n\n\n:::\n:::\n\n:::\n\nThe p-value for our observed statistic is reported as $0$, with a warning that the p-value estimate is contingent on the number of samples we generate in the null distribution. 1,000 is a reasonable number of samples, so we likely have a statistically significant result at the alpha level of 0.05.\n\nThe p-value is one, traditionally very common, estimate of uncertainty. Another estimate of uncertainty is the confidence interval, our 5th and final step. The **confidence interval** is the range of values for our test statistic that we would expect the true statistic value to fall within some level of uncertainty. Again, 95% is the most common level of uncertainty. The upper and lower bounds of this range are called the confidence limits for the test statistic. The confidence interval is calculated by calculating the confidence limits for the test statistic for many samples from the observed data. But instead of generating a null hypothesis distribution, we generate a distribution based on resampling from the observed data. This is called the bootstrap distribution. The **bootstrap distribution** is generated by resampling from the observed data, with replacement, many times. This simulates the process of sampling from the population many times. Each time the test statistic is generated for each sample. The confidence limits are the 2.5th and 97.5th percentiles of the bootstrap distribution. The confidence interval is the range between the confidence limits.\n\nIn @exm-ida-cat-confidence-interval, we see the code for calculating the confidence interval for our observed statistic.\n\n::: {#exm-ida-cat-confidence-interval}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate boostrap distribution\ndative_boot <-\n  dative_spec |>\n  generate(reps = 1000, type = \"bootstrap\") |>\n  calculate(stat = \"prop\")\n\ndative_ci <-\n  dative_boot |>\n  get_confidence_interval(level = 0.95) # 95% confidence interval\n\ndative_ci\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 1 × 2\n>   lower_ci upper_ci\n>      <dbl>    <dbl>\n> 1    0.723    0.755\n```\n\n\n:::\n:::\n\n:::\n\nLet's visualize the confidence interval for our bootstrapped samples, as seen in @exm-ida-cat-confidence-interval-visualize.\n\n::: {#exm-ida-cat-confidence-interval-visualize}\n```r\n# Visualize the bootstrap distribution with the confidence interval\ndative_boot |>\n  visualize() +\n  shade_confidence_interval(\n    dative_ci # the confidence interval\n  )\n```\n\n::: {.cell}\n::: {.cell-output-display}\n![Bootstrap distribution of the proportion of NP realizations of the recipient clause with the confidence interval.](inference_files/figure-html/fig-ida-cat-confidence-interval-visualize-1.png){#fig-ida-cat-confidence-interval-visualize width=768}\n:::\n:::\n\n:::\n\nThe confidence level is the probability that the confidence interval contains the true value. The confidence level is typically set to 0.95 in the social sciences. This means that if the confidence interval contains the null hypothesis value, then we fail to reject the null hypothesis. If the confidence interval does not contain the null hypothesis value, then we reject the null hypothesis.\n\nConfidence intervals are often misinterpreted. Confidence intervals are not the probability that the true value is within the range. The true value is either within the range or not. The confidence interval is the probability that the range contains the true value. This is a subtle but important distinction. Interpreted correctly confidence intervals can enhance our understanding of the uncertainty of our test statistic and reduces the interpretation of p-values (which are based on a relatively arbitrary alpha level) as a binary decision, significant or not significant. Instead, confidence intervals encourage us to think about the uncertainty of our test statistic as a range of values that we would expect the true value to fall within some level of uncertainty.\n\nOur stat is 0.74 and the confidence interval limits are 0.723 and 0.755. The confidence interval does not contain the null hypothesis value of 0.5, which provides supports the evidence from the p-value that the proportion of NP realizations of the recipient clause is greater than 0.5.\n\n#### Bivariate analysis {#sec-ida-cat-bivariate}\n\nThe univarite case is not very interesting or common in statistical inference, but it is a good place to start to understand the simulation-based process and the logic of statistical inference. The bivariate case, on the other hand, is much more common and interesting. The bivariate case includes two variables. The goal is to describe the relationship between the two variables.\n\nUsing the `dative_tbl` dataset, we can imagine making the claim that:\n\n- The proportion of NP and PP realizations of the recipient clause are contingent on the modality.\n\nThis hypothesis can be approached using a **difference in proportions** test, as both variables are binomial (have two levels). The null hypothesis is that there is no difference in the proportion of NP and PP realizations of the recipient clause by modality. The alternative hypothesis is that there is a difference in the proportion of NP and PP realizations of the recipient clause by modality.\n\nWe can cross-tabulate or visualize, but let's cross-tabulate this relationship as it is a basic 2-by-2 contingency table. In @exm-ida-cat-bivariate-tbl, we see the code for the cross-tabulation of the `realization_of_rcp` and `modality` variables.\n\n::: {#exm-ida-cat-bivariate-tbl}\n\n::: {#tbl-ida-cat-bivariate .cell tbl-cap='Contingency table for `realization_of_rcp` and `modality`.'}\n\n```{.r .cell-code}\ndative_tbl |>\n  tabyl(realization_of_rcp, modality) |> # cross-tabulate\n  adorn_totals(c(\"row\", \"col\")) |> # provide row and column totals\n  adorn_percentages(\"col\") |> # add percentages to the columns\n  adorn_pct_formatting(rounding = \"half up\", digits = 0) |> # round the digits\n  adorn_ns() |> # add observation number\n  adorn_title(\"combined\") |> # add a header title\n  kable(booktabs = TRUE) |>  # pretty table)\n  kable_styling()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> realization_of_rcp/modality </th>\n   <th style=\"text-align:left;\"> spoken </th>\n   <th style=\"text-align:left;\"> written </th>\n   <th style=\"text-align:left;\"> Total </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> NP </td>\n   <td style=\"text-align:left;\"> 79% (1,859) </td>\n   <td style=\"text-align:left;\"> 61% (555) </td>\n   <td style=\"text-align:left;\"> 74% (2,414) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> PP </td>\n   <td style=\"text-align:left;\"> 21%   (501) </td>\n   <td style=\"text-align:left;\"> 39% (348) </td>\n   <td style=\"text-align:left;\"> 26%   (849) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Total </td>\n   <td style=\"text-align:left;\"> 100% (2,360) </td>\n   <td style=\"text-align:left;\"> 100% (903) </td>\n   <td style=\"text-align:left;\"> 100% (3,263) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n:::\n\nIn @tbl-ida-cat-bivariate, both the proportions and raw counts adorn the table. We can appreciate that the proportion of NP realizations of the recipient clause is higher in both modalities, as we might expect from our univariate analysis. However, the proportion appears to be different with the spoken modality having a higher proportion of NP realizations of the recipient clause than the written modality. But we cannot conclude that there is a difference in the proportion of NP and PP realizations of the recipient clause by modality. We need to conduct a statistical test to determine if the difference is statistically significant.\n\nTo determine if the distribution of the levels of the `realization_of_rcp` variable by the levels of the `modality` variable is different from what we would expect if the null hypothesis were true, we need to calculate the difference observed in the sample and compare it to the differences observed in many samples where the null hypothesis is true.\n\nThe `infer` package provides a pipeline, steps 1-5, which maintains a consistent workflow for statistical inference. As such, the procedure is very similar to the univarite analysis we performed, with some adjustments. Let's focus on the adjustments. First, our `specify()` call needs to include the relationship between two variables: `realization_of_rcp` and `modality`. The `response` argument is the response variable, which is `realization_of_rcp`. The `explanatory` argument is the explanatory variable, which is `modality`.\n\n::: {.callout .halfsize}\n**{{< fa regular hand-point-up >}} Tip**\n\nThe formula syntax `y ~ x` can be read as 'y' as a function of 'x'.\n:::\n\nThere are two approaches to specifying the relationship between the response and explanatory variables. The first approach is to specify the response variable and the explanatory variable separately as values of the arguments `response` and `explanatory`. The second approach is to specify the response variable and the explanatory variable as a formula using the `~` operator. The formula approach is more flexible and allows for more complex relationships between the response and explanatory variables. In @exm-ida-cat-specify-bivariate, we see the code for the `specify()` call using the formula approach.\n\n::: {#exm-ida-cat-specify-bivariate}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Specify the relationship between the response and explanatory variables\ndative_spec <-\n  dative_tbl |>\n  specify(\n    realization_of_rcp ~ modality,\n    success = \"NP\"\n  )\n\n# Preview\ndative_spec\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> Response: realization_of_rcp (factor)\n> Explanatory: modality (factor)\n> # A tibble: 3,263 × 2\n>    realization_of_rcp modality\n>    <fct>              <fct>   \n>  1 NP                 written \n>  2 NP                 written \n>  3 NP                 written \n>  4 NP                 written \n>  5 NP                 written \n>  6 NP                 written \n>  7 NP                 written \n>  8 NP                 written \n>  9 NP                 written \n> 10 NP                 written \n> # ℹ 3,253 more rows\n```\n\n\n:::\n:::\n\n:::\n\nThe `dative_spec` now contains attributes about the response and explanatory variables encoded into the data frame.\n\nWe now calculate the observed statistic with `calculate()`, as seen in @exm-ida-cat-calculate-bivariate.\n\n::: {#exm-ida-cat-calculate-bivariate}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate the observed statistic\ndative_obs <-\n  dative_spec |>\n  calculate(\n    stat = \"diff in props\",\n    order = c(\"spoken\", \"written\")\n  )\n\n# Preview\ndative_obs\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> Response: realization_of_rcp (factor)\n> Explanatory: modality (factor)\n> # A tibble: 1 × 1\n>    stat\n>   <dbl>\n> 1 0.173\n```\n\n\n:::\n:::\n\n:::\n\nTwo differences are that our statistic is now a difference in proportions and that we are asked to specify the order of the levels of `modality`. The statistic is clear, we are investigating whether the proportion of NP realizations of the recipient clause is different between the spoken and written modalities. The order of the levels of `modality` is important because it determines the direction of the alternative hypothesis, specifically how the statistic is calculated (the order of the subtraction).\n\nSo our observed statistic 0.17 is the proportion of NP realizations of the recipient clause in the spoken modality minus the proportion of NP realizations of the recipient clause in the written modality, so the NP realization appears 17% more in the spoken modality compared to the written modality.\n\nThe question remains, is this difference statistically significant? To answer this question, we generate the null hypothesis distribution and calculate the p-value, as seen in @exm-ida-cat-null-hypothesis-bivariate.\n\n::: {#exm-ida-cat-null-hypothesis-bivariate}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate the null hypothesis distribution\ndative_null <-\n  dative_spec |>\n  hypothesize(null = \"independence\") |>\n  generate(reps = 1000, type = \"permute\") |>\n  calculate(stat = \"diff in props\", order = c(\"spoken\", \"written\"))\n\n# Calculate the p-value\ndative_null |>\n  get_p_value(\n    obs_stat = dative_obs, # the observed statistic\n    direction = \"two-sided\" # the direction of the alternative hypothesis\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 1 × 1\n>   p_value\n>     <dbl>\n> 1       0\n```\n\n\n:::\n:::\n\n:::\n\nNote when generating the null hypothesis distribution, we use the `hypothesize()` function with the `null` argument set to \"independence\". This is because we are interested in the relationship between the response and explanatory variables. The null hypothesis is that there is no relationship between the response and explanatory variables. When generating the samples, we use the permutation approach, which randomly shuffles the response variable values for each sample. This simulates the null hypothesis that there is no relationship between the response and explanatory variables.\n\nThe p-value is reported as $0$. To provide some context, we will generate a confidence interval for our observed statistic using the bootstrap method, as seen in @exm-ida-cat-confidence-interval-bivariate.\n\n::: {#exm-ida-cat-confidence-interval-bivariate}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate boostrap distribution\ndative_boot <-\n  dative_spec |>\n  generate(reps = 1000, type = \"bootstrap\") |>\n  calculate(stat = \"diff in props\", order = c(\"spoken\", \"written\"))\n\n# Calculate the confidence interval\ndative_ci <-\n  dative_boot |>\n  get_confidence_interval(level = 0.95)\n\n# Preview\ndative_ci\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 1 × 2\n>   lower_ci upper_ci\n>      <dbl>    <dbl>\n> 1    0.138    0.208\n```\n\n\n:::\n:::\n\n:::\n\nThe confidence interval does not contain the null hypothesis value of 0 (no difference), which provides evidence that the proportion of NP realizations of the recipient clause is different between the spoken and written modalities.\n\n#### Multivariate Analysis\n\nIn many scenarios, it is common to have multiple explanatory variables that need to be considered. In such cases, logistic regression is a suitable modeling technique. **Logistic regression** allows for the inclusion of both categorical and continuous explanatory variables. The primary objective of using logistic regression is to assess the association between these variables and the response variable. By analyzing this relationship, we can determine how changes in the explanatory variables influence the probability of the outcome occurring.\n\nTo explore this scenario, let's posit that:\n\n- NP and PP realizations of the recipient clause are contingent on modality and word length ratio of the recipient and theme.\n\nThe length ratio gets at the length of the recipient clause relative to the length of the theme clause. This ratio is an operationalization of a phenomenon known as 'Heavy NP' shift. There are many ways to operationalize this phenomenon, but the length ratio is a simple method to approximate the phenomenon. It attempts to capture the idea that the longer the theme clause is relative to the recipient clause, the more likely the recipient clause will be realized as an NP --in other words, when the theme is relatively longer than the recipient, the theme is ordered last in the sentence, and the recipient is ordered first in the sentence and takes the form of an NP (instead of a PP).\n\nFor example,\n\n1. John gave the book [to Mary]. (PP)\n2. John gave [Mary] the large book that I showed you in class yesterday. (NP)\n\nThe hypothesis, then, is that the example in (3) would be less likely than (2) because the theme is relatively longer than the recipient.\n\n3. John gave the book that I showed you in class yesterday [to Mary]. (PP)\n\nLet's consider this variable `length_ratio` and `modality` together as explanatory variables for the realizations of the recipient clause `realization_of_rcp`.\n\nLet's create the `length_ratio` variable by dividing the `length_of_thm` by the `length_of_rcp`. This will give us values larger than 1 when the theme is longer than the recipient. And since we are working with skewed-distributions, let's log-transform the `length_ratio` variable. In @exm-ida-cat-create-length-ratio, we see the code for creating the `length_ratio` variable.\n\n::: {#exm-ida-cat-create-length-ratio}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create the `length_ratio_log` variable\ndative_tbl <-\n  dative_tbl |>\n  mutate(\n    length_ratio_log = log(length_of_thm / length_of_rcp)\n  ) |>\n  select(-length_of_thm, -length_of_rcp)\n\n# Preview\ndative_tbl |> glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> Rows: 3,263\n> Columns: 3\n> $ realization_of_rcp <fct> NP, NP, NP, NP, NP, NP, NP, NP, NP, NP, NP, NP, NP,…\n> $ modality           <fct> written, written, written, written, written, writte…\n> $ length_ratio_log   <dbl> 2.639, 0.405, 2.565, 1.609, 0.405, 0.693, 0.693, 0.…\n```\n\n\n:::\n:::\n\n:::\n\nLet's visualize the relationship between `realization_of_rcp` and `length_ratio_log` separately and then together with `modality`, as seen in @exm-ida-cat-bivariate-vis-length-ratio-log.\n\n::: {#exm-ida-cat-bivariate-vis-length-ratio-log}\n\n::: {#fig-ida-cat-bivariate-length-ratio-log .cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\n# Visualize the proportion of `realization_of_rcp` by `modality`\ndative_tbl |>\n  ggplot(aes(x = realization_of_rcp, fill = modality)) +\n  geom_bar(position = \"fill\") +\n  labs(\n    x = \"Realization of recipient clause\",\n    y = \"Proportion\",\n    fill = \"Modality\"\n  )\n\n# Visualize the relationship between `realization_of_rcp` and `length_ratio_log`\ndative_tbl |>\n  ggplot(aes(x = realization_of_rcp, y = length_ratio_log)) +\n  geom_boxplot() +\n  labs(\n    x = \"Realization of recipient clause\",\n    y = \"Length ratio\"\n  )\n```\n\n::: {.cell-output-display}\n![Realization of recipient clause by modality](inference_files/figure-html/fig-ida-cat-bivariate-length-ratio-log-1.png){#fig-ida-cat-bivariate-length-ratio-log-1 width=384}\n:::\n\n::: {.cell-output-display}\n![Realization of recipient clause by length ratio](inference_files/figure-html/fig-ida-cat-bivariate-length-ratio-log-2.png){#fig-ida-cat-bivariate-length-ratio-log-2 width=384}\n:::\n\nDistribution the variables `modality` and `length_ratio_log` by the levels of the `realization_of_rcp` variable.\n:::\n\n:::\n\nTo understand visualizations in @fig-ida-cat-bivariate-length-ratio-log, remember the null hypothesis is that there is no difference in the proportion of NP and PP realizations of the recipient clause by modality or length ratio. On the flip side, the alternative hypothesis is that there is a difference in the proportion of NP and PP realizations of the recipient clause by modality and length ratio. From the visual inspection, it appears that NP realizations of the recipient clause are more common in the spoken modality and that the NP realizations have a higher overall length ratio (larger theme relative to recipient) than PP realizations of the recipient clause. This suggests that the alternative hypothesis is likely true, but we need to conduct a statistical test to determine if the differences are statistically significant.\n\nLet's calculate the statistics (not statistic) for our logistic regression by specifying the relationship between the response and explanatory variables and then using `fit()` to fit the logistic regression model, as seen in @exm-ida-cat-logistic-regression.\n\n::: {#exm-ida-cat-logistic-regression}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Specify the relationship\ndative_spec <-\n  dative_tbl |>\n  specify(\n    realization_of_rcp ~ modality + length_ratio_log\n  )\n\n# Fit the logistic regression model\ndative_fit <-\n  dative_spec |>\n  fit()\n\n# Preview\ndative_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 3 × 2\n>   term             estimate\n>   <chr>               <dbl>\n> 1 intercept          -0.563\n> 2 modalitywritten     1.01 \n> 3 length_ratio_log   -3.76\n```\n\n\n:::\n:::\n\n:::\n\n\n::: {.callout .halfsize}\n**{{< fa regular hand-point-up >}} Tip**\n\nThe reference level in R is assumed to be the first level alphabetically, unless otherwise specified. We can override this default by using the `fct_relevel()` function from the `forcats` package. The reason we would want to do this is to make the reference level more interpretable. In our case, we would want to make the spoken modality the reference level it allows us to estimate the difference of the proportion of NP realizations of the recipient as a positive value. Remember that in @fig-ida-cat-bivariate-length-ratio-log-1, the proportion of NP realizations of the recipient clause is higher in the spoken modality than in the written modality. If we were to use the written modality as the reference level, the difference would be negative. Not that we couldn't interpret this, but working with positive integers is easier to interpret.\n:::\n\nNote I pointed out statistics, not statistic. In logistic regression models, there the number of statistic reported depends on the number of explanatory variables. If there are two variables there will be at least three terms, one for each variable and the intercept term. If one or more variables are categorical, however, there will be additional terms when the categorical variable has three or more levels.\n\nIn our case, the `modality` variable has two levels, so there are three terms. The first term is the intercept term, which is the log odds of the proportion of NP realizations of the recipient clause in the written modality when the `length_ratio_log` is 1. The second term is the log odds of the proportion of NP realizations of the recipient clause in the spoken modality when the `length_ratio_log` is 1. The third term is the log odds of the proportion of NP realizations of the recipient clause when the `length_ratio_log` is 1 in the written modality. Notably, the spoken modality does not explicitly appear but is implicitly represented the `modalitywritten` term statistic. `modalityspoken`is used as the reference level for the `modality` variable.\n\n\nNow let's generate the null hypothesis distribution and calculate the p-value for each of the terms, as seen in @exm-ida-cat-null-hypothesis-logistic-regression.\n\n::: {#exm-ida-cat-null-hypothesis-logistic-regression}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate the null hypothesis distribution\ndative_null <-\n  dative_spec |>\n  hypothesize(null = \"independence\") |>\n  generate(reps = 1000, type = \"permute\") |>\n  fit()\n\n# Calculate the p-value\ndative_null |>\n  get_p_value(\n    dative_fit, # the observed statistics\n    direction = \"two-sided\" # the direction of the alternative hypothesis\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 3 × 2\n>   term             p_value\n>   <chr>              <dbl>\n> 1 intercept              0\n> 2 length_ratio_log       0\n> 3 modalitywritten        0\n```\n\n\n:::\n:::\n\n:::\n\nIt appears that our main effects, `modality` and `length_ratio_log`, are statistically significant. Let's generate the confidence intervals for each of the terms, as seen in @exm-ida-cat-confidence-interval-logistic-regression.\n\n::: {#exm-ida-cat-confidence-interval-logistic-regression}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate boostrap distribution\ndative_boot <-\n  dative_spec |>\n  generate(reps = 1000, type = \"bootstrap\") |>\n  fit()\n\n# Calculate the confidence interval\ndative_ci <-\n  dative_boot |>\n  get_confidence_interval(\n    point_estimate = dative_fit,\n    level = 0.95\n  )\n\n# Preview\ndative_ci\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 3 × 3\n>   term             lower_ci upper_ci\n>   <chr>               <dbl>    <dbl>\n> 1 intercept          -0.670   -0.453\n> 2 length_ratio_log   -4.14    -3.45 \n> 3 modalitywritten     0.800    1.23\n```\n\n\n:::\n:::\n\n:::\n\nThe confidence intervals for the main effects, `modality` and `length_ratio_log`, do not contain the null hypothesis value of 0, which provides evidence that each of the explanatory variables is related to the proportion of NP realizations of the recipient clause.\n\n::: {.callout .halfsize}\n**{{< fa medal >}} Dive deeper**\n\nSignificance tests are not the only way to evaluate the evidence for the null hypothesis. We can also quantify the effect size of each of the explanatory variables using the odds ratio to calculate the $r$ (correlation coefficient) and $R^2$ (coefficient of determination) values. The `effectsize` package provides a function `logoddsratio_to_r()` to calculate the $r$ and $R^2$ values for logistic regression models.\n\nIt can be important to use these measures to distinguish between statistically significant and practically significant results. A statistically significant result is one that is unlikely to have occurred by chance. A practically significant result is one that has a meaningful effect.\n:::\n\nOur logistic regression model as specified considers the explanatory variables `modality` and `length_ratio_log` independently, controlling for the other explanatory variable. This is an **additive model**, which is what we stated in our hypothesis and represented in the formula `y ~ x1 + x2`.\n\nNot all multivariate relationships are additive. We can also hypothesize an interaction between the explanatory variables. A **interaction** is the effect of one explanatory variable on the response variable is dependent on the other explanatory variable(s). In our case, we could have hypothesized that the effect of the `length_ratio_log` on the proportion of NP realizations of the recipient clause is dependent on the `modality`. We can specify this relationship using the formula approach, as seen in @exm-ida-cat-logistic-regression-interaction.\n\n::: {#exm-ida-cat-logistic-regression-interaction}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Specify the relationship between the response and explanatory variables\ndative_inter_spec <-\n  dative_tbl |>\n  specify(\n    realization_of_rcp ~ modality * length_ratio_log\n  )\n```\n:::\n\n:::\n\nReplacing the `+` with a `*` tells the model to consider the interaction between the explanatory variables. A model with an interaction changes the terms and the estimates. In @exm-ida-cat-logistic-regression-interaction-terms, we see the terms for the logistic regression model with an interaction.\n\n::: {#exm-ida-cat-logistic-regression-interaction-terms}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit the logistic regression model\ndative_inter_fit <-\n  dative_inter_spec |>\n  fit()\n\n# Preview\ndative_inter_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 4 × 2\n>   term                             estimate\n>   <chr>                               <dbl>\n> 1 intercept                          -0.549\n> 2 modalitywritten                     0.958\n> 3 length_ratio_log                   -3.88 \n> 4 modalitywritten:length_ratio_log    0.317\n```\n\n\n:::\n:::\n\n:::\n\n::: {.callout .halfsize}\n**{{< fa regular lightbulb >}} Consider this**\n\nAs an exercise, consider the following research question:\n\n- NP and PP realizations of the recipient clause are contingent on modality and word length ratio of the recipient and theme, and the effect of the length ratio on the proportion of NP realizations of the recipient clause is dependent on the modality.\n\nFollow the simulation-based process to test this hypothesis. What are the results? What are the implications of the results?\n:::\n\nThe additional term `modalitywritten:length_ratio_log` is the interaction term. We also see the log odds estimates have changed for the previous terms. This is because this interaction draws some of the explanatory power from the other terms. Whether or not we run an interaction model depends on our research question. Again, the hypothesis precedes the model. If we hypothesize an interaction, then we should run an interaction model. If we do not, then we should not.\n\n### Numeric {#sec-ida-numeric}\n\nWe now turn our attention to the analysis scenarios where the response variable is numeric. Just as for categorical variables, we can have univariate, bivariate, and multivariate analysis scenarios. The statistical tests for numeric variables are summarized in @tbl-ida-num-design.\n\n| Scenario | Explanatory variable(s) | Statistical test | `infer`\n|:---------|:------------------------|:-----------------|:-----------------|\n| Univariate | - | Mean | `mean` |\n| Bivariate  | Numeric | Correlation | `correlation` |\n| Bivariate | Categorical (2 levels) | Difference in means | `diff in means` |\n| Bivariate | Categorical (3+ levels ) | ANOVA | `f` |\n| Multivariate  | Numeric or Categorical (2+) | Linear regression | `fit()` |\n\n: Statistical test design for numeric response variables {#tbl-ida-num-design tbl-colwidths=\"[10, 35, 35, 20]\" .striped}\n\nThe dataset will will use is drawn from the Switchboard Dialog Act Corpus [@SWDA2008]. This dataset contains over 200k utterances from 1,155 5-minute telephone conversations and includes information about the use of fillers in the conversations. The data dictionary is found in @tbl-ida-num-data-dict.\n\n\n\n::: {#tbl-ida-num-data-dict .cell tbl-cap='Data dictionary for the transformed SWDA dataset'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> variable </th>\n   <th style=\"text-align:left;\"> name </th>\n   <th style=\"text-align:left;\"> variable_type </th>\n   <th style=\"text-align:left;\"> description </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> speaker_id </td>\n   <td style=\"text-align:left;\"> Speaker ID </td>\n   <td style=\"text-align:left;\"> numeric </td>\n   <td style=\"text-align:left;\"> Unique identifier for each speaker </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> age </td>\n   <td style=\"text-align:left;\"> Age </td>\n   <td style=\"text-align:left;\"> numeric </td>\n   <td style=\"text-align:left;\"> Age of the speaker in years </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> sex </td>\n   <td style=\"text-align:left;\"> Sex </td>\n   <td style=\"text-align:left;\"> categorical </td>\n   <td style=\"text-align:left;\"> Gender of the speaker </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> education </td>\n   <td style=\"text-align:left;\"> Education </td>\n   <td style=\"text-align:left;\"> ordinal </td>\n   <td style=\"text-align:left;\"> Level of education attained by the speaker </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fillers_per_100 </td>\n   <td style=\"text-align:left;\"> Fillers per 100 </td>\n   <td style=\"text-align:left;\"> numeric </td>\n   <td style=\"text-align:left;\"> Number of filler words used per 100 utterances </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> total_fillers </td>\n   <td style=\"text-align:left;\"> Total Fillers </td>\n   <td style=\"text-align:left;\"> numeric </td>\n   <td style=\"text-align:left;\"> Total number of filler words used </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> total_utterances </td>\n   <td style=\"text-align:left;\"> Total Utterances </td>\n   <td style=\"text-align:left;\"> numeric </td>\n   <td style=\"text-align:left;\"> Total number of utterances made by the speaker </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nWe see the dataset has seven variables. The `fillers_per_100` will be used as our reponse variable and corresponds to the rate of filler usage per speaker, normalized by the number of utterances. The other variables we will consider as explanatory variables are `age`, `sex`, and `education`, providing us a mix of numeric and categorical variables.\n\nThe context for these analysis demonstrations comes from the socio-linguistic literature on the use of filled pauses. Filled pauses have often been associated with a type of disfluency; speech errors that occur during speech production. However, some authors have argued that filled pauses can act as sociolinguistic markers of socio-demographic characterstics of speakers, such as gender, age, and educational level [@Shriberg1994; @Tottie2011].\n\n\n::: {.cell}\n\n:::\n\n\nReading the dataset and performing some basic diagnostics, a preview of the `fillers_tbl` dataset is seen in @exm-ida-num-dataset .\n\n::: {#exm-ida-num-dataset }\n\n::: {.cell}\n\n```{.r .cell-code}\n# Preview the dataset\nfillers_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 441 × 4\n>      age sex    education         fillers_per_100\n>    <dbl> <fct>  <ord>                       <dbl>\n>  1    38 Female Less Than College            2.14\n>  2    52 Male   More Than College           25.3 \n>  3    29 Female College                      4.13\n>  4    34 Female College                      2.41\n>  5    36 Female College                      3.79\n>  6    27 Female College                      0   \n>  7    53 Female Less Than College            8.33\n>  8    60 Male   Less Than College            1.82\n>  9    28 Female College                      5.22\n> 10    35 Female College                      6.23\n> # ℹ 431 more rows\n```\n\n\n:::\n:::\n\n:::\n\nOur `fillers_tbl` dataset has 441 observations. Again, we will postpone more specific descriptive statistics for treatment in the upcoming scenarios.\n\n#### Univariate analysis\n\nIn hypothesis testing, the analysis of a single variable is directed at determining whether or not the distribution or statistic of the variable differs from some expected distribution or statistic. In the case of a single categorical variable with two levels (as @sec-ida-categorical), we sampled from a binomial distribution by chance. In the case of a single numeric variable, we can sample and compare the observed distribution to a theoretical distribution. When approaching hypothesis testing from a theoretical perspective, it is often necessary to assess how well a numeric variable fits the normal distribution as many statistical tests assume that the data are normally distributed. However, we have adopted the simulation-based approach to hypothesis testing, which does not require that the data fit the normal distribution, or any other distribution for that matter.\n\nThe other approach to analyzing a single numeric variable is to compare an observed statistic to an expected statistic. This approach requires *a priori* knowledge of the expected statistic. For example, imagine we are interested testing the hypothesis that the length of words in a medical corpus tend to be longer than the average length of words in English. We would then calculate the observed mean for the length of words in the medical corpus and then generate a null distribution of means for the length of words in English, as in @exm-ida-num-uni-null-mean.\n\n::: {#exm-ida-num-uni-null-mean}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Observed mean\nobs_mean <-\n  medical_df |>\n  specify(response = word_length) |>\n  calculate(stat = \"mean\")\n\n# Null distribution of means\nnull_mean <-\n  medical_df |>\n  specify(response = word_length) |>\n  hypothesize(null = \"point\", mu = 5) |>\n  generate(reps = 1000, type = \"draw\") |>\n  calculate(stat = \"mean\")\n```\n:::\n\n:::\n\nNote that instead of a `p = ` argument, as was used in the `hypothesize()` step to generate a null distribution of proportions, we use a `mu = ` argument in @exm-ida-num-uni-null-mean to specify the expected mean. The rest of the hypothesis testing workflow is the same as for the null distribution of proportions.\n\n::: {.callout .halfsize}\n**{{< fa medal >}} Dive deeper**\n\nThe mean `mu` is not the only statistic we can specify for a numeric variable. We can also specify the median `med`, or the standard deviation `sigma`.\n:::\n\nIn our case, we do not have *a priori* knowledge of the expected statistic for the `fillers_per_100` variable, so we will not pursue this approach. However, it is useful to take a closer look at the distribution of a numeric variable in order to detect extreme skewing and/ or outliers. This is important because the presence of skewing and outliers can affect the results of statistical tests. We can visualize the distribution of the `fillers_per_100` variable using a histogram and density plot, as seen in @fig-ida-num-uni-hist-dens.\n\n::: {#exm-ida-num-uni-hist-dens}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Histogram-density plot\nfillers_tbl |>\n  ggplot(aes(x = fillers_per_100)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50) +\n  geom_density() +\n  labs(x = \"Fillers per 100 utterances\", y = \"Count\")\n```\n\n::: {.cell-output-display}\n![Histogram and density plot of the `fillers_per_100` variable](inference_files/figure-html/fig-ida-num-uni-hist-dens-1.png){#fig-ida-num-uni-hist-dens width=768}\n:::\n:::\n\n:::\n\nThe distribution of `fillers_per_100` is indeed skewed to the right. We might have predicted this given that we are working with ratio based on count data, perhaps not. In any case, the skewing we observe tends to compress the distribution and may make it difficult to see any patterns. To mitigate this, we can log transform the variable. But we will run into a problem if we have any speakers who do not use any fillers at all as these speakers will have a value of zero, as we can see in @fig-ida-num-uni-hist-dens. The log of zero is undefined. So we need to address this.\n\nEliminating the speakers who do not use any fillers at all is one option. This is quite extreme as we may lose quite a few speakers and it is not clear that removing data in this way will not cause inordinate bias in the results as these speakers may be different in some way from the rest of the speakers. Looking at the speakers with zero fillers in @exm-ida-num-uni-zero-fillers, we can see that there is some potential for bias as the speakers with zero fillers are not evenly distributed across the levels of the `education` and `sex` variables.\n\n::: {#exm-ida-num-uni-zero-fillers}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Cross-tabulation of zero fillers by education and sex\nfillers_tbl |>\n  filter(fillers_per_100 == 0) |>\n  tabyl(education, sex)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n>              education Female Male\n>      More Than College      3   14\n>                College     16   11\n>      Less Than College      2    0\n>  Less Than High School      1    0\n>                Unknown      1    0\n```\n\n\n:::\n:::\n\n:::\n\nAnother approach is to add a small value to the `fillers_per_100` variable, for all speakers. This will allow us to log transform the variable and will likely not have any (or very little) impact on the results. It also allows us to keep these speakers.\n\nAdding values can be done in one of two ways. We can add a small constant value to all speakers, or we can add a small random value to all speakers. The former is easier to implement, but means that we will still have a spike in the distribution at the value of the constant. Since we do not expect that speakers that did not use fillers at all would never do so and that when they do we would not expect them to be at exactly the same rate as other speakers, we can add a small random value to all speakers.\n\nIn R, we can use the `jitter()` function to add a small amount of random noise to the variable. Note, however, this random noise can be positive or negative. When a negative value is added to a zero value, we are still in trouble. So we need to make sure that none of the jitter produces negative values. We can do this by simply taking the absolute value of the jittered variable with the `abs()` function. Let's see how this works in @exm-ida-num-uni-jitter.\n\n::: {#exm-ida-num-uni-jitter}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set seed for reproducibility\nset.seed(1234)\n\n# Add jitter to fillers\nfillers_tbl <-\n  fillers_tbl |>\n  mutate(fillers_per_100_jitter = abs(jitter(fillers_per_100)))\n\nfillers_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 441 × 5\n>      age sex    education         fillers_per_100 fillers_per_100_jitter\n>    <dbl> <fct>  <ord>                       <dbl>                  <dbl>\n>  1    38 Female Less Than College            2.14               2.14    \n>  2    52 Male   More Than College           25.3               25.3     \n>  3    29 Female College                      4.13               4.13    \n>  4    34 Female College                      2.41               2.41    \n>  5    36 Female College                      3.79               3.80    \n>  6    27 Female College                      0                  0.000561\n>  7    53 Female Less Than College            8.33               8.33    \n>  8    60 Male   Less Than College            1.82               1.82    \n>  9    28 Female College                      5.22               5.22    \n> 10    35 Female College                      6.23               6.23    \n> # ℹ 431 more rows\n```\n\n\n:::\n:::\n\n:::\n\n\nThe results from @exm-ida-num-uni-jitter show that the `fillers_per_100_jitter` variable has been added to the `fillers_tbl` dataset and that zero values for `fillers_per_100` now have a small amount of random noise added to them. Note, that the other values also have a small amount of random noise added to them, but it is so small that rounding to 2 decimal places makes it look like nothing has changed.\n\nNow let's return to log transforming the `fillers_per_100_jitter` variable. We can do this with the `log()` function. Let's see how this works in @exm-ida-num-uni-log.\n\n::: {#exm-ida-num-uni-log}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Log transform fillers (with jitter)\nfillers_tbl <-\n  fillers_tbl |>\n  mutate(fillers_per_100_log = log(fillers_per_100_jitter))\n\nfillers_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 441 × 6\n>      age sex    education         fillers_per_100 fillers_per_100_jitter\n>    <dbl> <fct>  <ord>                       <dbl>                  <dbl>\n>  1    38 Female Less Than College            2.14               2.14    \n>  2    52 Male   More Than College           25.3               25.3     \n>  3    29 Female College                      4.13               4.13    \n>  4    34 Female College                      2.41               2.41    \n>  5    36 Female College                      3.79               3.80    \n>  6    27 Female College                      0                  0.000561\n>  7    53 Female Less Than College            8.33               8.33    \n>  8    60 Male   Less Than College            1.82               1.82    \n>  9    28 Female College                      5.22               5.22    \n> 10    35 Female College                      6.23               6.23    \n> # ℹ 431 more rows\n> # ℹ 1 more variable: fillers_per_100_log <dbl>\n```\n\n\n:::\n:::\n\n:::\n\nLet's now plot the log-transformed variable, as seen in @exm-ida-num-uni-log-plot.\n\n::: {#exm-ida-num-uni-log-plot}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Histogram-density plot\nfillers_tbl |>\n  ggplot(aes(x = fillers_per_100_log)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 50) +\n  geom_density() +\n  labs(x = \"Fillers per 100 utterances\", y = \"Count\")\n```\n\n::: {.cell-output-display}\n![Histogram and density plot of the `fillers_per_100_log` variable](inference_files/figure-html/fig-ida-num-uni-hist-dens-log-1.png){#fig-ida-num-uni-hist-dens-log width=768}\n:::\n:::\n\n:::\n\nThe distribution of the log-transformed variable is more spread out now, but the zero-filler speakers do show a low-level spike in the left tail of the distribution. Jitter and log-transformation, however, smooth over their effect to a large degree.\n\n\n::: {.cell}\n\n:::\n\n\n#### Bivariate analysis\n\nWhen considering a numeric reponses variable and another variable, it is key to consider the nature of the other variable. If it is a categorical variable with two levels, then we can compare a statistic between the two groups (mean or median). If it is categorical with more than two levels, the F statistic is used to compare the means. Finally, if it is a numeric variable, then we can use a correlation test to see if there is an association between the two variables.\n\nThe `fillers_tbl` contains the `sex` variable which is a categorical variable with two levels. According to the literature, filled pauses are associated with differences between men and women [@Shriberg1994; @Tottie2011, @Tottie2014]. Sex is one of the variables associated with the rate of filled pauses. The findings suggest that men use fillers at a higher rate than women. Let's test to see if this holds for the SWDA data.\n\nLet's first explore the distribution from a descriptive point of view. With a numeric response variable `fillers_per_100_log` and a categorical explanatory variable `sex`, a boxplot is a natural fit, as seen in @exm-ida-num-bi-vis.\n\n::: {#exm-ida-num-bi-vis}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Boxplot\nfillers_tbl |>\n  ggplot(aes(x = fillers_per_100_log, y = sex)) +\n  geom_boxplot(notch = TRUE) +\n  labs(\n    x = \"Filler use (log)\",\n    y = \"Sex\"\n  )\n```\n\n::: {.cell-output-display}\n![Boxplot of the `fillers_per_100_log` variable by `sex`](inference_files/figure-html/fig-ida-num-bi-vis-1.png){#fig-ida-num-bi-vis width=768}\n:::\n:::\n\n:::\n\nLooking at the boxplot in @fig-ida-num-bi-vis, we see that the appears to be an overall higher rate of filler use for men, compared to women. We also can see that the random noise added to zero-rate speakers appear as outliers in the left tail. Since I added a notch to the boxplots, we can also gauge to some degree the uncertainty of the median. The notches do not overlap, which suggests that the medians are different.\n\nTo test this differences, let's follow the simulation-based hypothesis testing workflow and investigate if the apparent difference between men and women is statistically significant, or expected by chance[^medians]. The first steps are found in @exm-ida-num-bi-sex-null.\n\n[^medians]: Given the fact that we added jitter to accommodate the zeros, it may actually make more sense to compare medians, rather than means. But to compare these results with the results from the literature, we will compare means.\n\n::: {#exm-ida-num-bi-sex-null}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Specify the relationship\nfillers_spec <-\n  fillers_tbl |>\n  specify(fillers_per_100_log ~ sex) # response ~ explanatory\n\n# Observed statistic\nfillers_obs <-\n  fillers_spec |>\n  # diff in means, Male - Female\n  calculate(stat = \"diff in means\", order = c(\"Male\", \"Female\"))\n\n# Null distribution\nfillers_null <-\n  fillers_spec |>\n  hypothesize(null = \"independence\") |> # independence = no relationship\n  generate(reps = 1000, type = \"permute\") |> # permute = shuffle\n  calculate(stat = \"diff in means\", order = c(\"Male\", \"Female\"))\n\n# Calculate the p-value\nfillers_null |>\n  get_p_value(obs_stat = fillers_obs, direction = \"two-sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 1 × 1\n>   p_value\n>     <dbl>\n> 1   0.066\n```\n\n\n:::\n:::\n\n:::\n\nFrom the analysis performed in @exm-ida-num-bi-sex-null, we can reject the null hypothesis that there is no difference between the rate of filler use between men and women, as the p-value is less than 0.05.\n\nTo further assess the uncertainty of the observed statistic, and the robustness of the difference, we calculate a confidence interval, as seen in @exm-ida-num-bi-sex-ci.\n\n::: {#exm-ida-num-bi-sex-ci}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Resampling distribution\nfillers_boot <-\n  fillers_spec |>\n  generate(reps = 1000, type = \"bootstrap\") |>\n  calculate(stat = \"diff in means\", order = c(\"Male\", \"Female\"))\n\n# Calculate the confidence interval\nfillers_ci <-\n  fillers_boot |>\n  get_ci(level = 0.95)\n\nfillers_ci\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 1 × 2\n>   lower_ci upper_ci\n>      <dbl>    <dbl>\n> 1 -0.00378     1.05\n```\n\n\n:::\n:::\n\n:::\n\nThe confidence interval includes 0, which suggests that the observed difference is questionable. It is of note, however, that the majority of the interval is above 0, which provides some evidence that the observed difference is not due to chance. This result highlights how p-values and confidence intervals together can provide a more nuanced picture of the data.\n\nThe second bivariate scenario we can consider is when the explanatory variable is categorical with more than two levels. In this case, we can use the F statistic to compare the means of the different levels. The `education` variable in the `fillers_tbl` dataset is a categorical variable with five levels. @Tottie2011 suggests that more educated speakers use more fillers than less educated speakers. Let's test this hypothesis.\n\nFirst, we visualize the distribution of the `fillers_per_100_log` variable by `education`, as seen in @exm-ida-num-bi-edu-vis.\n\n::: {#exm-ida-num-bi-edu-vis}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Boxplot\nfillers_tbl |>\n  ggplot(aes(y = fillers_per_100_log, x = education)) +\n  geom_boxplot(notch = TRUE) +\n  labs(\n    y = \"Filler use (log)\",\n    x = \"Education\"\n  )\n```\n\n::: {.cell-output-display}\n![Visualizations of the `fillers_per_100_log` variable by `education`](inference_files/figure-html/fig-ida-num-bi-edu-vis-1.png){#fig-ida-num-bi-edu-vis width=384}\n:::\n:::\n\n:::\n\nThe boxplot in @fig-ida-num-bi-edu-vis does not point to any obvious differences between the levels of the `education` variable. There are a fair number of outliers, however, in the two most educated groups. These outliers are likely due to the random noise added to the 0-rate speakers and it is interesting that they are concentrated in the two most educated groups.\n\nLet's now submit these variables to the simulation-based hypothesis testing workflow to quantify the uncertainty of the observed statistic and determine if the observed difference is statistically significant. The first steps are found in @exm-ida-num-bi-edu.\n\n::: {#exm-ida-num-bi-edu}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Specify the relationship\nfillers_spec <-\n  fillers_tbl |>\n  specify(fillers_per_100_log ~ education) # response ~ explanatory\n\n# Observed statistic\nfillers_obs <-\n  fillers_spec |>\n  calculate(stat = \"F\") # F = variance between groups / variance within groups\n\n# Null distribution\nfillers_null <-\n  fillers_spec |>\n  hypothesize(null = \"independence\") |> # independence = no relationship\n  generate(reps = 1000, type = \"permute\") |> # permute = shuffle\n  calculate(stat = \"F\")\n\n# Calculate the p-value\nfillers_null |>\n  get_p_value(obs_stat = fillers_obs, direction = \"two-sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 1 × 1\n>   p_value\n>     <dbl>\n> 1   0.426\n```\n\n\n:::\n:::\n\n:::\n\nThe analysis in @exm-ida-num-bi-edu suggests that the observed difference between the means of the different levels of the `education` variable not significantly different from what we would expect by chance.\n\n::: {.callout}\n**{{< fa exclamation-triangle >}} Warning**\n\nThe p-value in @exm-ida-num-bi-edu was calculated using a two-sided test, which is appropriate when the expected directionality is not known. In this case, while we do have an expected directionality, the visualizations strongly suggest that the observed difference is not in line with our expectations. To account for this uncertainty and to be conservative, we choose to use a two-sided test. This allows us to remain open to the possibility that the observed difference may actually be in the opposite direction, rather than solely focusing on our initial expectation. However, it's important to note that the decision to use a two-sided test should also consider factors such as the specific research question and the context of the analysis.\n:::\n\nLet's now calculate a confidence interval to assess the uncertainty of the observed statistic, as seen in @exm-ida-num-bi-edu-ci.\n\n::: {#exm-ida-num-bi-edu-ci}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Resampling distribution\nfillers_boot <-\n  fillers_spec |>\n  generate(reps = 1000, type = \"bootstrap\") |>\n  calculate(stat = \"F\")\n\n# Calculate the confidence interval\nfillers_ci <-\n  fillers_boot |>\n  get_ci(level = 0.95)\n\nfillers_ci\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 1 × 2\n>   lower_ci upper_ci\n>      <dbl>    <dbl>\n> 1    0.123     4.57\n```\n\n\n:::\n:::\n\n:::\n\nIn @exm-ida-num-bi-edu-ci, we see that we are in the opposite situation to the previous bivariate case --the p-value is not significant and but the confidence interval does not include 0.\n\nSo how do we interpret this? Remember, the p-value is the probability of observing a statistic as extreme or more extreme than the observed statistic, given that the null hypothesis is true. The confidence interval is the range of values that we are 95% confident contains the true population parameter. We should take into consideration two aspects: (1) the confidence interval has a large range (the interval is wide) and (2) that the lower limit is near 0. Take together and in addition to the p-value, we can conclude that the observed difference is not statistically significant, and if there is a difference, it is likely to be small or negligible.\n\n#### Multivariate analysis\n\n\n\n\n\nWhile bivariate analysis is useful for exploring the relationship between two variables, it is often the case that we want to consider relationships between more than two variables. In this case, we can use multivariate analysis. Linear regression is a common multivariate analysis technique.\n\nIn linear regression, we are interested in predicting the value of a numeric response variable based on the values of the explanatory variables. The contribution of the explanatory variables can be considered individually, as an interaction, or as a combination of both.\n\nLet's now introduce a variation of the SWDA dataset which includes a variable `filler_type` which has two levels, 'uh' and 'um', corresponding to the use of each filler. Here's a preview of the dataset in @exm-ida-num-fillers-type-dataset.\n\n::: {#exm-ida-num-fillers-type-dataset}\n\n::: {.cell}\n\n```{.r .cell-code}\nfillers_type_df\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 882 × 6\n>    speaker_id sex    education           age filler_type fillers_per_100_log\n>         <dbl> <fct>  <ord>             <dbl> <chr>                     <dbl>\n>  1       1000 Female Less Than College    38 uh                        0.561\n>  2       1000 Female Less Than College    38 um                       -0.941\n>  3       1001 Male   More Than College    52 uh                        3.22 \n>  4       1001 Male   More Than College    52 um                       -1.64 \n>  5       1002 Female College              29 uh                        0.956\n>  6       1002 Female College              29 um                        0.425\n>  7       1004 Female College              34 uh                        0.474\n>  8       1004 Female College              34 um                       -0.220\n>  9       1005 Female College              36 uh                        1.17 \n> 10       1005 Female College              36 um                       -0.582\n> # ℹ 872 more rows\n```\n\n\n:::\n:::\n\n:::\n\nThe `fillers_type_df` dataset has 882 observations and 6 variables.  With this dataset, we will explore the hypothesis that the rate of filler use varies by the type of filler across the socio-demographic variable `sex`.\n\nTo do this we will use R formula syntax to specify the variables we want to include in the model and their relationships. The possible relationships appear in @tbl-ida-num-multi-relationships.\n\n| Relationship | Formula | Description |\n|:-------------|:--------|:------------|\n| Simple effects | `response ~ explanatory_1 + explanatory_2` | The response variable as a function of each explanatory variable |\n| Interaction effects | `response ~ explanatory_1:explanatory_2` | The response variable as a function of the interaction between the two explanatory variables |\n| Simple and interaction effects | `response ~ explanatory_1 * explanatory_2` | The response variable as a function of each explanatory variable and the interaction between the two explanatory variables |\n\n: Possible relationships in a multivariate analysis {#tbl-ida-num-multi-relationships tbl-colwidths=\"[25, 25, 50]\"}\n\nOur hypothesis is that men and women differ in the rates that they use the filler types. This describes an interaction, so we can use either the interaction or the simple and interaction effects relationships. To demonstrate the difference between simple and interaction terms, let's approach this using the third relationship (*i.e.* `fillers_per_100_log ~ filler_type * sex`).\n\nA plot will help us begin to understand the potential relationships. In @exm-ida-multi-sex-plot, we use a boxplot to visualize the relationship between the `fillers_per_100_log` variable and the `filler_type` variable, with a `sex` overlay.\n\n::: {#exm-ida-multi-sex-plot}\n\n::: {#fig-ida-multi-sex-plot .cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\n# Boxplot `filler_type`\nfillers_type_df |>\n  ggplot(aes(y = fillers_per_100_log, x = filler_type)) +\n  geom_boxplot(notch = TRUE) +\n  labs(\n    x = \"Filler type\",\n    y = \"Fillers per 100 (log)\"\n  )\n\n# Boxplot `filler_type` and `sex`\nfillers_type_df |>\n  ggplot(aes(y = fillers_per_100_log, x = filler_type, fill = sex)) +\n  geom_boxplot(notch = TRUE) +\n  labs(\n    x = \"Filler type\",\n    y = \"Fillers per 100 (log)\",\n    fill = \"Sex\"\n  )\n```\n\n::: {.cell-output-display}\n![Boxplot by `filler_type`](inference_files/figure-html/fig-ida-multi-sex-plot-1.png){#fig-ida-multi-sex-plot-1 width=384}\n:::\n\n::: {.cell-output-display}\n![Boxplot by `filler_type` and `sex`](inference_files/figure-html/fig-ida-multi-sex-plot-2.png){#fig-ida-multi-sex-plot-2 width=384}\n:::\n\nBoxplot of the `fillers_per_100_log` variable by `filler_type` and `sex`\n:::\n\n:::\n\n\nLet's interpret the boxplots in @fig-ida-multi-sex-plot. Focusing on @fig-ida-multi-sex-plot-1 first, we see that the filler 'uh' is more frequent than 'um' as the median is distinct and the confidence intervals do not overlap. Now, looking at @fig-ida-multi-sex-plot-2, we see the same distinction between 'uh' and 'um', but we also see that the difference between the use of 'uh' and 'um' is different for males and females. This is the interaction effect we hypothesized. In this case the interaction effect goes in the same direction but the magnitude of the difference is different. The upshot, men and women both use 'uh' more than 'um' but men are even more likely to use 'uh' over 'um' than women.\n\nLet's test this effect using the `infer` workflow. Calculating the observed statistics for the simple and interaction effects is very similar to other designs, except instead of `calculate()` to derive our statistics we will use the `fit()` function, just as we did for logistic regression. Let's go ahead calculate the observed statistics first, as seen in @exm-ida-num-multi-spec.\n\n::: {#exm-ida-num-multi-spec}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Specify the relationship\nfillers_type_spec <-\n  fillers_type_df |>\n  specify(fillers_per_100_log ~ filler_type * sex)\n\n# Observed statistics\nfillers_type_obs <-\n  fillers_type_spec |>\n  fit()\n\nfillers_type_obs\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 4 × 2\n>   term                  estimate\n>   <chr>                    <dbl>\n> 1 intercept                0.551\n> 2 filler_typeum           -2.16 \n> 3 sexMale                  0.657\n> 4 filler_typeum:sexMale   -1.84\n```\n\n\n:::\n:::\n\n:::\n\nThe terms in the output from @exm-ida-num-multi-spec provide information as to what the reference levels are. For example, `filler_typeum` tells us that the 'uh' level is the reference for `filler_type` and by the same logic, 'Female' is the reference for `sex`. These terms provide our simple effect statistics. Each can be understood as the difference between the reference level when the other variables are held constant. Our response variable is log transformed, so it is not directly interpretable beyond the fact that smaller units are lower rates of filler use and larger units are higher rates of filler use. So 'um' is used less than 'uh' and men use more fillers than women.\n\nThe interaction term `fillertypeum:sexMale` is the difference in the rate of fillers for this combination compared to the reference level combination ('uh' and 'Female'). In this case, the observed rate is lower.\n\nWe now need to generate a null distribution to compare the observed statistics to. We will again use the permutation method, but since there is an interaction effect, we need to shuffle the `filler_type` and `sex` variables together. This ensures that any relationship between the two variables is removed. Let's see how this works in @exm-ida-num-multi-null.\n\n::: {#exm-ida-num-multi-null}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Null distribution\nfillers_type_null <-\n  fillers_type_spec |>\n  hypothesize(null = \"independence\") |>\n  generate(reps = 1000, type = \"permute\", variables = c(\"filler_type\", \"sex\")) |>\n  fit()\n\n# Calculate the p-values\nfillers_type_null |>\n  get_p_value(obs_stat = fillers_type_obs, direction = \"two-sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 4 × 2\n>   term                  p_value\n>   <chr>                   <dbl>\n> 1 filler_typeum           0    \n> 2 filler_typeum:sexMale   0    \n> 3 intercept               0    \n> 4 sexMale                 0.066\n```\n\n\n:::\n:::\n\n:::\n\nFor the simple effects, we see that `filler_type` is significant but `sex` is not. Remember, when we only considered `sex` in isolation in the bivariate case, we found it to be significant. So why is it not significant now? It is important to remember that in every statistical design, there are other factors that are not considered. When these are not in the model, our effects may appear to account for more of the variance than they actually do. In this case, the `filler_type` variable is accounting for some of the variance that `sex` was accounting for in the bivariate case, enough, it appears, to make `sex` not significant as a simple effect.\n\nOur interaction effect is also significant meaning the observed difference we visualized in @fig-ida-multi-sex-plot is likely not due to chance. The upshot, both men and women use more 'uh' compared to 'um' but mens' difference in use is larger than womens'.\n\nAs always, let's calculate a confidence interval to assess the uncertainty of the observed statistic, as seen in @exm-ida-num-multi-sex-ci.\n\n::: {#exm-ida-num-multi-sex-ci}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Resampling distribution\nfillers_type_boot <-\n  fillers_type_spec |>\n  generate(reps = 1000, type = \"bootstrap\") |>\n  fit()\n\n# Calculate the confidence intervals\nfillers_type_ci <-\n  fillers_type_boot |>\n  get_ci(level = 0.95, point_estimate = fillers_type_obs)\n\nfillers_type_ci\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n> # A tibble: 4 × 3\n>   term                  lower_ci upper_ci\n>   <chr>                    <dbl>    <dbl>\n> 1 filler_typeum          -2.75     -1.54 \n> 2 filler_typeum:sexMale  -2.68     -0.934\n> 3 intercept               0.168     0.909\n> 4 sexMale                 0.0947    1.22\n```\n\n\n:::\n:::\n\n:::\n\nFrom the confidence intervals, we see that zero is not included in any of the intervals, which suggests that the observed differences are not due to chance. Interpreting the width and the proximity to zero, however, suggests that the observed differences for `filler_type` are stronger than for `sex`, which did not result in a significant simple effect. The interaction effect is also significant, but the confidence interval is quite wide and approximates zero. This should raise some questions about the robustness of the observed effect.\n\n## Activities {.unnumbered}\n\nThe following activities aim to reinforce the concepts covered in this chapter. You'll review working with key variables, examine data distributions, and employ simulation-based statistical methods using the `infer` package to test hypotheses about their relationships.\n\n::: {.callout}\n**{{< fa regular file-code >}} Recipe**\n\n**What**: [Building inference models](https://qtalr.github.io/qtalrkit/articles/recipe-10.html)\\\n**How**: Read Recipe 10, complete comprehension check, and prepare for Lab 10.\\\n**Why**: To review and extend your knowledge regarding the simulation-based approach to statistical inference.\n:::\n\n::: {.callout}\n**{{< fa flask >}} Lab**\n\n**What**: [Statistical inference](https://github.com/qtalr/lab-10)\\\n**How**: Clone, fork, and complete the steps in Lab 10.\\\n**Why**: To apply the concepts covered in this chapter to a real-world dataset.\n:::\n\n## Summary {.unnumbered}\n\nIn sum, in this section we explored the process of null hypothesis testing using the `infer` package, which is a simulation-based approach to statistical inference. We considered statistical designs, such as univariate, bivariate, and multivariate analyses, and explored the process of hypothesis testing with categorical and numeric responses variables. The workflow provided demonstrates that the `infer` package is a powerful tool for conducting statistical inference, and that it can be used to test a wide range of hypotheses with a similar workflow.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Quantitative Text Analysis for Linguistics - 5&nbsp; Acquire data</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./curate-datasets.html" rel="next">
<link href="./preparation.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script src="site_libs/quarto-contrib/kbd/kbd.js"></script>
<link href="site_libs/quarto-contrib/kbd/kbd.css" rel="stylesheet"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script async="" src="https://hypothes.is/embed.js"></script><link rel="stylesheet" href="assets/css/style.css">
</head>
<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./preparation.html">Preparation</a></li><li class="breadcrumb-item"><a href="./acquire-data.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Acquire data</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Quantitative Text Analysis for Linguistics</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com" rel="" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./orientation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Orientation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./text-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Text analysis in context</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./understanding-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Understanding data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./approaching-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Approaching analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./framing-research.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Framing research</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./preparation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preparation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./acquire-data.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Acquire data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./curate-datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Curate datasets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./transform-datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Transform datasets</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Analysis</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./exploration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Exploration</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Inference</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./communication.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Communication</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reporting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Reports</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./collaboration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Collaboration</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./feedback.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Feedback <i class="fa-solid fa-comment" aria-label="comment"></i></span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#downloads" id="toc-downloads" class="nav-link active" data-scroll-target="#downloads"><span class="header-section-number">5.1</span> Downloads</a>
  <ul class="collapse">
<li><a href="#manual" id="toc-manual" class="nav-link" data-scroll-target="#manual"><span class="header-section-number">5.1.1</span> Manual</a></li>
  <li><a href="#programmatic" id="toc-programmatic" class="nav-link" data-scroll-target="#programmatic"><span class="header-section-number">5.1.2</span> Programmatic</a></li>
  </ul>
</li>
  <li><a href="#sec-apis" id="toc-sec-apis" class="nav-link" data-scroll-target="#sec-apis"><span class="header-section-number">5.2</span> APIs</a></li>
  <li>
<a href="#sec-web-scraping" id="toc-sec-web-scraping" class="nav-link" data-scroll-target="#sec-web-scraping"><span class="header-section-number">5.3</span> Web scraping</a>
  <ul class="collapse">
<li><a href="#apis" id="toc-apis" class="nav-link" data-scroll-target="#apis"><span class="header-section-number">5.3.1</span> APIs</a></li>
  <li><a href="#web-scraping" id="toc-web-scraping" class="nav-link" data-scroll-target="#web-scraping"><span class="header-section-number">5.3.2</span> Web scraping</a></li>
  <li><a href="#documentation" id="toc-documentation" class="nav-link" data-scroll-target="#documentation"><span class="header-section-number">5.3.3</span> Documentation</a></li>
  </ul>
</li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  <li><a href="#activities" id="toc-activities" class="nav-link" data-scroll-target="#activities">Activities</a></li>
  <li><a href="#questions" id="toc-questions" class="nav-link" data-scroll-target="#questions">Questions</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title"><span id="sec-acquire-data" class="quarto-section-identifier"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Acquire data</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><div class="callout callout-style-default callout-caution callout-titled" title="Caution">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>Under development.</p>
</div>
</div>
<!--

Content:

- [x] Figure out what do do with Twitter API: can we still stream? Or is `rtoot` for Mastodon a better option at this point? Remove.
- [x] Figure out what to do with the web scraping section: Gutenberg Project (single page), SPLLOC (multiple pages), Maybe the American Presidency Project?
  - [x] Single page SOTU here (Federalist Papers LOC on Recipe)

Exercises:

- [ ] Add concept questions to the Activities
- [ ] Add exercises to the Activities
- [ ] Add thought questions/ case studies to prose sections

Formatting:

-->
<blockquote class="blockquote">
<p>The scariest moment is always just before you start.</p>
<p>―– Stephen King</p>
</blockquote>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-list-alt" aria-label="list-alt"></i> Outcomes</strong></p>
<!-- Remember and understand verbs: https://tips.uark.edu/blooms-taxonomy-verb-chart/ -->
<!-- [x] change to outcomes/ update for new chapter content -->
<ul>
<li>Identify common strategies for acquiring corpus data.</li>
<li>Describe how to organize and document data acquisition to support reproducibility.</li>
<li>Recall R programming concepts and strategies relevant to acquiring data.</li>
</ul>
</div>
</div>
</div>
<!--  
Programming topics:
- control statements
  - `if` statements
  - `message` function
  - `stop` function
- custom functions
  - required and optional arguments
  - argument checks
  - `return` function
  - `invisible` function
-->

<!--  
- [x] Consider how to document the changes to the scaffolding.
  - [x] Use R or qmd?
    - Quarto make more sense for documentation, but the rendered HTML appears side-by-side with the script files. This looks messy. Or I don't show the HTML output. Then, later in the book (Chapter 13: collaboration), I introduce how to tie the HTML output to a full website with `_site.yml`? 

project/
├── _main.R
├── data/
│   ├── analysis/
│   ├── derived/
│   └── original/
├── output/
│   ├── figures/
│   ├── reports/
│   ├── results/
│   └── tables/
├── README
└── code/

-->
<p>As we start down the path to executing our research blueprint, our first step is to acquire the primary data that will be employed in the project. This chapter covers three widely-used strategies for acquiring corpus data: downloads, APIs (Application Programming Interfaces), and web scraping. We get started with the most straighforward approaches from a conceptual standpoint, gradually escalating to more nuanced methods. We will encounter various file formats and folder structures in the process and we will address how to effectively organize our data for subsequent processing. Crucial to our efforts is the process of documenting our data. We will learn to provide data origin information to ensure key characteristics of the data and its source are documented. Along the way we will explore R coding concepts including control statements and custom functions relevant to the task of acquiring data. By the end of this chapter, you will not only be adept at acquiring data from diverse sources but also capable of documenting it comprehensively, enabling you to replicate the process in the future.</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-terminal" aria-label="terminal"></i> Swirl lesson</strong></p>
<!-- Remember and understand verbs: https://tips.uark.edu/blooms-taxonomy-verb-chart/ -->
<p><strong>What</strong>: <a href="https://github.com/qtalr/lessons">Control Statements, Custom Functions</a><br><strong>How</strong>: In the R Console pane load <code>swirl</code>, run <code>swirl()</code>, and follow prompts to select the lesson.<br><strong>Why</strong>: To recognize the logic behind code that can make dynamic choices and to recall how functions serve to produce efficient, reusable, and more legible code.</p>
</div>
</div>
</div>
<section id="downloads" class="level2" data-number="5.1"><h2 data-number="5.1" class="anchored" data-anchor-id="downloads">
<span class="header-section-number">5.1</span> Downloads</h2>
<p>The most common and straightforward method for acquiring corpus data is through direct downloads. In a nutshell, this method involves navigating to a website, locating the data, and downloading it to your computing environment. In some cases access to the data requires manual intervention and in others the process can be implemented programmatically. The data may be contained in a single file or multiple files. The files may be compressed or uncompressed. The data may be hierarchically organized or not. Each resource will have its own unique characteristics that will influence the process of acquiring the data. In this section we will work through a few examples to demonstrate the general process of acquiring data through downloads.</p>
<section id="manual" class="level3" data-number="5.1.1"><h3 data-number="5.1.1" class="anchored" data-anchor-id="manual">
<span class="header-section-number">5.1.1</span> Manual</h3>
<p>In contrast to the other data acquisition methods we will cover in this chapter, <strong>manual downloads</strong> require human intervention. This means that manual downloads are non-reproducible in a strict sense and require that we keep track of and document our procedure. It is a very common for research projects to acquire data through manual downloads as many data resources require some legwork before they are accessible for downloading. These can be resources that require institutional or private licensing and fees (<a href="https://www.ldc.upenn.edu/">Language Data Consortium</a>, <a href="http://ice-corpora.net/ice/">International Corpus of English</a>, <a href="https://www.corpusdata.org/">BYU Corpora</a>, <em>etc.</em>), require authorization/ registration (<a href="https://archive.mpi.nl/tla/">The Language Archive</a>, <a href="https://www.webcorpora.org/">COW Corpora</a>, <em>etc.</em>), and/ or are only accessible via resource search interfaces (<a href="https://cesa.arizona.edu/">Corpus of Spanish in Southern Arizona</a>, <a href="http://cedel2.learnercorpora.com/">Corpus Escrito del Español como L2 (CEDEL2)</a>, <em>etc.</em>).</p>
<p>Let’s take a look at how to acquire data from a resource that requires manual intervention. The resource we will use is the <a href="http://cedel2.learnercorpora.com/">Corpus Escrito del Español como L2 (CEDEL2)</a> <span class="citation" data-cites="Lozano2009">(<a href="references.html#ref-Lozano2009" role="doc-biblioref">Lozano 2009</a>)</span>, a corpus of Spanish learner writing. It includes L2 writing from students with a variety of L1 backgrounds. For comparative puposes it also includes native writing for Spanish, English, and several other languages.</p>
<p>The CEDEL2 corpus is a freely available resource, but to access the data you must first use a search interface to select the relevant characteristics of the data of interest. Following the search/ download link you can find a search interface that allows the user to select the subcorpus and filter the results by a set of attributes, seen in <a href="#fig-ad-cedel2-search">Figure&nbsp;<span>5.1</span></a>.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/fig-ad-cedel2-search_7da21ec64ddb97bff18376e05ce330cd">
<div class="cell-output-display">
<div id="fig-ad-cedel2-search" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="figures/acquire-data/ad-cedel2-search.png" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;5.1: Search and download interface for the CEDEL2 Corpus</figcaption></figure>
</div>
</div>
</div>
<p>For this example let’s assume that we want to acquire data to use in a study comparing the use of the Spanish preterite and imperfect past tense aspect in written texts by English L1 learners of Spanish to native Spanish speakers. To acquire data for such a project, we will first select the subcorpus “Learners of L2 Spanish”. We will set the results to provide full texts and filter the results to “L1 English - L2 Spanish”. Additionally, we will set the medium to “Written”. This will provide us with a set of texts for the L2 learners that we can use for our study. The search parameters and results are shown in <a href="#fig-ad-cedel2-results">Figure&nbsp;<span>5.2</span></a>.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/fig-ad-cedel2-results_f1fd124ae8984a41c70e991e4e3a4004">
<div class="cell-output-display">
<div id="fig-ad-cedel2-results" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="figures/acquire-data/ad-cedel2-results.png" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;5.2: Search results for the CEDEL2 Corpus</figcaption></figure>
</div>
</div>
</div>
<p>The ‘Download’ link now appears for this search criteria. Following this link will provide the user a form to fill out. This particular resource allows for access to different formats to download (Texts only, Texts with metadata, CSV (Excel), CSV (Others)). I will select the ‘CSV (Others)’ option so that the data is structured for easier processing downstream when we work to curate the data in our next processing step. Then I will choose to save the CSV in the <em>data/original/</em> directory of my project and create a sub-directory named <em>cedel2/</em>, as seen in <a href="#exm-ad-cedel2-learners-download">Example&nbsp;<span>5.1</span></a>.</p>
<div id="exm-ad-cedel2-learners-download" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.1 </strong></span>Download CEDEL2 L2 Spanish Learners data</p>
<pre><code>data/
├── analysis/
├── derived/
└── original/
    └── cedel2/
       └── cedel2-l1-english-learners.csv</code></pre>
</div>
<p>Note that the file is named <em>cedel2-l1-english-learners.csv</em> to reflect the search criteria used to acquire the data. In combination with other data documentation, this will help us to maintain transparency.</p>
<p>Now, after downloading the L2 learner and the native speaker data into the appropriate directory, we move on to the next processing step, right? Not so fast! Imagine we are working on a project with a collaborator. How will they know where the data came from? What if we need to come back to this data in the future? How will we know what characteristics we used to filter the data? The directory and filenames may not be enough. To address these questions we need to document the origin of the data, and in the case of data acquired through manual downloads, we need to document the procedures we took to acquire the data to the best of our ability.</p>
<p>As discussed in <a href="understanding-data.html#sec-ud-data-origin"><span>Section&nbsp;2.3.1</span></a>, all acquired data should be accompanied by a data origin file. The majority of this information can typically be identified on the resource’s website and/ or the resource’s documentation. In the case of the CEDEL2 corpus, the corpus homepage provides most of the information we need.</p>
<p>Structurally, data documentation files should be stored close to the data they describe. So for our data origin file this means adding it to the <em>data/original/</em> directory. Naming the file in a transparent way is also important. I’ve named the file <em>cedel2_do.csv</em> to reflect the name of the corpus, the meaning of the file as data origin with *_do<em>, and the file extension </em>.csv* to reflect the file format. CSV files reflect tabular content. It is not required that data origin files are tabular, but it makes it easier to read and display them in literate programming documents.</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-hand-point-up" aria-label="hand-point-up"></i> Tip</strong></p>
<p>There are many ways to create and edit CSV files. You can use a spreadsheet program like MS Excel or Google Sheets, a text editor like Notepad or TextEdit, or a code editor like RStudio or VS Code. The <code>qtalrkit</code> package provides a convenient function, <code><a href="https://qtalr.github.io/qtalrkit/reference/create_data_origin.html">create_data_origin()</a></code> to create a CSV file with the data origin boilerplate structure. This CSV file then can be edited to add the relevant information in any of the above mentioned programs.</p>
<p>Using a spreadsheet program is the easiest method for editing tabular data. The key is to save the file as a CSV file, and not as an Excel file, to maintain our adherence to the principle of using open formats for reproducible research.</p>
</div>
</div>
</div>
<p>In <a href="#tbl-ad-cedel2-do">Table&nbsp;<span>5.1</span></a>, I’ve created a data origin file for the CEDEL2 corpus.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/tbl-ad-cedel2-do_d60071b3e443c240d532f990d72acb17">
<div class="cell-output-display">
<div id="tbl-ad-cedel2-do" class="anchored">
<table class="table table-sm table-striped small">
<caption>Table&nbsp;5.1: Data origin file for the CEDEL2 corpus</caption>
<colgroup>
<col style="width: 25%">
<col style="width: 75%">
</colgroup>
<thead><tr class="header">
<th style="text-align: left;">attribute</th>
<th style="text-align: left;">description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Resource name</td>
<td style="text-align: left;">CEDEL2: Corpus Escrito del Español como L2.</td>
</tr>
<tr class="even">
<td style="text-align: left;">Data source</td>
<td style="text-align: left;">http://cedel2.learnercorpora.com/, https://doi.org/10.1177/02676583211050522</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Data sampling frame</td>
<td style="text-align: left;">Corpus that contains samples of the language produced from learners of Spanish as a second language. For comparative purposes, it also contains a native control subcorpus of the language produced by native speakers of Spanish from different varieties (peninsular Spanish and all varieties of Latin American Spanish), so it can be used as a native corpus in its own right.</td>
</tr>
<tr class="even">
<td style="text-align: left;">Data collection date(s)</td>
<td style="text-align: left;">2006-2020.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Data format</td>
<td style="text-align: left;">CSV file. Each row corresponds to a writing sample. Each column is an attribute of the writing sample.</td>
</tr>
<tr class="even">
<td style="text-align: left;">Data schema</td>
<td style="text-align: left;">A CSV file for L2 learners and a CSV file for native speakers.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">License</td>
<td style="text-align: left;">CC BY-NC-ND 3.0 ES</td>
</tr>
<tr class="even">
<td style="text-align: left;">Attribution</td>
<td style="text-align: left;">Lozano, C. (2022). CEDEL2: Design, compilation and web interface of an online corpus for L2 Spanish acquisition research. Second Language Research, 38(4), 965-983. https://doi.org/10.1177/02676583211050522.</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Given this is a manual download we also need to document the procedure used to retrieve the data in prose. The script in the <em>code/</em> directory that is typically used to acquire the data is not used to programmatically retrieve data in this case. However, to keep things predictable we will use this file to document the download procedure. I’ve created a Quarto file named <em>1_acquire_data.qmd</em> in the <em>code/</em> directory of my project.</p>
<p>A glimpse at the directory structure of the project at this point is seen in <a href="#exm-ad-cedel2-structure">Example&nbsp;<span>5.2</span></a>.</p>
<div id="exm-ad-cedel2-structure" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.2 </strong></span>Project structure for the CEDEL2 corpus data acquisition</p>
<pre><code>project/
├── code/
│   ├── 1_acquire_data.qmd
│   └── ...
├── data/
│   ├── analysis/
│   ├── derived/
│   └── original/
│       ├── cedel2_do.csv
│       └── cedel2/
|           ├── cedel2-l1-english-learners.csv
|           └── cedel2-native-spanish-speakers.csv
├── output/
│   ├── figures/
│   ├── reports/
│   ├── results/
│   └── tables/
├── README.md
└── _main.R</code></pre>
</div>
<p>In the <em>1_acquire_data.qmd</em> file I’ve added example sections to display the data origin CSV file as a table and to document the data download procedures, as seen in <a href="#exm-ad-cedel2-acquire-data-qmd">Example&nbsp;<span>5.3</span></a>.</p>
<div id="exm-ad-cedel2-acquire-data-qmd" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.3 </strong></span>&nbsp;</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>1_acquire_data.qmd</strong></pre>
</div>
<div class="sourceCode" id="cb3"><pre class="sourceCode markdown quarto code-with-copy"><code class="sourceCode markdown"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Acquire data"</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> html</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="fu">## Overview</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>The goal of this script is to acquire and document data for this project from the CEDEL2 corpus. The acquired data will be stored in the <span class="in">`data/original/cedel2/`</span> directory.</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data origin</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>To document the origin of the data we created a file named <span class="in">`cedel2_do.csv`</span> in the <span class="in">`data/original/`</span> directory. This file contains the following information: </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-cedel2-data-origin</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Data origin file for the CEDEL2 corpus"</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Display data origin file</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>readr<span class="sc">::</span><span class="fu">read_csv</span>(<span class="st">"../data/original/cedel2_do.csv"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="fu">## Download procedures</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>The process to acquire data from the CEDEL2 corpus involved the following steps:</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>L2 Spanish Learners:</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Navigate to the <span class="co">[</span><span class="ot">CEDEL2 Corpus</span><span class="co">](http://cedel2.learnercorpora.com/search)</span> search interface</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Select the subcorpus "Learners of L2 Spanish"</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Set the results to provide full texts</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Filter the results to "L1 English - L2 Spanish"</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Set the medium to "Written"</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>Download the data in CSV format</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a><span class="ss">7. </span>Save the CSV file to the <span class="in">`data/original/cedel2/`</span> directory as <span class="in">`cedel2-l1-english-learners.csv`</span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>Spanish natives: </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>The output from <em>1_acquire_data.qmd</em> will contain a table displaying the data origin file and a prose section documenting the data acquisition process. This will provide a transparent record of the data acquisition process for future reference.</p>
<p>Manually downloading other resources will inevitably include unique processes for obtaining the data, but in the end the data should be archived in the research structure in the <em>data/original/</em> directory and documented in the appropriate places. The acquired data is treated as ‘read-only’, meaning it is not modified in any way. This gives us a transparent starting point for subsequent steps in the data preparation process.</p>
</section><section id="programmatic" class="level3" data-number="5.1.2"><h3 data-number="5.1.2" class="anchored" data-anchor-id="programmatic">
<span class="header-section-number">5.1.2</span> Programmatic</h3>
<!-- [ ] Update to SWDA information and download URL -->
<p>There are many resources that provide corpus data that is directly accessible for which programmatic downloads can be applied. A <strong>programmatic download</strong> is a download in which the process can be automated through code. Thus, this is a reproducible process. The data can be acquired by anyone with access to the necessary code.</p>
<p>In this case, and subsquent data acquisition procedures in this chapter, we use the <em>1_acquire_data.qmd</em> Quarto file to its full potential intermingling prose, code, and code comments to execute and document the download procedure. In <a href="#exm-ad-swda-acquire-data-qmd">Example&nbsp;<span>5.4</span></a> I’ve added example sections to display example boilerplate structure for a programmatic data acquisition and documentation.</p>
<!-- Acquire data script -->
<div id="exm-ad-swda-acquire-data-qmd" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.4 </strong></span>Boilerplate for a programmatic data acquisition and documentation</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>1_acquire_data.qmd</strong></pre>
</div>
<div class="sourceCode" id="cb4"><pre class="sourceCode markdown quarto code-with-copy"><code class="sourceCode markdown"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Acquire data"</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> html</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="fu">## Overview</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>The goal of this script is to ...</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data origin</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>To document the origin of the data we created a file named ...</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="fu">## Download procedures</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: setup</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Load libraries</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="co"># .. additional code here to acquire data ...</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>... and so on</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>To illustrate how this works to conduct a programmatic download, we will work with the Switchboard Dialog Act Corpus (SWDA) <span class="citation" data-cites="SWDA2008">(<a href="references.html#ref-SWDA2008" role="doc-biblioref">University of Colorado Boulder 2008</a>)</span>. The version that we will use is found on the Linguistic Data Consortium under the <a href="https://catalog.ldc.upenn.edu/LDC97S62">Switchboard-1 Release 2 Corpus</a>. The corpus and related documentation are linked on the catalog page <a href="https://catalog.ldc.upenn.edu/docs/LDC97S62/" class="uri">https://catalog.ldc.upenn.edu/docs/LDC97S62/</a>.</p>
<p>From the documentation we learn that the corpus contains transcripts for 1155 5-minute two-way telephone conversations among English speakers for all areas of the United States. The speakers were given a topic to discuss and the conversations were recorded. The corpus metadata and annotations for sociolinguistic and discourse features.</p>
<p>The SWDA was referred to in <a href="approaching-analysis.html#sec-aa-infer"><span>Section&nbsp;3.2.3</span></a> to support our toy hypothesis that men and women differ in the frequency of the use of questions in spontaneous conversations. This corpus, as you can image, could support a wide range of interesting reseach questions. Let’s assume we are following research conducted by <span class="citation" data-cites="Tottie2011">Tottie (<a href="references.html#ref-Tottie2011" role="doc-biblioref">2011</a>)</span> to explore the use of filled pauses such as “um” and “uh” and traditional sociolinguistic variables such as sex, age, and education in spontaneous speech by American English speakers.</p>
<p>With this goal in mind, let’s get started writing the code to download and organize the data in our project directory. First we need to identify the URL (Uniform Resource Locator) for the data that we want to download. More often than not this file will be some type of compressed archive file with an extension such as <em>.zip</em> (Zipped file), <em>.tar</em> (Tarball file), or <em>tar.gz</em> (Gzipped tarball file), which is the case for the SWDA corpus. Compressed files make downloading multiple files easy by grouping files and directories into one file.</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-lightbulb" aria-label="lightbulb"></i> Consider this</strong></p>
<p>You may be wondering what the difference betwen <em>.zip</em>, <em>.tar</em>, and <em>.tar.gz</em> files are. The <em>.zip</em> file format is the most common. It groups file and directories into one file (archives) and compresses them to reduce the size of the file in one step when the file is created.</p>
<p>The <em>.tar</em> file format is used archive files and folders, it does not perform compression. Gzipping peforms the compression to the <em>.tar</em> file resulting in a file with the <em>.tar.gz</em> extension. Notably the <em>.gz</em> compression is highly efficient for large files. Take the <em>swda.tar.gz</em> file for example. It has a compressed file size of 4.6 MB, but when uncompressed it is 16.9 MB. This is a 73% reduction in file size.</p>
</div>
</div>
</div>
<p>In R we can use the <code><a href="https://rdrr.io/r/utils/download.file.html">download.file()</a></code> function from base R. The <code><a href="https://rdrr.io/r/utils/download.file.html">download.file()</a></code> function minimally requires two arguments: <code>url</code> and <code>destfile</code>. These correspond to the file to download and the location where it is to be saved to disk. To break out the process a bit, I will assign the URL and destination file path to variables and then use the <code><a href="https://rdrr.io/r/utils/download.file.html">download.file()</a></code> function to download the file.</p>
<div id="exm-ad-swda-download-file" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.5 </strong></span>&nbsp;</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-swda-download-file_9473d241969fba3e438f5155f5d733ea">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># URL to SWDA corpus compressed file</span></span>
<span><span class="va">file_url</span> <span class="op">&lt;-</span> <span class="st">"https://catalog.ldc.upenn.edu/docs/LDC97S62/swb1_dialogact_annot.tar.gz"</span></span>
<span></span>
<span><span class="co"># Relative path to project/data/original directory</span></span>
<span><span class="va">file_path</span> <span class="op">&lt;-</span> <span class="st">"../data/original/swda.tar.gz"</span></span>
<span></span>
<span><span class="co"># Download SWDA corpus compressed file</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/download.file.html">download.file</a></span><span class="op">(</span>url <span class="op">=</span> <span class="va">file_url</span>, destfile <span class="op">=</span> <span class="va">file_path</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-exclamation-triangle" aria-label="exclamation-triangle"></i> Warning</strong></p>
<p>Note that the <code>file_path</code> variable in <a href="#exm-ad-swda-download-file">Example&nbsp;<span>5.5</span></a> is a relative path to the <em>data/original/</em> directory. This is because the <em>1_acquire_data.qmd</em> file that we are using for this code is located in the <em>code/</em> directory and the <em>data/</em> directory is a sibling directory to the <em>code/</em> directory.</p>
<p>It is also possible to use an absolute path to the <em>data/original/</em> directory. I will have more to say about the advantages and disadvantages of relative and absolute paths in reproducible research in <a href="collaboration.html"><span>Chapter&nbsp;12</span></a>.</p>
</div>
</div>
</div>
<p>As we can see looking at the directory structure, in <a href="#exm-ad-swda-download-location">Example&nbsp;<span>5.6</span></a>, the <em>swda.tar.zip</em> file has been added to the <em>data/original/</em> directory.</p>
<div id="exm-ad-swda-download-location" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.6 </strong></span>Downloaded SWDA corpus compressed file</p>
<pre><code>data/
├── analysis/
├── derived/
└── original/
    └── swda.tar.zip</code></pre>
</div>
<p>Once an compressed file is downloaded, however, the file needs to be ‘decompressed’ to reveal the directory structure and files. To decompress this <em>.tar.gz</em> file we use the <code><a href="https://rdrr.io/r/utils/untar.html">untar()</a></code> function with the arguments <code>tarfile</code> pointing to the <em>.tar.gz</em> file and <code>exdir</code> specifying the directory where we want the files to be extracted to. Again, I will assign the arguments to variables. Then we can decompress the file using the <code><a href="https://rdrr.io/r/utils/untar.html">untar()</a></code> function.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-swda-decompress-file_be70a695f62f76703a936b4d5529e54e">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Relative path to the compressed file</span></span>
<span><span class="va">tar_file</span> <span class="op">&lt;-</span> <span class="st">"../data/original/swda.tar.gz"</span></span>
<span></span>
<span><span class="co"># Relative path to the directory to extract to</span></span>
<span><span class="va">extract_to_dir</span> <span class="op">&lt;-</span> <span class="st">"../data/original/swda/"</span></span>
<span></span>
<span><span class="co"># Decompress .zip file and extract to our target directory</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/untar.html">untar</a></span><span class="op">(</span><span class="va">tar_file</span>, <span class="va">extract_to_dir</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The directory structure of <em>data/</em> in <a href="#exm-ad-swda-decompress-location">Example&nbsp;<span>5.7</span></a> now shows the <em>swda.tar.gz</em> file and the <em>swda</em> directory that contains the decompressed directories and files.</p>
<div id="exm-ad-swda-decompress-location" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.7 </strong></span>&nbsp;</p>
<pre><code>data/
├── analysis/
├── derived/
└── original/
    ├── swda/
    │   ├── README
    │   ├── doc/
    │   ├── sw00utt/
    │   ├── sw01utt/
    │   ├── sw02utt/
    │   ├── sw03utt/
    │   ├── sw04utt/
    │   ├── sw05utt/
    │   ├── sw06utt/
    │   ├── sw07utt/
    │   ├── sw08utt/
    │   ├── sw09utt/
    │   ├── sw10utt/
    │   ├── sw11utt/
    │   ├── sw12utt/
    │   └── sw13utt/
    └── swda.tar.gz</code></pre>
</div>
<p>At this point we have acquired the data programmatically and with this code as part of our workflow anyone could run this code and reproduce the same results. The code as it is, however, is not ideally efficient. Firstly the <em>swda.tar.gz</em> file is not strictly needed after we decompress it and it occupies disk space if we keep it. And second, each time we run this code the file will be downloaded from the remote server. This leads to unnecessary data transfer and server traffic and will overwrite the data if it already exists in our project directory which could be problematic if the data changes on the remote server. Let’s tackle each of these issues in turn.</p>
<p>To avoid writing the <em>swda.tar.gz</em> file to disk (long-term) we can use the <code><a href="https://rdrr.io/r/base/tempfile.html">tempfile()</a></code> function to open a temporary holding space for the file in the computing environment. This space can then be used to store the file, decompress it, and then the temporary file will automatically be deleted. We assign the temporary space to an R object we will name <code>temp_file</code> with the <code><a href="https://rdrr.io/r/base/tempfile.html">tempfile()</a></code> function. This object can now be used as the value of the argument <code>destfile</code> in the <code><a href="https://rdrr.io/r/utils/download.file.html">download.file()</a></code> function.</p>
<div id="exm-ad-swda-temp-file" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.8 </strong></span>&nbsp;</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-swda-temp-file_ae6aec798151bd3f3d2ee66f13892518">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># URL to SWDA corpus compressed file</span></span>
<span><span class="va">file_url</span> <span class="op">&lt;-</span> <span class="st">"https://catalog.ldc.upenn.edu/docs/LDC97S62/swb1_dialogact_annot.tar.gz"</span></span>
<span></span>
<span><span class="co"># Create a temporary file space for our .tar.gz file</span></span>
<span><span class="va">temp_file</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html">tempfile</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Download SWDA corpus compressed file</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/download.file.html">download.file</a></span><span class="op">(</span><span class="va">file_url</span>, <span class="va">temp_file</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-hand-point-up" aria-label="hand-point-up"></i> Tip</strong></p>
<p>In the previous code I’ve used the values stored in the objects <code>file_url</code> and <code>temp_file</code> in the <code><a href="https://rdrr.io/r/utils/download.file.html">download.file()</a></code> function without specifying the argument names –only providing the names of the objects. R will assume that values of a function map to the ordering of the arguments. If your values do not map to ordering of the arguments you are required to specify the argument name and the value. To view the ordering of objects hit <kbd>tab</kbd> after entering the function name or consult the function documentation by prefixing the function name with <code>?</code> and hitting <kbd>enter</kbd>.</p>
</div>
</div>
</div>
<p>At this point our downloaded file is stored temporarily on disk and can be accessed and decompressed to our target directory using <em>temp_file</em> as the value for the argument <code>tarfile</code> from the <code><a href="https://rdrr.io/r/utils/untar.html">untar()</a></code> function. I’ve assigned our target directory path to <code>extract_to_dir</code> and used it as the value for the argument <code>exdir</code>.</p>
<!-- 
Note: `untar()` function arguments needed are not in order and need names 
-->
<div id="exm-ad-swda-untar-temp" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.9 </strong></span>&nbsp;</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-swda-untar-temp_49f0124c095625ba9ba1fc97cefdda29">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Assign our target directory to `extract_to_dir`</span></span>
<span><span class="va">extract_to_dir</span> <span class="op">&lt;-</span> <span class="st">"../data/original/swda/"</span></span>
<span></span>
<span><span class="co"># Decompress .tar.gz file and extract to our target directory</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/untar.html">untar</a></span><span class="op">(</span>tarfile <span class="op">=</span> <span class="va">temp_file</span>, exdir <span class="op">=</span> <span class="va">target_dir</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>Our directory structure in <a href="#exm-ad-swda-untar-temp">Example&nbsp;<span>5.9</span></a> is the same as in <a href="#exm-ad-swda-decompress-location">Example&nbsp;<span>5.7</span></a>, minus the <em>swda.tar.gz</em> file.</p>
<p>The second issue I raised concerns the fact that running this code as part of our project will repeat the download each time. Since we would like to be good citizens and avoid unnecessary traffic on the web and avoid potential issues in overwriting data, it would be nice if our code checked to see if we already have the data on disk and if it exists, then skip the download, if not then download it.</p>
<p>The desired functionality we’ve described can be implemented using the <code>if()</code> function. The <code>if()</code> function is one of a class of functions known as control statements. <strong>Control statments</strong> allow us to control the flow of our code by evaluating logical statements and processing subsequent code based on the logical value it is passed as an argument.</p>
<p>So in this case we want to evaluate whether the data directory exists on disk. If it does then skip the download, if not, proceed with the download. In combination with <code>else</code> which provides the ‘if not’ part of the statement, we have the following logical flow in <a href="#exm-ad-if-dir-exists">Example&nbsp;<span>5.10</span></a>.</p>
<div id="exm-ad-if-dir-exists" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.10 </strong></span>&nbsp;</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw">if</span> <span class="op">(</span><span class="va">DIRECTORY_EXISTS</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Do nothing</span></span>
<span><span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>  <span class="co"># Download data</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can simplify this statement by using the <code>!</code> operator which negates the logical value of the statement it precedes. So if the directory exists, <code>!DIRECTORY_EXISTS</code> will return <code>FALSE</code> and if the directory does not exist, <code>!DIRECTORY_EXISTS</code> will return <code>TRUE</code>. In other words, if the directory does not exist, download the data. This is shown in <a href="#exm-ad-if-dir-exists-simplified">Example&nbsp;<span>5.11</span></a>.</p>
<div id="exm-ad-if-dir-exists-simplified" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.11 </strong></span>&nbsp;</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="va">DIRECTORY_EXISTS</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Download data</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, to determine if a directory exists in our project directory we will turn to the <code>fs</code> package <span class="citation" data-cites="R-fs">(<a href="references.html#ref-R-fs" role="doc-biblioref">Hester, Wickham, and Csárdi 2023</a>)</span>. The <code>fs</code> package provides a set of functions for interacting with the file system, including <code><a href="https://fs.r-lib.org/reference/file_access.html">dir_exists()</a></code>. <code><a href="https://fs.r-lib.org/reference/file_access.html">dir_exists()</a></code> takes a path to a directory as an argument and returns the logical value, <code>TRUE</code>, if that directory exists, and <code>FALSE</code> if it does not.</p>
<p>We can use this function to evaluate whether the directory exists and then use the <code>if()</code> function to process the subsequent code based on the logical flow we set out in <a href="#exm-ad-if-dir-exists-simplified">Example&nbsp;<span>5.11</span></a>. Applied to our project, the code will look like <a href="#exm-ad-swda-if-dir-exists">Example&nbsp;<span>5.12</span></a>.</p>
<div id="exm-ad-swda-if-dir-exists" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.12 </strong></span>&nbsp;</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-swda-if-dir-exists_4652486fc39334b044b7df01ea060884">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load the `fs` package</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://fs.r-lib.org">fs</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># URL to SWDA corpus compressed file</span></span>
<span><span class="va">file_url</span> <span class="op">&lt;-</span> <span class="st">"https://catalog.ldc.upenn.edu/docs/LDC97S62/swb1_dialogact_annot.tar.gz"</span></span>
<span></span>
<span><span class="co"># Create a temporary file space for our .tar.gz file</span></span>
<span><span class="va">temp_file</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html">tempfile</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Assign our target directory to `extract_to_dir`</span></span>
<span><span class="va">extract_to_dir</span> <span class="op">&lt;-</span> <span class="st">"../data/original/swda/"</span></span>
<span></span>
<span><span class="co"># Check if our target directory exists</span></span>
<span><span class="co"># If it does not exist, download the file and extract it</span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://fs.r-lib.org/reference/file_access.html">dir_exists</a></span><span class="op">(</span><span class="va">extract_to_dir</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Download SWDA corpus compressed file</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/download.file.html">download.file</a></span><span class="op">(</span><span class="va">file_url</span>, <span class="va">temp_file</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Decompress .tar.gz file and extract to our target directory</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/untar.html">untar</a></span><span class="op">(</span>tarfile <span class="op">=</span> <span class="va">temp_file</span>, exdir <span class="op">=</span> <span class="va">extract_to_dir</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>The code in <a href="#exm-ad-swda-if-dir-exists">Example&nbsp;<span>5.12</span></a> is added to the <em>1_acquire_data.qmd</em> file we introduced in <a href="#exm-ad-swda-acquire-data-qmd">Example&nbsp;<span>5.4</span></a>. When this file is run, the SWDA corpus data will be downloaded and extracted to our project directory. If the data already exists, the download will be skipped, just as we wanted.</p>
<p>Before we move on, we need to make sure to create and add the appropriate information to the data origin file. To make this easier, the <code>qtalrkit</code> package includes a function, <code><a href="https://qtalr.github.io/qtalrkit/reference/create_data_origin.html">create_data_origin()</a></code>, to create a data origin file template in CSV format. This function takes the path for the desired file. In the SWDA Corpus case, this might be something like: <em>../data/original/swda_do.csv</em>. The function only needs to be run once and does not need to be part of the reproducible workflow.</p>
<p>Running the code in <a href="#exm-ad-swda-create-do">Example&nbsp;<span>5.13</span></a> at the console will create the file. Open it in your preferred text or spreadsheet editor to add the appropriate information.</p>
<div id="exm-ad-swda-create-do" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.13 </strong></span>&nbsp;</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-swda-create-do_e0750e64501d7257ab85b3081f1839e3">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load the `qtalrkit` package</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/qtalr/qtalrkit">qtalrkit</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a data origin file template</span></span>
<span><span class="fu"><a href="https://qtalr.github.io/qtalrkit/reference/create_data_origin.html">create_data_origin</a></span><span class="op">(</span><span class="st">"../data/original/swda_do.csv"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>Our complete project structure for the SWDA corpus data acquisition is shown in <a href="#exm-ad-swda-structure">Example&nbsp;<span>5.14</span></a>.</p>
<div id="exm-ad-swda-structure" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.14 </strong></span>Project structure for the SWDA corpus data acquisition</p>
<pre><code>project/
├── code/
│   ├── 1_acquire_data.qmd
│   └── ...
├── data/
│   ├── analysis/
│   ├── derived/
│   └── original/
│       ├── swda_do.csv
│       └── swda/
│          ├── README
│          ├── doc/
│          ├── sw00utt/
│          ├── sw01utt/
│          ├── sw02utt/
│          ├── sw03utt/
│          ├── sw04utt/
│          ├── sw05utt/
│          ├── sw06utt/
│          ├── sw07utt/
│          ├── sw08utt/
│          ├── sw09utt/
│          ├── sw10utt/
│          ├── sw11utt/
│          ├── sw12utt/
│          └── sw13utt/
├── output/
│   ├── figures/
│   ├── reports/
│   ├── results/
│   └── tables/
├── README.md
└── _main.R</code></pre>
</div>
<p>Great, we’ve successfully acquired and documented the SWDA Corpus data. We’ve leveraged R to automate the download and extraction of the data, depending on the existence of the data in our project directory. But you may be asking yourself, “Can’t I just navigate to the corpus page and download the data manually myself?” The simple answer is, “Yes, you can.” The more nuanced answer is, “Yes, but consider the trade-offs.”</p>
<p>The following scenarios highlight the some advantages to automating the process. If you are acquiring data from multiple files, it can become tedious to document the manual process for each file such that it is reproducible. It’s possible, but it’s error prone. Now, if you are collaborating with others, you will want to share this data with them. It is very common to find data that has limited restrictions for use in academic projects, but the most common limitation is redistribution. This means that you can use the data for your own research, but you cannot share it with others. If you plan on publishing your project to a repository, like GitHub, to share the data as part of your reproducible project, you would be violating the terms of use for the data. By including the programmatic download in your project, you can ensure that your collaborators can easily and effectively acquire the data themselves and that you are not violating the terms of use.</p>
</section></section><section id="sec-apis" class="level2" data-number="5.2"><h2 data-number="5.2" class="anchored" data-anchor-id="sec-apis">
<span class="header-section-number">5.2</span> APIs</h2>
<p>A convenient alternative method for acquiring data in R is through package interfaces to web services. These interfaces are built using R code to make connections with resources on the web through <strong>Application Programming Interfaces</strong> (APIs). Websites such as Project Gutenberg, Twitter, Facebook, and many others provide APIs to allow access to their data under certain conditions, some more limiting for data collection than others. Programmers (like you!) in the R community take up the task of wrapping calls to an API with R code to make accessing that data from R convenient, and of course reproducible.</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-medal" aria-label="medal"></i> Dive deeper</strong></p>
<p>Many, many web services provide API access. These APIs span all kinds of data, from text to images to video to audio. Visit the <a href="https://publicapis.io/">Public APIs website</a> to explore the diversity of APIs available. ROpenSci maintains a curated list of R packages that provide access to data from web services. Visit the <a href="https://ropensci.org/packages/data-access/">ROpenSci website</a> to explore the packages available.</p>
</div>
</div>
</div>
<!-- Change list of examples: gutenbergr, rwhatsapp, rtoot, jstor? -->
<p>Examples of APIs that provide access to text data include the <a href="https://www.gutenberg.org/">Project Gutenberg</a> API, the <a href="https://developer.twitter.com/en/docs">Twitter</a> API, and the <a href="https://developers.facebook.com/docs/apis-and-sdks">Facebook</a> API. In this section, we will explore the <a href="https://talkbank.org/">TalkBank</a> API, which provides access to a large collection of spoken language corpora. We will use the [TBDBr](</p>
<ul class="task-list">
<li>
<input type="checkbox"><strong>Pick up here</strong>
<ul>
<li>Introduce CABANK and TalkBank
<ul>
<li>Useful for a study aiming to research spoken British English, either in isoloation or in comparison to American English (SWDA).</li>
</ul>
</li>
<li>Introduce <code>TBDBr</code> package.
<ul>
<li>Show available functions in the package. <code>ls(getNamespace("TBDBr"))</code>
</li>
<li>Basic arguments for <code>get*()</code> functions: <code>corpusName</code> and <code>corpora</code>
<ul>
<li>Same for these function, demonstrate. So, ideally we could use one function to get all the data we need.</li>
<li>
<input type="checkbox">Write custom function to download all resources for a TalkBank API resource.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<input type="checkbox">Where to add the function.
<ul class="task-list">
<li>
<input type="checkbox">In the relevant script, <code>1_acquire_data.qmd</code> in this case.</li>
<li>
<input type="checkbox">In a separate file, <code>_functions.R</code> in this case.
<ul class="task-list">
<li>
<input type="checkbox">If you have multiple functions, it is good practice to put them in a separate file. Cleans up the main script and makes it easier to find the functions you need and reuse them in other scripts, if needed.</li>
</ul>
</li>
</ul>
</li>
</ul>
<div id="exm-ad-functions-r" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.15 </strong></span>&nbsp;</p>
<pre><code>project/
├── code/
│   ├── _functions.R
│   ├── 1_acquire_data.qmd
│   └── ...
├── data/
│   ├── analysis/
│   ├── derived/
│   └── original/
├── output/
│   ├── figures/
│   ├── reports/
│   ├── results/
│   └── tables/
├── README.md
└── _main.R</code></pre>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-hand-point-up" aria-label="hand-point-up"></i> Tip</strong></p>
<p>Note that that the <code>functions.R</code> file is an R script, not a Quarto document. Therefore code blocks that are used in <code>.qmd</code> files are not used, only the R code and code comments.</p>
</div>
</div>
</div>
<p>We then use the <code><a href="https://rdrr.io/r/base/source.html">source()</a></code> function to read that function into our current script to make it available to use as needed. It is good practice to source your functions early on a script so that it is available for use throughout the script.</p>
<p>(note relative path to functions.R) ::: {#exm-ad-source-function}</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-source-function_27d59cab6711d83678752bee92bc2ae8">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load custom functions for this project</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/source.html">source</a></span><span class="op">(</span>file <span class="op">=</span> <span class="st">"functions.R"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>:::</p>
<ul class="task-list">
<li>
<input type="checkbox">Add ‘dive deeper’ on writing functions and creating R packages.</li>
</ul>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong></strong></p>
<p>Writing functions is a great way to make your code more reproducible. If you find yourself repeating the same code over and over again, it is a good candidate for a function. Functions can be used to automate repetitive tasks, but they can also be used to make your code more readable. If you find yourself writing code that is difficult to understand, it is a good candidate for a function. Functions can be used to make your code more readable by abstracting away the details of the code and providing a name that describes what the code does. This is especially useful when you are writing code that will be used by others. If you are interested in learning more about writing functions, check out the <a href="https://r4ds.had.co.nz/functions.html">Writing Functions chapter</a> in the <a href="https://r4ds.had.co.nz/">R for Data Science</a> book.</p>
<p>If you find yourself writing functions that are useful for multiple projects, you may want to consider creating an R package. R packages are a great way to share your code with others. If you are interested in learning more about creating R packages, check out the <a href="https://r-pkgs.org/">R Packages book</a> by Hadley Wickham and Jenny Bryan.</p>
</div>
</div>
</div>
</section><section id="sec-web-scraping" class="level2" data-number="5.3"><h2 data-number="5.3" class="anchored" data-anchor-id="sec-web-scraping">
<span class="header-section-number">5.3</span> Web scraping</h2>
<ul class="task-list">
<li>
<input type="checkbox">Add example of <code><a href="http://xml2.r-lib.org/reference/read_xml.html">rvest::read_html()</a></code>
</li>
<li>
<input type="checkbox">? Add example of <code><a href="https://httr.r-lib.org/reference/GET.html">httr::GET()</a></code> with <code><a href="https://httr.r-lib.org/reference/content.html">httr::content()</a></code>.</li>
<li>
<input type="checkbox"><code><a href="http://xml2.r-lib.org/reference/write_xml.html">xml2::write_html()</a></code>
</li>
</ul>
<p>Federalist papers</p>
<ul>
<li>Example of scraping a single page</li>
<li>Example of scraping multiple pages
<ul>
<li>Pulling out links from single page and then scraping those pages</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Previous material:</strong></p>
<section id="apis" class="level3" data-number="5.3.1"><h3 data-number="5.3.1" class="anchored" data-anchor-id="apis">
<span class="header-section-number">5.3.1</span> APIs</h3>
<p>A convenient alternative method for acquiring data in R is through package interfaces to web services. These interfaces are built using R code to make connections with resources on the web through <strong>Application Programming Interfaces</strong> (APIs). Websites such as Project Gutenberg, Twitter, Facebook, and many others provide APIs to allow access to their data under certain conditions, some more limiting for data collection than others. Programmers (like you!) in the R community take up the task of wrapping calls to an API with R code to make accessing that data from R possible. For example, <a href="https://CRAN.R-project.org/package=gutenbergr">gutenbergr</a> provides access to Project Gutenberg, <a href="https://CRAN.R-project.org/package=rtweet">rtweet</a> to Twitter, and <a href="https://CRAN.R-project.org/package=Rfacebook">Rfacebook</a> to Facebook.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<!-- RESOURCES:
- [rwhatsapp](https://github.com/JBGruber/rwhatsapp) work with personal chat history 
-->
<ul class="task-list">
<li>
<input type="checkbox">Add discussion about APIs.
<ul class="task-list">
<li>
<input type="checkbox">Open access and authentication-based</li>
<li>
<input type="checkbox">API documentation</li>
<li>
<input type="checkbox">R interface packages
<ul class="task-list">
<li>
<input type="checkbox">Examples: <code>gutenbergr</code>, <code>rtweet</code>, <code>rtoot</code>, <code>rwhatsapp</code>, etc.</li>
</ul>
</li>
</ul>
</li>
<li>
<input type="checkbox">Introduce TalkBank repository, API, and <code>TBDBr</code> package.
<ul class="task-list">
<li>
<input type="checkbox">Functions</li>
</ul>
</li>
</ul>
<p>Using R package interfaces, however, often requires some more knowledge about R objects and functions. Let’s take a look at how to access data from Project Gutenberg through the <code>gutenbergr</code> package. Along the way we will touch upon various functions and concepts that are key to working with the R data types vectors and data frames including filtering and writing tabular data to disk in plain-text format.</p>
<p>To get started let’s install and/ or load the <code>gutenbergr</code> package. If a package is not part of the R base library, we cannot assume that the user will have the package in their library. The standard approach for installing and then loading a package is by using the <code><a href="https://rdrr.io/r/utils/install.packages.html">install.packages()</a></code> function and then calling <code><a href="https://rdrr.io/r/base/library.html">library()</a></code>.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-standard-install-load-gutenbergr_34104f8223a90e194a741a31bf0dcfe4">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"gutenbergr"</span><span class="op">)</span> <span class="co"># install `gutenbergr` package</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://docs.ropensci.org/gutenbergr/">gutenbergr</a></span><span class="op">)</span> <span class="co"># load the `gutenbergr` package</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This approach works just fine, but luck has it that there is an R package for installing and loading packages! The <a href="https://CRAN.R-project.org/package=pacman">pacman</a> package includes a set of functions for managing packages. A very useful one is <code>p_load()</code> which will look for a package on a system, load it if it is found, and install and then load it if it is not found. This helps potentially avoid using unnecessary bandwidth to install packages that may already exist on a user’s system. But, to use <code>pacman</code> we need to include the code to install and load it with the functions <code><a href="https://rdrr.io/r/utils/install.packages.html">install.packages()</a></code> and <code><a href="https://rdrr.io/r/base/library.html">library()</a></code>. I’ve included some code that will mimic the behavior of <code>p_load()</code> for installing <code>pacman</code> itself, but as you can see it is not elegant, luckily it’s only used once as we add it to the SETUP section of our master file, <code>_pipeline.R</code>.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/install-load-pacman_68c90bc7a184bb790133d08cb028a008">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load `pacman`. If not installed, install then load.</span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="kw"><a href="https://rdrr.io/r/base/library.html">require</a></span><span class="op">(</span><span class="st"><a href="https://github.com/trinker/pacman">"pacman"</a></span>, character.only <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"pacman"</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/trinker/pacman">"pacman"</a></span>, character.only <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>At this point we have data and could move on to processing this dataset in preparation for analysis. However, we are aiming for a reproducible workflow and this code does not conform to our principle of modularity: each subsequent step in our analysis will depend on running this code first. Furthermore, running this code as it is creates issues with bandwidth, as in our previous examples from direct downloads. To address modularity we will write the dataset to disk in <strong>plain-text format</strong>. In this way each subsequent step in our analysis can access the dataset locally. To address bandwidth concerns, we will devise a method for checking to see if the dataset is already downloaded and skip the download, if possible, to avoid accessing the Project Gutenberg server unnecessarily.</p>
<p>To write our data frame to disk we will export it into a standard plain-text format for two-dimensional datasets: a CSV file (comma-separated value). The CSV structure for this dataset will look like this:</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-csv-snippet_7fbfd9200b88aa1b0d0694d753345b97">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">works_pr</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">format_csv</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The first line contains the names of the columns and subsequent lines the observations. Data points that contain commas themselves (e.g.&nbsp;“Shaw, Bernard”) are quoted to avoid misinterpreting these commas a deliminators in our data. To write this dataset to disk we will use the <code>reader::write_csv()</code> function.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-write-csv-brit_203efab61db94ceb3bb0361412871a85">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">write_csv</span><span class="op">(</span><span class="va">works_pr</span>, file <span class="op">=</span> <span class="st">"../data/original/gutenberg_works_pr.csv"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="web-scraping" class="level3" data-number="5.3.2"><h3 data-number="5.3.2" class="anchored" data-anchor-id="web-scraping">
<span class="header-section-number">5.3.2</span> Web scraping</h3>
<p>There are many resources available through manual and direct downloads from repositories and individual sites and R package interfaces to web resources with APIs, but these resources are relatively limited to the amount of public-facing textual data recorded on the web. In the case that you want to acquire data from webpages, R can be used to access the web programmatically through a process known as web scraping. The complexity of web scrapes can vary but in general it requires more advanced knowledge of R as well as the structure of the language of the web: HTML (Hypertext Markup Language).</p>
<section id="a-toy-example" class="level4"><h4 class="anchored" data-anchor-id="a-toy-example">A toy example</h4>
<p>HTML is a cousin of XML (eXtensible Markup Language) and as such organizes web documents in a hierarchical format that is read by your browser as you navigate the web. Take for example the toy webpage I created as a demonstration in <a href="#fig-ad-example-webpage">Figure&nbsp;<span>5.3</span></a>.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/fig-ad-example-webpage_4736f4afea21ae4c6e5f22afbc1c795e">
<div class="cell-output-display">
<div id="fig-ad-example-webpage" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="figures/acquire-data/example-webpage.png" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;5.3: Example web page.</figcaption></figure>
</div>
</div>
</div>
<p>The file accessed by my browser to render this webpage is <code>test.html</code> and in plain-text format looks like this:</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-html-structure_b188ee618656f08af31d2e4e875b38ec">
<div class="cell-output cell-output-stdout">
<pre><code>
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;My website&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div class="intro"&gt;
      &lt;p&gt;Welcome!&lt;/p&gt;
      &lt;p&gt;This is my first website. &lt;/p&gt;
    &lt;/div&gt;
    &lt;table&gt;
      &lt;tr&gt;
        &lt;td&gt;Contact me:&lt;/td&gt;
        &lt;td&gt;
          &lt;a href="mailto:francojc@wfu.edu"&gt;francojc@wfu.edu&lt;/a&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
    &lt;/table&gt;
    &lt;div class="conc"&gt;
      &lt;p&gt;Good-bye!&lt;/p&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;</code></pre>
</div>
</div>
<p>Each element in this file is delineated by an opening and closing tag, <code>&lt;head&gt;&lt;/head&gt;</code>. Tags are nested within other tags to create the structural hierarchy. Tags can take class and id labels to distinguish them from other tags and often contain other attributes that dictate how the tag is to behave when rendered visually by a browser. For example, there are two <code>&lt;div&gt;</code> tags in our toy example: one has the label <code>class = "intro"</code> and the other <code>class = "conc"</code>. <code>&lt;div&gt;</code> tags are often used to separate sections of a webpage that may require special visual formatting. The <code>&lt;a&gt;</code> tag, on the other hand, creates a web link. As part of this tag’s function, it requires the attribute <code>href=</code> and a web protocol –in this case it is a link to an email address <code>mailto:francojc@wfu.edu</code>. More often than not, however, the <code>href=</code> contains a URL (Uniform Resource Locator). A working example might look like this: <code>&lt;a href="https://francojc.github.io/"&gt;My homepage&lt;/a&gt;</code>.</p>
<p>The aim of a web scrape is to download the HTML file, parse the document structure, and extract the elements containing the relevant information we wish to capture. Let’s attempt to extract some information from our toy example. To do this we will need the <a href="https://CRAN.R-project.org/package=rvest">rvest</a><span class="citation" data-cites="R-rvest">(<a href="references.html#ref-R-rvest" role="doc-biblioref">Wickham 2022</a>)</span> package. First, install/load the package, then, read and parse the HTML from the character vector named <code>web_file</code> assigning the result to <code>html</code>.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-read-html-toy_b56161b8a56de125885cdf9d10001edc">
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">pacman</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="va">rvest</span><span class="op">)</span> <span class="co"># install/ load `rvest`</span></span>
<span></span>
<span><span class="va">html</span> <span class="op">&lt;-</span> <span class="fu">read_html</span><span class="op">(</span><span class="va">web_file</span><span class="op">)</span> <span class="co"># read raw html and parse to xml</span></span>
<span><span class="va">html</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; {html_document}
&gt; &lt;html&gt;
&gt; [1] &lt;head&gt;\n&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8 ...
&gt; [2] &lt;body&gt;\n    &lt;div class="intro"&gt;\n      &lt;p&gt;Welcome!&lt;/p&gt;\n      &lt;p&gt;This is  ...</code></pre>
</div>
</div>
<p><code>read_html()</code> parses the raw HTML into an object of class <code>xml_document</code>. The summary output above shows that tags the HTML structure have been parsed into ‘elements’. The tag elements can be accessed by using the <code>html_elements()</code> function by specifying the tag to isolate.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-parse-html-toy-1_025de27ab7af38d2b2fb792c8afc0b7e">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">html</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">html_elements</span><span class="op">(</span><span class="st">"div"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; {xml_nodeset (2)}
&gt; [1] &lt;div class="intro"&gt;\n      &lt;p&gt;Welcome!&lt;/p&gt;\n      &lt;p&gt;This is my first web ...
&gt; [2] &lt;div class="conc"&gt;\n      &lt;p&gt;Good-bye!&lt;/p&gt;\n    &lt;/div&gt;</code></pre>
</div>
</div>
<p>Notice that <code>html_elements("div")</code> has returned both <code>div</code> tags. To isolate one of tags by its class, we add the class name to the tag separating it with a <code>.</code>.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-parse-html-toy-2_0872764a7579e93e49b21bbf248765f8">
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">html</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">html_elements</span><span class="op">(</span><span class="st">"div.intro"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; {xml_nodeset (1)}
&gt; [1] &lt;div class="intro"&gt;\n      &lt;p&gt;Welcome!&lt;/p&gt;\n      &lt;p&gt;This is my first web ...</code></pre>
</div>
</div>
<p>Great. Now say we want to drill down and isolate the subordinate <code>&lt;p&gt;</code> nodes. We can add <code>p</code> to our node filter.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-parse-html-toy-3_b13158b97aae13dd5f6563d15d4ed66e">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">html</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">html_elements</span><span class="op">(</span><span class="st">"div.intro p"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; {xml_nodeset (2)}
&gt; [1] &lt;p&gt;Welcome!&lt;/p&gt;
&gt; [2] &lt;p&gt;This is my first website. &lt;/p&gt;</code></pre>
</div>
</div>
<p>To extract the text contained within a node we use the <code>html_text()</code> function.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-parse-html-toy-4_4766c591e2f81262d33397ba504ed994">
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">html</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">html_elements</span><span class="op">(</span><span class="st">"div.intro p"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">html_text</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; [1] "Welcome!"                   "This is my first website. "</code></pre>
</div>
</div>
<p>The result is a character vector with two elements corresponding to the text contained in each <code>&lt;p&gt;</code> tag. If you were paying close attention you might have noticed that the second element in our vector includes extra whitespace after the period. To trim leading and trailing whitespace from text we can add the <code>trim = TRUE</code> argument to <code>html_text()</code>.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-parse-html-toy-5_d9f3750fe61c34fff2a5e4e2c4caa814">
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">html</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">html_elements</span><span class="op">(</span><span class="st">"div.intro p"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">html_text</span><span class="op">(</span>trim <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; [1] "Welcome!"                  "This is my first website."</code></pre>
</div>
</div>
<p>From here we would then work to organize the text into a format we want to store it in and write the results to disk. Let’s leave writing data to disk for later in the chapter. For now keep our focus on working with <code>rvest</code> to acquire data from html documents working with a more practical example.</p>
</section><section id="a-practical-example" class="level4"><h4 class="anchored" data-anchor-id="a-practical-example">A practical example</h4>
<!-- update: change website to scrape -->
<!-- remember to remove `eval = FALSE` from code chunks to run -->
<p>With some basic understanding of HTML and how to use the <code>rvest</code> package, let’s turn to a realistic example.</p>
<p>Say we want to acquire … . The first step in any web scrape is to investigate the site and page(s) we want to scrape to ascertain if there any licensing restrictions. Many, but not all websites, will include a plain text file <a href="https://www.cloudflare.com/learning/bots/what-is-robots.txt/"><code>robots.txt</code></a> at the root of the main URL. This file is declares which webpages a ‘robot’ (including web scraping scripts) can and cannot access. We can use the <code>robotstxt</code> package to find out which URLs are accessible <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<!-- change domain -->
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-web-permissions_cd1eb8038877680dcfb733d69cd7cfdd">
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">pacman</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="va">robotstxt</span><span class="op">)</span> <span class="co"># load/ install `robotstxt`</span></span>
<span></span>
<span><span class="co"># paths_allowed(paths = "https://www.last.fm/") # check permissions</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<!-- screenshot of page to scrape -->
<p>The next step includes identifying the URL we want to target and exploring the structure of the HTML document. Take the following webpage I have identified, seen in <span class="quarto-unresolved-ref">?fig-ad-example-lyrics-page-lastfm</span>.</p>
<p>As in our toy example, first we want to feed the HTML web address to the <code>read_html()</code> function to parse the tags into elements. We will then assign the result to <code>html</code>.</p>
<!-- rvest::read_html() -->
<!-- show code, but don't evaluate -->
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-read-page-lyrics-lastfm_e2b7ab1087cbee3ec93ccff974141562">
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># read and parse html as an xml object</span></span>
<span><span class="va">lyrics_url</span> <span class="op">&lt;-</span> <span class="st">"https://www.last.fm/music/Radiohead/_/Karma+Police/+lyrics"</span></span>
<span><span class="va">html</span> <span class="op">&lt;-</span> <span class="fu">read_html</span><span class="op">(</span><span class="va">lyrics_url</span><span class="op">)</span> <span class="co"># read raw html and parse to xml</span></span>
<span><span class="va">html</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<!-- show html object -->
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-print-html-lyrics-lastfm_cb8f293670c0dc2a8268c56001e40ad4">
<div class="cell-output cell-output-stdout">
<pre><code>&gt; {html_document}
&gt; &lt;html lang="en" class="
&gt;         no-js
&gt;         playbar-masthead-release-shim
&gt;         youtube-provider-not-ready
&gt;     "&gt;
&gt; [1] &lt;head&gt;\n&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8 ...
&gt; [2] &lt;body&gt;\n&lt;div id="initial-tealium-data" data-require="tracking/tealium-uta ...</code></pre>
</div>
</div>
<p>At this point we have captured and parsed the raw HTML assigning it to the object named <code>html</code>. The next step is to identify the html elements that contain the information we want to extract from the page. To do this it is helpful to use a browser to inspect specific elements of the webpage. Your browser will be equipped with a command that you can enable by hovering your mouse over the element of the page you want to target and using a right click to select “Inspect” (Chrome) or “Inspect Element” (Safari, Brave). This will split your browser window vertical or horizontally showing you the raw HTML underlying the webpage.</p>
<!-- change class/ tag/ attribute appropriately -->
<p>From <span class="quarto-unresolved-ref">?fig-ad-inspect-element-artist-lastfm</span> we see that the element we want to target is contained within an <code>&lt;a&gt;&lt;/a&gt;</code> tag. Now this tag is common and we don’t want to extract every <code>a</code> so we use the class <code>header-new-crumb</code> to specify we only want the artist name. Using the convention described in our toy example, we can isolate the artist of the lyrics page.</p>
<!-- change class/ tag/ attribute appropriately -->
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-extract-artist-lastfm-1_ed9120712e5c1727d0e05fdf8226fde2">
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">html</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">html_element</span><span class="op">(</span><span class="st">"a.header-new-crumb"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can then extract the text with <code>html_text()</code>.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-extract-artist-lastfm-2_4cc8c16f6841372bdbe52374d7de4b78">
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">artist</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">html</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">html_element</span><span class="op">(</span><span class="st">"a.header-new-crumb"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">html_text</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">artist</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s extract the song title in the same way.</p>
<!-- change class/ tag/ attribute appropriately -->
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-extract-song-title_b6b7cbbcd7d82759863630136d35c5a6">
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">song</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">html</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">html_element</span><span class="op">(</span><span class="st">"h1.header-new-title"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">html_text</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">song</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now if we inspect the HTML of the lyrics page, we will notice that the lyrics are contained in <code>&lt;p&gt;&lt;/p&gt;</code> tags with the class <code>lyrics-paragraph</code>.</p>
<p>Since there are multiple elements that we want to extract, we will need to use the <code>html_elements()</code> function instead of the <code>html_element()</code> which only targets one element.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-extract-lyrics_379c477d444d9867992e610baa0d5569">
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lyrics</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">html</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">html_elements</span><span class="op">(</span><span class="st">"p.lyrics-paragraph"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">html_text</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">lyrics</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>At this point, we have isolated and extracted the artist, song, and lyrics from the webpage. Each of these elements are stored in character vectors in our R session. To complete our task we need to write this data to disk as plain text. With an eye towards a tidy dataset, an ideal format to store the data is in a CSV file where each column corresponds to one of the elements from our scrape and each row an observation. A CSV file is a tabular format and so before we can write the data to disk let’s coerce the data that we have into tabular format. We will use the <code>tibble()</code> function here to streamline our data frame creation. <a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> Feeding each of the vectors <code>artist</code>, <code>song</code>, and <code>lyrics</code> as arguments to <code>tibble()</code> creates the tabular format we are looking for.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-create-tibble-lastfm-1_518fe2e35497299d10c1bb823a45e7f1">
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">tibble</span><span class="op">(</span><span class="va">artist</span>, <span class="va">song</span>, <span class="va">lyrics</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">glimpse</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Notice that there are seven rows in this data frame, one corresponding to each paragraph in <code>lyrics</code>. R has a bias towards working with vectors of the same length. As such each of the other vectors (<code>artist</code>, and <code>song</code>) are replicated, or recycled, until they are the same length as the longest vector <code>lyrics</code>, which a length of seven.</p>
<p>For good documentation let’s add our object <code>lyrics_url</code> to the data frame, which contains the actual web link to this page, and assign the result to <code>song_lyrics</code>.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-create-tibble-lastfm-2_800bb48f74fb437960d5163796883bfc">
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">song_lyrics</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span><span class="va">artist</span>, <span class="va">song</span>, <span class="va">lyrics</span>, <span class="va">lyrics_url</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The final step is to write this data to disk. To do this we will use the <code>write_csv()</code> function.</p>
<!-- adjust target file -->
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-write-csv-lastfm_e2415299be5d05cb56fa907edc41efa3">
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">write_csv</span><span class="op">(</span>x <span class="op">=</span> <span class="va">song_lyrics</span>, path <span class="op">=</span> <span class="st">"../data/original/lyrics.csv"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="scaling-up" class="level4"><h4 class="anchored" data-anchor-id="scaling-up">Scaling up</h4>
<p>At this point you may be think, ‘Great, I can download data from a single page, but what about downloading multiple pages?’ Good question. That’s really where the strength of a programming approach takes hold. Extracting information from multiple pages is not fundamentally different than working with a single page. However, it does require more sophisticated understanding of the web and R coding strategies, in particular <strong>iteration</strong>.</p>
<p>Before we get to iteration, let’s first create a couple functions to make it possible to efficiently reuse the code we have developed so far:</p>
<ol type="1">
<li>the <code>get_lyrics</code> function wraps the code for scraping a single lyrics webpage from last.fm.</li>
</ol>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-get-lyrics-function_9d8e0e6263081beab8a120f9653f519f">
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">get_lyrics</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">lyrics_url</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Function: Scrape last.fm lyrics page for: artist, song, </span></span>
<span>  <span class="co"># and lyrics from a provided content link. </span></span>
<span>  <span class="co"># Return as a tibble/data.frame</span></span>
<span>  </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Scraping song lyrics from:"</span>, <span class="va">lyrics_url</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="fu">pacman</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="va">tidyverse</span>, <span class="va">rvest</span><span class="op">)</span> <span class="co"># install/ load package(s)</span></span>
<span>  </span>
<span>  <span class="va">url</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/connections.html">url</a></span><span class="op">(</span><span class="va">lyrics_url</span>, <span class="st">"rb"</span><span class="op">)</span> <span class="co"># open url connection </span></span>
<span>  <span class="va">html</span> <span class="op">&lt;-</span> <span class="fu">read_html</span><span class="op">(</span><span class="va">url</span><span class="op">)</span> <span class="co"># read and parse html as an xml object</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/connections.html">close</a></span><span class="op">(</span><span class="va">url</span><span class="op">)</span> <span class="co"># close url connection</span></span>
<span>  </span>
<span>  <span class="va">artist</span> <span class="op">&lt;-</span> </span>
<span>    <span class="va">html</span> <span class="op">|&gt;</span> </span>
<span>    <span class="fu">html_element</span><span class="op">(</span><span class="st">"a.header-new-crumb"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>    <span class="fu">html_text</span><span class="op">(</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">song</span> <span class="op">&lt;-</span> </span>
<span>    <span class="va">html</span> <span class="op">|&gt;</span> </span>
<span>    <span class="fu">html_element</span><span class="op">(</span><span class="st">"h1.header-new-title"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>    <span class="fu">html_text</span><span class="op">(</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">lyrics</span> <span class="op">&lt;-</span> </span>
<span>    <span class="va">html</span> <span class="op">|&gt;</span> </span>
<span>    <span class="fu">html_elements</span><span class="op">(</span><span class="st">"p.lyrics-paragraph"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>    <span class="fu">html_text</span><span class="op">(</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"...one moment "</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html">Sys.sleep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span> <span class="co"># sleep for 1 second to reduce server load</span></span>
<span>  </span>
<span>  <span class="va">song_lyrics</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span><span class="va">artist</span>, <span class="va">song</span>, <span class="va">lyrics</span>, <span class="va">lyrics_url</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"... done! \n"</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">song_lyrics</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Tip</strong></p>
<p>The <code>get_lyrics</code> function includes all of the code developed previously, but also includes: (1) output messages (<code><a href="https://rdrr.io/r/base/cat.html">cat()</a></code>), (2) a processing pause (<code><a href="https://rdrr.io/r/base/Sys.sleep.html">Sys.sleep()</a></code>), and (3) code to manage opening and closing web connections (<code><a href="https://rdrr.io/r/base/connections.html">url()</a></code> and <code><a href="https://rdrr.io/r/base/connections.html">close()</a></code>).</p>
<p>Points (1) and (2) will be useful when we iterate over this function to provide status messages and to reduce server load when processing multiple webpages from a web domain. (3) will be necessary to manage webpages that are non-existent. As we will see, we will generate url link to multiple song lyrics some of which will not be valid. To avoid errors that will stop the processing these steps have been incorporated here.</p>
</div>
</div>
<ol start="2" type="1">
<li>the <code>write_content</code> writes the webscraped data to our local machine, including functionality to create the necessary directory structure of the target file path we choose.</li>
</ol>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-write-content-function_25be71e4e8fd439c0c26b6ee206db188">
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">write_content</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">content</span>, <span class="va">target_file</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Function: Write the tibble content to disk. Create the directory if</span></span>
<span>  <span class="co"># it does not already exist.</span></span>
<span>  </span>
<span>  <span class="fu">pacman</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="va">tidyverse</span><span class="op">)</span> <span class="co"># install/ load packages</span></span>
<span>  </span>
<span>  <span class="va">target_dir</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/basename.html">dirname</a></span><span class="op">(</span><span class="va">target_file</span><span class="op">)</span> <span class="co"># identify target file directory structure</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/files2.html">dir.create</a></span><span class="op">(</span>path <span class="op">=</span> <span class="va">target_dir</span>, recursive <span class="op">=</span> <span class="cn">TRUE</span>, showWarnings <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="co"># create directory</span></span>
<span>  <span class="fu">write_csv</span><span class="op">(</span><span class="va">content</span>, <span class="va">target_file</span><span class="op">)</span> <span class="co"># write csv file to target location</span></span>
<span>  </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Content written to disk!\n"</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With just these two functions, we can take a lyrics URL from last.fm and scrape and write the data to disk like this.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-get-write-single-lyric-lastfm_0dcf521a1baa022d009288459559cee1">
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lyrics_url</span> <span class="op">&lt;-</span> <span class="st">"https://www.last.fm/music/Pixies/_/Where+Is+My+Mind%3F/+lyrics"</span></span>
<span></span>
<span><span class="va">lyrics_url</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">get_lyrics</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">write_content</span><span class="op">(</span>target_file <span class="op">=</span> <span class="st">"../data/original/lastfm/lyrics.csv"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="sourceCode" id="cb48"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="ex">data/original/lastfm/</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="ex">└──</span> lyrics.csv</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Now we could manually search and copy URLs and run this function pipeline. This would be fine if we had just a few particular URLs that we wanted to scrape. But if we want to, say, scrape a set of lyrics grouped by genre. We would probably want a more programmatic approach. The good news is we can leverage our understanding of webscraping to scrape last.fm to harvest the information needed to create and store links to songs by genre. We can then pass these links to a pipeline, similar to the previous one, to scrape lyrics for many songs and store the results in files grouped by genre.</p>
<p>Last.fm provides a genres page where some of the top genres are listed and can be further explored.</p>
<p>Diving into a a particular genre, ‘rock’ for example, you will get a listing of the top tracks in that genre.</p>
<p>If we inspect the HTML elements for the track names in <span class="quarto-unresolved-ref">?fig-ad-genre-tracks-list-lastfm</span>, we can see that a relative URL is found for the track. In this case, I have ‘Smells Like Teen Spirit’ by Nirvana highlighted in the inspector. If we follow this link to the track page and then to the lyrics for the track, you will notice that the relative URL on the track listings page has all the unique information. Only the web domain <code>https://www.last.fm</code> and the post-pended <code>/+lyrics</code> is missing.</p>
<p>So with this we can put together a function which gets the track listing for a last.fm genre, scrapes the relative URLs for each of the tracks, and creates a full absolute URL to the lyrics page.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-get-genre-lyrics-url-lastfm_d5cca5be69a29c2d5bebdc61bd2af675">
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">get_genre_lyrics_urls</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">last_fm_genre</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Function: Scrapes a given last.fm genre title for top tracks in</span></span>
<span>  <span class="co"># that genre and then creates links to the lyrics pages for these tracks</span></span>
<span>  </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Scraping top songs from:"</span>, <span class="va">last_fm_genre</span>, <span class="st">"genre: \n"</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="fu">pacman</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="va">tidyverse</span>, <span class="va">rvest</span><span class="op">)</span> <span class="co"># install/ load packages</span></span>
<span>  </span>
<span>  <span class="co"># create web url for the genre listing page</span></span>
<span>  <span class="va">genre_listing_url</span> <span class="op">&lt;-</span> </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"https://www.last.fm/tag/"</span>, <span class="va">last_fm_genre</span>, <span class="st">"/tracks"</span><span class="op">)</span> </span>
<span>  </span>
<span>  <span class="va">genre_lyrics_urls</span> <span class="op">&lt;-</span> </span>
<span>    <span class="fu">read_html</span><span class="op">(</span><span class="va">genre_listing_url</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># read raw html and parse to xml</span></span>
<span>    <span class="fu">html_elements</span><span class="op">(</span><span class="st">"td.chartlist-name a"</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># isolate the track elements</span></span>
<span>    <span class="fu">html_attr</span><span class="op">(</span><span class="st">"href"</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># extract the href attribute</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"https://www.last.fm"</span>, <span class="va">.</span>, <span class="st">"/+lyrics"</span><span class="op">)</span> <span class="co"># join the domain, relative artist path, and the post-pended /+lyrics to create an absolute URL</span></span>
<span>  </span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">genre_lyrics_urls</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With this function, all we need is to identify the verbatim way last.fm lists the genres. For Rock, it is <code>rock</code> but for Hip Hop, it is <code>hip+hop</code>.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-demo-get-genre-lyrics-urls-lastfm_9b92137ea4dfe9e154b55a1003311b69">
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">get_genre_lyrics_urls</span><span class="op">(</span><span class="st">"hip+hop"</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># get urls for top hip hop tracks</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span> <span class="co"># only display 10 tracks</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>So now we have a method to scrape URLs by genre and list them in a vector. Our approach, then, could be to pass these lyrics URLs to our existing pipeline which downloads the lyrics (<code>get_lyrics()</code>) and then writes them to disk (<code>write_content()</code>).</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-example-genre-pipeline-lastfm-1_21ae6d7f07c528b073534ee418f75eec">
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Note: will not run</span></span>
<span><span class="fu">get_genre_lyrics_urls</span><span class="op">(</span><span class="st">"hip+hop"</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># get lyrics urls for specific genre</span></span>
<span>  <span class="fu">get_lyrics</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># scrape lyrics url</span></span>
<span>  <span class="fu">write_content</span><span class="op">(</span>target_file <span class="op">=</span> <span class="st">"../data/original/lastfm/hip_hop.csv"</span><span class="op">)</span> <span class="co"># write to disk</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This approach, however, has a couple of problems. (1) our <code>get_lyrics()</code> function only takes one URL at a time, but the result of <code>get_genre_lyrics_urls()</code> will produce many URLs. We will be able to solve this with iteration using the <a href="">purrr</a> package, specifically the <code>map()</code> function which will iteratively map each URL output from <code>get_genre_lyrics_urls()</code> to <code>get_lyrics()</code> in turn. (2) the output from our iterative application of <code>get_lyrics()</code> will produce a tibble for each URL, which then sets up a problem with writing the tibbles to disk with the <code>write_content()</code> function. To avoid this we will want to combine the tibbles into one single tibble and then send it to be written to disk. The <code>bind_rows()</code> function will do just this.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-example-genre-pipeline-lastfm-2_3cfac168fbaeb15fa352a0e0c4d84de2">
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Note: will run, but with occasional errors</span></span>
<span><span class="fu">get_genre_lyrics_urls</span><span class="op">(</span><span class="st">"hip+hop"</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># get lyrics urls for specific genre</span></span>
<span>  <span class="fu">map</span><span class="op">(</span><span class="va">get_lyrics</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># scrape lyrics url</span></span>
<span>  <span class="fu">bind_rows</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># combine tibbles into one</span></span>
<span>  <span class="fu">write_content</span><span class="op">(</span>target_file <span class="op">=</span> <span class="st">"../data/original/lastfm/hip_hop.csv"</span><span class="op">)</span> <span class="co"># write to disk</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This preceding pipeline conceptually will work. However, on my testing, it turns out that some of the URLs that are generated in the <code>get_genre_lyrics_urls()</code> do not exist on the site. That is, the song is listed but no lyrics have been added to the song site. This will mean that when the URL is sent to the <code>get_lyrics()</code> function, there will be an error when attempting to download and parse the page with <code>read_html()</code> which will halt the entire process. To avoid this error, we can wrap the <code>get_lyrics()</code> function in a function designed to attempt to download and parse the URL (<code><a href="https://rdrr.io/r/base/conditions.html">tryCatch()</a></code>), but if there is an error, it will skip it and move on to the next URL without stopping the processing. This approach is reflected in the <code>get_lyrics_catch()</code> function below.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-get-lyrics-catch-lastfm_03a9bf7e4a0994e063be94e3bd1aeff0">
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Wrap the `get_lyrics()` function with `tryCatch()` to </span></span>
<span><span class="co"># skip URLs that have no lyrics</span></span>
<span></span>
<span><span class="va">get_lyrics_catch</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">lyrics_url</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/conditions.html">tryCatch</a></span><span class="op">(</span><span class="fu">get_lyrics</span><span class="op">(</span><span class="va">lyrics_url</span><span class="op">)</span>, </span>
<span>           error <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">e</span><span class="op">)</span> <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="cn">NULL</span><span class="op">)</span><span class="op">)</span> <span class="co"># no, URL, return(NULL)/ skip</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Updating the pipeline with the <code>get_lyrics_catch()</code> function would look like this:</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-example-genre-pipeline-lastfm-3_39d60dc078cd16458cf8a392e10248f4">
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Note: will run, but we can do better</span></span>
<span><span class="fu">get_genre_lyrics_urls</span><span class="op">(</span><span class="st">"hip+hop"</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># get lyrics urls for specific genre</span></span>
<span>  <span class="fu">map</span><span class="op">(</span><span class="va">get_lyrics_catch</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># scrape lyrics url</span></span>
<span>  <span class="fu">bind_rows</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># combine tibbles into one</span></span>
<span>  <span class="fu">write_content</span><span class="op">(</span>target_file <span class="op">=</span> <span class="st">"../data/original/lastfm/hip_hop.csv"</span><span class="op">)</span> <span class="co"># write to disk</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This will work, but as we have discussed before one of this goals we have we acquiring data for a reproducible research project is to make sure that we are developing efficient code that will not burden site’s server we are scraping from. In this case, we would like to check to see if the data is already downloaded. If not, then the script should run. If so, then the script does not run. Of course this is a perfect use of a conditional statement. To make this a single function we can call, I’ve wrapped the functions we created for getting lyric URLs from last.fm, scraping the URLs, and writing the results to disk in the <code>download_lastfm_lyrics()</code> function below. I also added a line to add a <code>last_fm_genre</code> column to the combined tibble to store the name of the genre we scraped (i.e.&nbsp;<code>mutate(genre = last_fm_genre)</code>.</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-download-lyrics-lastfm-function_5efa5b245d1ae1c466895ed36bafb0db">
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">download_lastfm_lyrics</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">last_fm_genre</span>, <span class="va">target_file</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Function: get last.fm lyric urls by genre and write them to disk</span></span>
<span>  </span>
<span>  <span class="kw">if</span><span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/files.html">file.exists</a></span><span class="op">(</span><span class="va">target_file</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Downloading data.\n"</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="fu">get_genre_lyrics_urls</span><span class="op">(</span><span class="va">last_fm_genre</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>      <span class="fu">map</span><span class="op">(</span><span class="va">get_lyrics_catch</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>      <span class="fu">bind_rows</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>      <span class="fu">mutate</span><span class="op">(</span>genre <span class="op">=</span> <span class="va">last_fm_genre</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>      <span class="fu">write_content</span><span class="op">(</span><span class="va">target_file</span><span class="op">)</span></span>
<span>    </span>
<span>  <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Data already downloaded!\n"</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we can call this function on any genre on the last.fm site and download the top 50 song lyrics for that genre (provided they all have lyrics pages).</p>
<div class="cell" data-layout-align="center" data-hash="acquire-data_cache/html/ad-download-lyrics-genre-lastfm-show_a93b61236267c0a7d21305f806259836">
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Scrape lyrics for 'pop'</span></span>
<span><span class="fu">download_lastfm_lyrics</span><span class="op">(</span>last_fm_genre <span class="op">=</span> <span class="st">"pop"</span>, target_file <span class="op">=</span> <span class="st">"../data/original/lastfm/pop.csv"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Scrape lyrics for 'rock'</span></span>
<span><span class="fu">download_lastfm_lyrics</span><span class="op">(</span>last_fm_genre <span class="op">=</span> <span class="st">"rock"</span>, target_file <span class="op">=</span> <span class="st">"../data/original/lastfm/rock.csv"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Scrape lyrics for 'hip hop'</span></span>
<span><span class="fu">download_lastfm_lyrics</span><span class="op">(</span>last_fm_genre <span class="op">=</span> <span class="st">"hip+hop"</span>, target_file <span class="op">=</span> <span class="st">"../data/original/lastfm/hip_hop.csv"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Scrape lyrics for 'metal'</span></span>
<span><span class="fu">download_lastfm_lyrics</span><span class="op">(</span>last_fm_genre <span class="op">=</span> <span class="st">"metal"</span>, target_file <span class="op">=</span> <span class="st">"../data/original/lastfm/metal.csv"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we can see that our web scrape data is organized in a similar fashion to the other data we acquired in this chapter.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="ex">data/</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> derived/</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="ex">└──</span> original/</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> cedel2/</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   └── texts.csv</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> gutenberg/</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── works_pq.csv</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   └── works_pr.csv</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> lastfm/</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── country.csv</span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── hip_hop.csv</span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── lyrics.csv</span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── metal.csv</span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── pop.csv</span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   └── rock.csv</span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> sbc/</span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── meta-data/</span>
<span id="cb57-18"><a href="#cb57-18" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   └── transcriptions/</span>
<span id="cb57-19"><a href="#cb57-19" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> scs/</span>
<span id="cb57-20"><a href="#cb57-20" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── README</span>
<span id="cb57-21"><a href="#cb57-21" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── discourse</span>
<span id="cb57-22"><a href="#cb57-22" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── disfluency</span>
<span id="cb57-23"><a href="#cb57-23" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── documentation/</span>
<span id="cb57-24"><a href="#cb57-24" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── tagged</span>
<span id="cb57-25"><a href="#cb57-25" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── timed-transcript</span>
<span id="cb57-26"><a href="#cb57-26" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   └── transcript</span>
<span id="cb57-27"><a href="#cb57-27" aria-hidden="true" tabindex="-1"></a>    <span class="ex">└──</span> twitter/</span>
<span id="cb57-28"><a href="#cb57-28" aria-hidden="true" tabindex="-1"></a>        <span class="ex">└──</span> rt_latinx.csv</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Again, it is important to add these custom functions to our <code>acquire_functions.R</code> script in the <code>functions/</code> directory so we can access them in our scripts more efficiently and make our analysis steps more succinct and legible.</p>
<p>In this section we covered scraping language data from the web. The rvest package provides a host of functions for downloading and parsing HTML. We first looked at a toy example to get a basic understanding of how HTML works and then moved to applying this knowledge to a practical example. To maintain a reproducible workflow, the code developed in this example was grouped into task-oriented functions which were in turn joined and wrapped into a function that provided convenient access to our workflow and avoided unnecessary downloads (in the case the data already exists on disk).</p>
<p>Here we have built on previously introduced R coding concepts and demonstrated various others. Web scraping often requires more knowledge of and familiarity with R as well as other web technologies. Rest assured, however, practice will increase confidence in your abilities. I encourage you to practice on your own with other websites. You will encounter problems. Consult the R documentation in RStudio or online and lean on the R community on the web at sites such as <a href="https://stackoverflow.com/">Stack Overflow</a> <em>inter alia</em>.</p>
</section></section><section id="documentation" class="level3" data-number="5.3.3"><h3 data-number="5.3.3" class="anchored" data-anchor-id="documentation">
<span class="header-section-number">5.3.3</span> Documentation</h3>
<p>As part of the data acquisition process it is important include documentation that describes the data resource(s) that will serve as the base for a research project. For all resources the data should include as much information possible that outlines the sampling frame of the data <span class="citation" data-cites="Adel2020">(<a href="references.html#ref-Adel2020" role="doc-biblioref">Ädel 2020</a>)</span>. For a corpus sample acquired from a repository will often include documentation which will outline the sampling frame –this most likely will be the very information which leads a researcher to select this resource for the project at hand. It is important to include this documentation (HTML or PDF file) or reference to the documentation (article citation or link<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>) within the reproducible project’s directory structure.</p>
<p>In other cases where the data acquisition process is formulated and conducted by the researcher for the specific aims of the research (i.e.&nbsp;API and web scraping approaches), the researcher should make an effort to document those aspects which are key for the study, but that may also be of interest to other researchers for similar research questions. This will may include language characteristics such as modality, register, genre, etc., speaker/ writer characteristics such as demographics, time period(s), context of the linguistic communication, etc. and process characteristics such as the source of the data, the process of acquisition, date of acquisition, etc. However, it is important to recognize that each language sample and the resource from which it is drawn is unique. As a general rule of thumb, a researcher should document the resource as if this were a resource <em>they</em> were to encounter for the first time. To archive this information, it is standard practice to include a <code>README</code> file in the relevant directory where the data is stored.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="ex">data/</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> derived/</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="ex">└──</span> original/</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> cedel2/</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> ├── documentation/</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> └── texts.csv</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> gutenberg/</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> ├── README.md</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> ├── works_pq.csv</span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> └── works_pr.csv</span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> lastfm/</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> ├── README.md</span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> ├── country.csv</span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> ├── hip_hop.csv</span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> ├── lyrics.csv</span>
<span id="cb58-16"><a href="#cb58-16" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> ├── metal.csv</span>
<span id="cb58-17"><a href="#cb58-17" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> ├── pop.csv</span>
<span id="cb58-18"><a href="#cb58-18" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> └── rock.csv</span>
<span id="cb58-19"><a href="#cb58-19" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> sbc/</span>
<span id="cb58-20"><a href="#cb58-20" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> ├── meta-data/</span>
<span id="cb58-21"><a href="#cb58-21" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> └── transcriptions/</span>
<span id="cb58-22"><a href="#cb58-22" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> scs/</span>
<span id="cb58-23"><a href="#cb58-23" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> ├── README</span>
<span id="cb58-24"><a href="#cb58-24" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> ├── discourse</span>
<span id="cb58-25"><a href="#cb58-25" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> ├── disfluency</span>
<span id="cb58-26"><a href="#cb58-26" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> ├── documentation/</span>
<span id="cb58-27"><a href="#cb58-27" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> ├── tagged</span>
<span id="cb58-28"><a href="#cb58-28" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> ├── timed-transcript</span>
<span id="cb58-29"><a href="#cb58-29" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│&nbsp;&nbsp;</span> └── transcript</span>
<span id="cb58-30"><a href="#cb58-30" aria-hidden="true" tabindex="-1"></a>    <span class="ex">└──</span> twitter/</span>
<span id="cb58-31"><a href="#cb58-31" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> README.md</span>
<span id="cb58-32"><a href="#cb58-32" aria-hidden="true" tabindex="-1"></a>        <span class="ex">└──</span> rt_latinx.csv</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>For both existing corpora and data samples acquired by the researcher it is also important to signal if there are conditions and/ or licensing restrictions that one should heed when using and potentially sharing the data. In some cases existing corpus data come with restrictions on data sharing. These can be quite restrictive and ultimately require that the corpus data not be included in publically available reproducible project or data can only be shared in a derived format. If this the case, it is important to document the steps to legally acquire the data so that a researcher can acquire their own license and take full advantage of your reproducible project.</p>
<p>In the case of data from APIs or web scraping, there too may be stipulations on sharing data. A growing number of data sources apply one of <a href="https://creativecommons.org/about/cclicenses/">the available Creative Common Licenses</a>. Check the source of your data for more information and if you are a member of a research institution you will likely have a <a href="https://zsr.wfu.edu/digital-scholarship/copyright/">specialist</a> on <a href="https://www.copyright.gov/fair-use/more-info.html">Copyright and Fair Use</a>.</p>
</section></section><section id="summary" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="summary">Summary</h2>
<p>In this chapter we have covered a lot of ground. On the surface we have discussed three methods for acquiring corpus data for use in text analysis. In the process we have delved into various aspects of the R programming language. Some key concepts include writing custom functions and working with those function in an iterative manner. We have also considered topics that are more general in nature and concern interacting with data found on the internet.</p>
<p>Each of these methods should be approached in a way that is transparent to the researcher and to would-be collaborators and the general research community. For this reason the documentation of the steps taken to acquire data are key both in the code and in human-facing documentation.</p>
<p>At this point you have both a bird’s eye view of the data available on the web and strategies on how to access a great majority of it. It is now time to turn to the next step in our data analysis project: data curation. In the next posts I will cover how to wrangle your raw data into a tidy dataset. This will include working with and incorporating meta-data as well as augmenting a dataset with linguistic annotations.</p>
</section><section id="activities" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="activities">Activities</h2>
<ul class="task-list">
<li>
<input type="checkbox">Add description of outcomes</li>
</ul>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-file-code" aria-label="file-code"></i> Recipe</strong></p>
<!-- Understand, apply, and analyze verbs: https://tips.uark.edu/blooms-taxonomy-verb-chart/ -->
<ul class="task-list">
<li>
<input type="checkbox">update</li>
</ul>
<p><strong>What</strong>: <a href="https://lin380.github.io/tadr/articles/recipe_6.html">Control statements, custom functions, and iteration</a><br><strong>How</strong>: Read Recipe 6 and participate in the Hypothes.is online social annotation.<br><strong>Why</strong>: To increase your ability to produce effective, concise, and reproducible code. The three main areas we will cover are working with control statements, writing custom functions, and leveraging iteration. These programming strategies are often useful for acquiring data but, as we will see, they are powerful concepts that can be used throughout a reproducible research project.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-flask" aria-label="flask"></i> Lab</strong></p>
<!-- Analyze, evaluate, and create verbs: https://tips.uark.edu/blooms-taxonomy-verb-chart/ -->
<ul class="task-list">
<li>
<input type="checkbox">update</li>
</ul>
<p><strong>What</strong>: <a href="https://github.com/lin380/lab_6">Control statements, custom functions, and iteration</a><br><strong>How</strong>: Clone, fork, and complete the steps in Lab 6.<br><strong>Why</strong>: To gain experience working with coding strategies such as control statements, custom functions, and iteration, practice working with direct downloads and API interfaces to acquire data, and implement organizational strategies for organizing data in reproducible fashion.</p>
</div>
</div>
</div>
</section><section id="questions" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="questions">Questions</h2>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Conceptual questions</strong></p>
<ul>
<li>…</li>
<li>For many resources, information to describe the data origin is found on the resource’s website. Visit the XXX resource and complete the data origin information.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Technical exercises</strong></p>
<ul>
<li>…</li>
<li>…</li>
</ul>
</div>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-Adel2020" class="csl-entry" role="listitem">
Ädel, Annelie. 2020. <span>“Corpus Compilation.”</span> In <em>A Practical Handbook of Corpus Linguistics</em>, edited by Magali Paquot and Stefan Th. Gries, 3–24. Switzerland: Springer.
</div>
<div id="ref-R-fs" class="csl-entry" role="listitem">
Hester, Jim, Hadley Wickham, and Gábor Csárdi. 2023. <em>Fs: Cross-Platform File System Operations Based on Libuv</em>. <a href="https://CRAN.R-project.org/package=fs">https://CRAN.R-project.org/package=fs</a>.
</div>
<div id="ref-Lozano2009" class="csl-entry" role="listitem">
Lozano, Cristóbal. 2009. <span>“CEDEL2: Corpus Escrito Del Español L2.”</span> <em>Applied Linguistics Now: Understanding Language and Mind/La Lingüística Aplicada Hoy: Comprendiendo El Lenguaje y La Mente. Almería: Universidad de Almería</em>, 197–212.
</div>
<div id="ref-Tottie2011" class="csl-entry" role="listitem">
Tottie, Gunnel. 2011. <span>“Uh and Um as Sociolinguistic Markers in British English.”</span> <em>International Journal of Corpus Linguistics</em> 16 (2): 173–97.
</div>
<div id="ref-SWDA2008" class="csl-entry" role="listitem">
University of Colorado Boulder. 2008. <span>“Switchboard Dialog Act Corpus. Web Download.”</span> Linguistic Data Consortium.
</div>
<div id="ref-R-rvest" class="csl-entry" role="listitem">
Wickham, Hadley. 2022. <em>Rvest: Easily Harvest (Scrape) Web Pages</em>. <a href="https://CRAN.R-project.org/package=rvest">https://CRAN.R-project.org/package=rvest</a>.
</div>
</div>
</section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>See Section @ref(sources) for a list of some other API packages.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>It is important to check the paths of sub-domains as some website allow access in some areas and not in others<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><code>tibble</code> objects are <code>data.frame</code> objects with some added extra bells and whistles that we won’t get into here.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Note that web links can change and it is often best to safeguard the documentation by downloading the HTML documentation page instead of linking<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./preparation.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Preparation</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./curate-datasets.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Curate datasets</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>An Introduction to Quantitative Text Analysis for Linguistics - 8&nbsp; Exploration</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./prediction.html" rel="next">
<link href="./analysis.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script async="" src="https://hypothes.is/embed.js"></script><script src="site_libs/kePrint-0.0.1/kePrint.js"></script><link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><link rel="stylesheet" href="assets/css/mini.css">
</head>
<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./analysis.html">Analysis</a></li><li class="breadcrumb-item"><a href="./exploration.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Exploration</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">An Introduction to Quantitative Text Analysis for Linguistics</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/qtalr/book" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./qtalr-manuscript.pdf" rel="" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./orientation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Orientation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./text-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Text analysis in context</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./understanding-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Understanding data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./approaching-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Approaching analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./framing-research.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Framing research</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./preparation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preparation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./acquire-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Acquire data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./curate-datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Curate datasets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./transform-datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Transform datasets</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Analysis</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./exploration.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Exploration</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Inference</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./communication.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Communication</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reporting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Reports</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./collaboration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Collaboration</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./feedback.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Feedback <i class="fa-solid fa-comment" aria-label="comment"></i></span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#sec-eda-orientation" id="toc-sec-eda-orientation" class="nav-link active" data-scroll-target="#sec-eda-orientation"><span class="header-section-number">8.1</span> Orientation</a>
  <ul class="collapse">
<li><a href="#sec-eda-research-goal" id="toc-sec-eda-research-goal" class="nav-link" data-scroll-target="#sec-eda-research-goal"><span class="header-section-number">8.1.1</span> Research goal</a></li>
  <li><a href="#sec-eda-approach" id="toc-sec-eda-approach" class="nav-link" data-scroll-target="#sec-eda-approach"><span class="header-section-number">8.1.2</span> Approach</a></li>
  </ul>
</li>
  <li>
<a href="#sec-eda-analysis" id="toc-sec-eda-analysis" class="nav-link" data-scroll-target="#sec-eda-analysis"><span class="header-section-number">8.2</span> Analysis</a>
  <ul class="collapse">
<li><a href="#sec-eda-descriptive" id="toc-sec-eda-descriptive" class="nav-link" data-scroll-target="#sec-eda-descriptive"><span class="header-section-number">8.2.1</span> Descriptive analysis</a></li>
  <li><a href="#sec-eda-unsupervised" id="toc-sec-eda-unsupervised" class="nav-link" data-scroll-target="#sec-eda-unsupervised"><span class="header-section-number">8.2.2</span> Unsupervised learning</a></li>
  </ul>
</li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">8.3</span> Summary</a></li>
  <li><a href="#activities" id="toc-activities" class="nav-link" data-scroll-target="#activities">Activities</a></li>
  <li><a href="#questions" id="toc-questions" class="nav-link" data-scroll-target="#questions">Questions</a></li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/qtalr/book/edit/main/exploration.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/qtalr/book/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title"><span id="sec-exploration" class="quarto-section-identifier"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Exploration</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><div class="callout callout-style-default callout-caution callout-titled" title="Caution">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>Under development.</p>
</div>
</div>
<!--

Content:

Bxploratory Data Analysis (EDA) is a set of methods used for analyzing and exploring text data in the areas of text analysis and corpus linguistics. Descriptive methods commonly used in EDA include data visualization, word frequency and distribution analysis, and collocation analysis. These methods help identify common words and phrases, as well as relationships between different elements in the text. 

Additionally, unsupervised learning methods such as clustering, topic modeling, semantic analysis, and word embedding are used in EDA. These techniques help group similar items, extract topics, understand content, and represent words as numerical vectors for various tasks.



Descriptive analysis:
- `tidytext` package
    - `unnest_tokens()` function
    - `count()` function
    - `bind_tf_idf()` function
    - `widyr` package for co-occurrence analysis
    - `tidy()`
  
- `quanteda` package
  - `dfm()` objects
    - matrix subsetting `[, ]`
    - `dfm_select()`, `dfm_trim()`, `dfm_remove()`, `dfm_keep()`, `dfm_sample()

Unsupervised learning:
- `cluster()`, `factoextra` package
- `kmeans()`, `factoextra` package
- `hclust()`, `factoextra` package
- `topicmodels` package
- `text2vec` package

Exercises:

- [ ] add concept questions to Activities
- [ ] add exercises to Activities
- [ ] add thought questions/ case studies to prose sections

Formatting:

-->
<!---
> The real voyage of discovery consists not in seeking new landscapes, but in having new eyes.
> 
> --- Marcel Proust 
--->
<blockquote class="blockquote">
<p>The data speaks for itself, but only if we are willing to listen.</p>
<p>— Nate Silver</p>
</blockquote>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-list-alt" aria-label="list-alt"></i> Outcomes</strong></p>
<!-- Remember and understand verbs: https://tips.uark.edu/blooms-taxonomy-verb-chart/ -->
<ul>
<li>Identify when an exploratory data analysis approach is the best fit for a given research project.</li>
<li>Describe the fundamental methods of descriptive analysis and unsupervised learning, recognizing their strengths in revealing patterns and summarizing data.</li>
<li>Interpret the basic insights gained from data summarization and pattern recognition, considering how these insights could guide further questions or research.</li>
</ul>
</div>
</div>
</div>
<p>In this chapter, we examine a wide range of strategies for deriving insight from data in cases where the researcher does not start with a preconceived hypothesis or prediction, but rather the researcher aims to uncover patterns and associations from data allowing the data to guide the trajectory of the analysis. The chapter outlines two main branches of exploratory data analysis: 1) descriptive analysis which statistically and/ or visually summarizes a dataset and 2) unsupervised learning which is a machine learning approach that does not assume any particular relationship between variables in a dataset. Either through descriptive or unsupervised learning methods, exploratory data analysis employs quantitative methods to summarize, reduce, and sort complex datasets and statistically and visually interrogate a dataset in order to provide the researcher novel perspective to be qualitatively assessed.</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-terminal" aria-label="terminal"></i> Lessons</strong></p>
<!-- Remember and understand verbs: https://tips.uark.edu/blooms-taxonomy-verb-chart/ -->
<!-- [ ] lesson: update the why -->
<p><strong>What</strong>: <a href="https://github.com/qtalr/lessons">Matrices, Exploratory Visualization</a><br><strong>How</strong>: In the R Console pane load <code>swirl</code>, run <code>swirl()</code>, and follow prompts to select the lesson.<br><strong>Why</strong>: Learn how to work with matrices to store and analyze numeric data using <code>quanteda</code> and to further your understanding of graphically representing data using <code>ggplot2</code> and other packages for more advanced plotting.</p>
</div>
</div>
</div>
<section id="sec-eda-orientation" class="level2" data-number="8.1"><h2 data-number="8.1" class="anchored" data-anchor-id="sec-eda-orientation">
<span class="header-section-number">8.1</span> Orientation</h2>
<p>The aim of this section is to provide an overview of exploratory data analysis (EDA). We will delve into various descriptive methods, such as frequency analysis and co-occurrence analysis, which are fundamental tools in linguistic research. However, our exploration won’t stop there. We will also integrate modern exploratory methods from unsupervised learning approaches, including clustering, topic modeling, and vector space modeling. This may sound overwhelming, but I will strive to keep explanations clear and concise, ensuring their practicality and relevance to your linguistic inquiries is apparent. To this end, we will provide real-world examples to exemplify the applicability of these methodologies.</p>
<section id="sec-eda-research-goal" class="level3" data-number="8.1.1"><h3 data-number="8.1.1" class="anchored" data-anchor-id="sec-eda-research-goal">
<span class="header-section-number">8.1.1</span> Research goal</h3>
<p>As discussed in <a href="approaching-analysis.html#sec-aa-explore"><span>Section&nbsp;3.2.1</span></a> and <a href="framing-research.html#sec-fr-aim"><span>Section&nbsp;4.3.1</span></a>, the goal of exploratory data analysis is to discover, describe, and posit new hypotheses. The researcher does not start with a preconceived hypothesis or prediction, but rather the researcher aims to uncover patterns and associations from data allowing the data to guide the trajectory of the analysis. This analysis approach is best-suited for research where the literature on a research question is limited, or where the researcher is interested in exploring a new research question.</p>
<p>Since the researcher does not start with a preconceived hypothesis, the researcher is not able to test a hypothesis and generalize to a population, but rather the researcher is able to describe the data and provide a new perspective to be qualitatively assessed. This is achieved through an iterative and inductive process of data exploration, where the researcher uses quantitative methods to summarize, reduce, and sort complex datasets and statistically and visually interrogate a dataset letting the data guide the analysis.</p>
</section><section id="sec-eda-approach" class="level3" data-number="8.1.2"><h3 data-number="8.1.2" class="anchored" data-anchor-id="sec-eda-approach">
<span class="header-section-number">8.1.2</span> Approach</h3>
<!-- Note:  

This section should cover the following:
- Workflow: Identify, Inspect, Interrogate, Interpret
  - Add a few words on the common aspects with other research approaches
  - And point out the differences (use of data, results, interpretation, etc.)

Drop the independent sections in favor of a more integrated approach.
-->
<p>The approach to exploratory data analysis is iterative and inductive. To reign in the analysis, however, it is important to have a research question to guide the analysis. The research question will often be broad and exploratory in nature, but it will provide a framework for the analysis including the unit of analysis and sometimes the units of observation. Yet the units of observation can be modified as needed to address the research question. Furthermore, the methods applied to the data can evolve as the research unfolds. The researcher may start with a descriptive analysis and then move to an unsupervised learning approach, or vice versa. The researcher may also pivot the approach to explore new questions and new variables. Ultimately, the researcher is guided by the data and the research question, but the researcher is not bound by a preconceived hypothesis or prediction.</p>
<!-- Workflow -->
<p>With a research question and relevant data in hand, we can look to conduct the analysis. The workflow for exploratory data analysis is as follows:</p>
<ol type="1">
<li>Identify and extract the variables of interest in the dataset</li>
<li>Inspect the dataset to ensure the quality of the data and understand its characteristics</li>
<li>Interrogate the dataset using descriptive analysis and/ or unsupervised learning</li>
<li>Interpret the results of the analysis to determine if they are meaningful and if they provide a new perspective on the research question</li>
<li>(Optional) Pivot and repeat steps 1-4 to explore new questions and new variables</li>
</ol>
<p>Let’s elaborate on each of these steps. First, we want to consider our research question and identify the variables of potential interest to provide insight to our question. Starting with a transformed dataset means that much of the data preparation has already been done, but we may need to further transform the data, either up front or as we explore the data. In text analysis, this often includes identifying and extracting the linguistic variables of interest, such as words, <span class="math inline">\(n\)</span>-grams, sentences, <em>etc</em>. Depending on the annotation scheme, other linguistic variables may be of interest, such as part-of-speech tags, syntactic dependencies, semantic roles, <em>etc</em>.</p>
<p>We may also want to consider the operational measures of the variables derived from the text, such as frequency, dispersion, co-occurrence, keyness, <em>etc</em>. We may also want to consider the other variables in the dataset that may be target for grouping or filtering the dataset, such as speaker information, document information, linguistic unit information, <em>etc</em>.</p>
<p>During or after extracting and operationalizing the variables of interest, we want to inspect the dataset to ensure the quality of the data and understand its characteristics. This may include checking for missing data, checking for outliers, checking for errors, checking for inconsistencies, <em>etc</em>. We may also want to inspect the distribution of the variables of interest to understand their characteristics. Summary statistics and visualizations, such as those covered in <a href="approaching-analysis.html#sec-aa-diagnose"><span>Section&nbsp;3.1</span></a>, are useful for inspecting the dataset and also provide a foundation for interrogating the dataset.</p>
<p>Once we have identified the variables of interest and inspected the dataset, we can interrogate the dataset using descriptive analysis and/ or unsupervised learning. Descriptive analysis is a set of methods that statistically and/ or visually summarizes a dataset. Descriptive analysis can be used to describe a dataset and to identify linguistic units (frequency analysis) or co-occuring (co-occurrence analysis) units that are distinctive to a particular group or sub-group in the dataset. Unsupervised learning is a machine learning approach that does not assume any particular relationship between variables in a dataset. It can be used to identify groupings (clustering) in the data including patterning of linguistic units, identifying semantically similar topics (topic modeling), and estimating word context relationships (vector space modeling).</p>
<!-- Interpret -->
<p>Exploratory methods will produce a set of statistical and/ or visual results. The researcher must interpret these results to determine if they are meaningful and if they provide a new perspective on the research question. Many times the results from one method will lead to new questions which can be explored with other methods. In some cases, the results may not be meaningful and the researcher may need to return to the data preparation stage to modify the dataset or the variables of interest. As the aim of exploratory analysis is just that, to explore, the researcher can pivot the approach to explore new questions and new variables. Ultimately, what is meaningful is determined by the researcher in the light of the research question and the potential insight obtained from the results.</p>
</section></section><section id="sec-eda-analysis" class="level2" data-number="8.2"><h2 data-number="8.2" class="anchored" data-anchor-id="sec-eda-analysis">
<span class="header-section-number">8.2</span> Analysis</h2>
<p>In this section will discuss exploratory data analysis (EDA) for linguists, with a focus on descriptive methods such as frequency analysis and co-occurence analysis, as well as unsupervised learning approaches such as clustering, topic modelling, and word embedding. To ground the discussion, we will use the the Manually Annotated Sub-Corpus (MASC) of the American National Corpus. The data dictionary for the <code>masc_transformed</code> dataset is shown in <a href="#tbl-eda-masc-dd-show">Table&nbsp;<span>8.1</span></a>.</p>
<!-- Show data dictionary -->
<div class="cell" data-hash="exploration_cache/html/tbl-eda-masc-dd-show_12565e1f1bc74536025b1dc8e3fd1596">
<div class="cell-output-display">
<div id="tbl-eda-masc-dd-show" class="anchored">
<table class="table table-sm table-striped small" data-quarto-postprocess="true">
<caption>Table&nbsp;8.1: Data dictionary for the MASC dataset.</caption>
<thead><tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">variable</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">name</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">variable_type</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">doc_id</td>
<td style="text-align: left;">Document ID</td>
<td style="text-align: left;">numeric</td>
<td style="text-align: left;">Unique identifier for each document</td>
</tr>
<tr class="even">
<td style="text-align: left;">description</td>
<td style="text-align: left;">Description</td>
<td style="text-align: left;">categorical</td>
<td style="text-align: left;">Description of the content of the document</td>
</tr>
<tr class="odd">
<td style="text-align: left;">modality</td>
<td style="text-align: left;">Modality</td>
<td style="text-align: left;">categorical</td>
<td style="text-align: left;">The form in which the document is presented (written or spoken)</td>
</tr>
<tr class="even">
<td style="text-align: left;">genre</td>
<td style="text-align: left;">Genre</td>
<td style="text-align: left;">categorical</td>
<td style="text-align: left;">The category or type of the document</td>
</tr>
<tr class="odd">
<td style="text-align: left;">domain</td>
<td style="text-align: left;">Domain</td>
<td style="text-align: left;">categorical</td>
<td style="text-align: left;">The subject or field to which the document belongs</td>
</tr>
<tr class="even">
<td style="text-align: left;">token_num</td>
<td style="text-align: left;">Token Number</td>
<td style="text-align: left;">numeric</td>
<td style="text-align: left;">Index number token per document</td>
</tr>
<tr class="odd">
<td style="text-align: left;">token</td>
<td style="text-align: left;">Token</td>
<td style="text-align: left;">categorical</td>
<td style="text-align: left;">Individual word forms in the document</td>
</tr>
<tr class="even">
<td style="text-align: left;">lemma</td>
<td style="text-align: left;">Lemma</td>
<td style="text-align: left;">categorical</td>
<td style="text-align: left;">Base or dictionary form of the token</td>
</tr>
<tr class="odd">
<td style="text-align: left;">pos</td>
<td style="text-align: left;">Part of Speech</td>
<td style="text-align: left;">categorical</td>
<td style="text-align: left;">Grammatical category of the token (modified PENN Treebank tagset)</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
<!-- Load the MASC dataset/ preview -->
<p>We will work with the MASC as our dataset to approach a task, more than a question. The task will be to identify relevant materials for an English Language Learner (ELL) textbook. This will involve multiple research questions and allow us to illustrate some very fundamental concepts that will emerge across text analysis research.</p>
<p>First, I’ll read in the dataset and only keep the variables that will pertain to our task, dropping the <code>description</code> and <code>domain</code> variables, and preview the dataset in <a href="#exm-eda-masc-read">Example&nbsp;<span>8.1</span></a>.</p>
<div id="exm-eda-masc-read" class="theorem example">
<p><span class="theorem-title"><strong>Example 8.1 </strong></span>&nbsp;</p>
<div class="cell" data-hash="exploration_cache/html/exm-eda-masc-read-show_4b25ee9afaeba306d7f921b3b1e9391f">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Read and subset the MASC dataset</span></span>
<span><span class="va">masc_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu">read_csv</span><span class="op">(</span><span class="st">"../data/masc/masc_transformed.csv"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="op">-</span><span class="va">description</span>, <span class="op">-</span><span class="va">domain</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview the MASC dataset</span></span>
<span><span class="va">masc_tbl</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-hash="exploration_cache/html/exm-eda-masc-read-run_9842f6a1ca590d7337cb2cdeb888685f">
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 5 × 7
&gt;   doc_id modality genre   term_num term         lemma        pos  
&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;
&gt; 1      1 Written  Letters        0 December     december     NNP  
&gt; 2      1 Written  Letters        1 1998         1998         CD   
&gt; 3      1 Written  Letters        2 Your         your         PRP$ 
&gt; 4      1 Written  Letters        3 contribution contribution NN   
&gt; 5      1 Written  Letters        4 to           to           TO</code></pre>
</div>
</div>
</div>
<p>From the output in <a href="#exm-eda-masc-read">Example&nbsp;<span>8.1</span></a>, we should note a couple of things. First the <code>doc_id</code> is treated as numeric <code>&lt;dbl&gt;</code> and it is not a quantitative variable –we should change this vector type to <code>&lt;chr&gt;</code>. Second, at some point in our analysis we may need to recode some of the character variables to factor variables as analysis methods may require this.</p>
<div id="exm-eda-masc-doc-id" class="theorem example">
<p><span class="theorem-title"><strong>Example 8.2 </strong></span>&nbsp;</p>
<div class="cell" data-hash="exploration_cache/html/exm-eda-masc-doc-id_cc89983065687372749549790b7e725a">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Change doc_id to character</span></span>
<span><span class="va">masc_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">masc_tbl</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>doc_id <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="va">doc_id</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>To get a better sense of distribution of the dataset, let’s use <code><a href="https://docs.ropensci.org/skimr/reference/skim.html">skim()</a></code> from the <code>skimr</code> package to generate a summary of the dataset. In particular, let’s just focus on the character variables by using <code>yank("character")</code>, as seen in <a href="#exm-eda-masc-skim">Example&nbsp;<span>8.3</span></a>.</p>
<div id="exm-eda-masc-skim" class="theorem example">
<p><span class="theorem-title"><strong>Example 8.3 </strong></span>&nbsp;</p>
<div class="cell" data-hash="exploration_cache/html/tbl-exm-eda-masc-skim_fdf0d5e686efc73a875d175ca5b6b277">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load package</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://docs.ropensci.org/skimr/">skimr</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Generate summary of the MASC dataset</span></span>
<span><span class="va">masc_tbl_skm</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">masc_tbl</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://docs.ropensci.org/skimr/reference/skim.html">skim</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Pull character variables</span></span>
<span><span class="va">masc_tbl_skm</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://docs.ropensci.org/skimr/reference/partition.html">yank</a></span><span class="op">(</span><span class="st">"character"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">kable</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="tbl-exm-eda-masc-skim" class="anchored">
<table data-quarto-postprocess="true" class="table table-sm table-striped small">
<caption>Table&nbsp;8.2: Summary of the MASC dataset.</caption>
<thead><tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">skim_variable</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">n_missing</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">complete_rate</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">min</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">max</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">empty</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">n_unique</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">whitespace</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">doc_id</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">392</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">modality</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">genre</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">12</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">18</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">token</td>
<td style="text-align: right;">25</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">99</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">32968</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">lemma</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">99</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">28010</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">pos</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">39</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
</div>
<p>Looking at <a href="#tbl-exm-eda-masc-skim">Table&nbsp;<span>8.2</span></a>, we see that there are 392 documents, two modalities, 18 genres, over 30k unique terms (which are words), over 28k lemmas (word base forms), and 39 distinct part-of-speech tags.</p>
<!--  
[ ] the skim shows that there are some 'words' up to 99 characters long, which are likely errors
[ ] there are 25 missing tokens and 4 missing lemmas
-->
<section id="sec-eda-descriptive" class="level3" data-number="8.2.1"><h3 data-number="8.2.1" class="anchored" data-anchor-id="sec-eda-descriptive">
<span class="header-section-number">8.2.1</span> Descriptive analysis</h3>
<p>Descriptive analysis techniques are used to gain insights from text data without interpreting or making conclusions about the actual meaning or context. Common techniques include frequency analysis to determine the most frequent words or phrases, dispersion analysis to see how terms or topics are distributed throughout a document or corpus, keyword analysis to identify distinctive terms, and/ or co-occurrence analysis to see what terms tend to appear together.</p>
<p>Using the MASC dataset, we will entertain questions such as:</p>
<ul>
<li>What are the most common terms a beginning ELL should learn?</li>
<li>Are there term differences between spoken and written discourses that should be emphasized?</li>
<li>What are the most common phrasal verbs (verb particle constructions)? Do they vary by modality or genre?</li>
</ul>
<p>Along the way, we will introduce some fundamental concepts in text analysis such as tokens and types and frequency, dispersion, and co-occurrence measures. In addition, we will apply various descriptive analysis techniques and visualizations to explore the dataset and identify new questions and new variables of interest.</p>
<section id="sec-eda-frequency" class="level4"><h4 class="anchored" data-anchor-id="sec-eda-frequency">Frequency analysis</h4>
<!-- 4 I's: identify, inspect, interrogate, interpret -->
<p>At its core, frequency analysis is a descriptive method that counts the number of times a linguistic unit, or term, (<em>i.e.</em> word, <span class="math inline">\(n\)</span>-gram, sentence, <em>etc</em>.) occurs in a dataset. The results of frequency analysis can be used to describe the dataset and to identify terms that are linguistically distinctive or distinctive to a particular group or sub-group in the dataset.</p>
<!--- Raw frequency (counting) --->
<section id="sec-eda-frequency-raw" class="level5"><h5 class="anchored" data-anchor-id="sec-eda-frequency-raw">Raw frequency</h5>
<p>Let’s consider what the most common words in the MASC dataset are as a starting point to making inroads on our task by identifying relevant vocabulary for an ELL textbook.</p>
<p>In the <code>masc_tbl</code> data frame we have the linguistic unit <code>term</code> which corresponds to the word-level annotation of the MASC. The <code>lemma</code> corresponds to the base form of each term, for words with inflectional morphology, the lemma is the word sans the inflection (<em>e.g.</em> is - be, are - be). For other words, the <code>term</code> and the <code>lemma</code> will be the same (<em>e.g.</em> the - the, in - in). These two variables pose a choice point for us: do we consider words to be the actual forms or the base forms? There is an argument to be made for both. In this case I will operationalize our linguistic unit as the <code>lemma</code> variable, as this will allow us to group words with inflectional morphology together.</p>
<p>To perform a basic word frequency analysis, we start by using the <code>count()</code> function from the <code>dplyr</code> package to count the number of times each lemma occurs in the dataset. We’ll sort by the most frequent lemmas, as seen in <a href="#exm-eda-masc-count">Example&nbsp;<span>8.4</span></a>.</p>
<div id="exm-eda-masc-count" class="theorem example">
<p><span class="theorem-title"><strong>Example 8.4 </strong></span>&nbsp;</p>
<div class="cell" data-hash="exploration_cache/html/eda-masc-count_dfa0ec013f34667f04d70c336e66a3c6">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Lemma count, sorted</span></span>
<span><span class="va">masc_tbl</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">count</span><span class="op">(</span><span class="va">lemma</span>, sort <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 28,011 × 2
&gt;    lemma     n
&gt;    &lt;chr&gt; &lt;int&gt;
&gt;  1 ,     27113
&gt;  2 .     26258
&gt;  3 the   26137
&gt;  4 be    19405
&gt;  5 to    13548
&gt;  6 and   12528
&gt;  7 of    12005
&gt;  8 a     10480
&gt;  9 in     8374
&gt; 10 i      7783
&gt; # ℹ 28,001 more rows</code></pre>
</div>
</div>
</div>
<p>The output of this frequency tabulation in <a href="#exm-eda-masc-count">Example&nbsp;<span>8.4</span></a> is a data frame with two columns: <code>lemma</code> and <code>n</code>. The <code>lemma</code> column contains the unique lemmas in the dataset, and the <code>n</code> column contains the frequency of each lemma. The data frame is sorted in descending order by the frequency of lemmas. Now the result includes over 28,000 rows –which corresponds to the number of unique lemmas in the dataset.</p>
<p>At this point, it is important to define two key concepts that are fundamental to working with text. First, a <strong>term</strong> is a defined linguistic unit extracted from a corpus. In our dataset, the terms are words, such as ‘the’, ‘houses’, ‘are’. A <strong>lemma</strong> is an annotated recoding of words which represent the uninflected base form of a word. In either case, the term or lemma is an instance of a linguistic unit. These instances are called <strong>tokens</strong>. When we count the number of times a term or lemma occurs in a dataset, we are counting the number of tokens, such as in <a href="#exm-eda-masc-count">Example&nbsp;<span>8.4</span></a>. Now, the list of unique terms, or lemmas, is a list of <strong>types</strong>. In other words, a token is an instance of a type. By definition, then, there will always be at least as many tokens as types, but more often than not (many) more tokens than types.</p>
<p>Our first pass a calculating lemma frequency in <a href="#exm-eda-masc-count">Example&nbsp;<span>8.4</span></a> should bring something else to our attention. As we can see among the most frequent lemmas are non-words such as <code>,</code>, and <code>.</code>. As you can imagine, given the conventions of written and transcriptional language, these types are very frequent. For a frequency analysis focusing on words, however, we should probably remove them. Thinking ahead, there may also be other non-words that we want to remove, such as symbols, numbers, <em>etc</em>. Let’s take a look at <a href="#tbl-eda-masc-pos">Table&nbsp;<span>8.3</span></a>, where I’ve counted the part-of-speech tags <code>pos</code> in the dataset to see what other non-words we might want to remove.</p>
<div id="exm-eda-masc-pos" class="theorem example">
<p><span class="theorem-title"><strong>Example 8.5 </strong></span>&nbsp;</p>
<div class="cell" data-hash="exploration_cache/html/tbl-eda-masc-pos_d978ff8bd548f7d177b66cd47c350f63">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># [ ] consider how to present this better, more concisely</span></span>
<span></span>
<span><span class="co"># Part-of-speech tags</span></span>
<span><span class="va">masc_tbl</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">count</span><span class="op">(</span><span class="va">pos</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">arrange</span><span class="op">(</span><span class="va">pos</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">kable</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="tbl-eda-masc-pos" class="anchored">
<table data-quarto-postprocess="true" class="table table-sm table-striped small">
<caption>Table&nbsp;8.3: Part-of-speech tags in the MASC dataset.</caption>
<thead><tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">pos</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">n</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">CC</td>
<td style="text-align: right;">16768</td>
</tr>
<tr class="even">
<td style="text-align: left;">CD</td>
<td style="text-align: right;">12788</td>
</tr>
<tr class="odd">
<td style="text-align: left;">DT</td>
<td style="text-align: right;">48708</td>
</tr>
<tr class="even">
<td style="text-align: left;">EX</td>
<td style="text-align: right;">1048</td>
</tr>
<tr class="odd">
<td style="text-align: left;">FW</td>
<td style="text-align: right;">199</td>
</tr>
<tr class="even">
<td style="text-align: left;">IN</td>
<td style="text-align: right;">56710</td>
</tr>
<tr class="odd">
<td style="text-align: left;">JJ</td>
<td style="text-align: right;">31736</td>
</tr>
<tr class="even">
<td style="text-align: left;">JJR</td>
<td style="text-align: right;">1507</td>
</tr>
<tr class="odd">
<td style="text-align: left;">JJS</td>
<td style="text-align: right;">776</td>
</tr>
<tr class="even">
<td style="text-align: left;">LRB</td>
<td style="text-align: right;">3</td>
</tr>
<tr class="odd">
<td style="text-align: left;">LS</td>
<td style="text-align: right;">54</td>
</tr>
<tr class="even">
<td style="text-align: left;">MD</td>
<td style="text-align: right;">6855</td>
</tr>
<tr class="odd">
<td style="text-align: left;">NN</td>
<td style="text-align: right;">78141</td>
</tr>
<tr class="even">
<td style="text-align: left;">NNP</td>
<td style="text-align: right;">46417</td>
</tr>
<tr class="odd">
<td style="text-align: left;">NNPS</td>
<td style="text-align: right;">839</td>
</tr>
<tr class="even">
<td style="text-align: left;">NNS</td>
<td style="text-align: right;">25461</td>
</tr>
<tr class="odd">
<td style="text-align: left;">PDT</td>
<td style="text-align: right;">259</td>
</tr>
<tr class="even">
<td style="text-align: left;">POS</td>
<td style="text-align: right;">2107</td>
</tr>
<tr class="odd">
<td style="text-align: left;">PP</td>
<td style="text-align: right;">7</td>
</tr>
<tr class="even">
<td style="text-align: left;">PRP</td>
<td style="text-align: right;">29202</td>
</tr>
<tr class="odd">
<td style="text-align: left;">PRP$</td>
<td style="text-align: right;">8395</td>
</tr>
<tr class="even">
<td style="text-align: left;">PUNCT</td>
<td style="text-align: right;">88319</td>
</tr>
<tr class="odd">
<td style="text-align: left;">RB</td>
<td style="text-align: right;">23747</td>
</tr>
<tr class="even">
<td style="text-align: left;">RBR</td>
<td style="text-align: right;">600</td>
</tr>
<tr class="odd">
<td style="text-align: left;">RBS</td>
<td style="text-align: right;">216</td>
</tr>
<tr class="even">
<td style="text-align: left;">RP</td>
<td style="text-align: right;">1244</td>
</tr>
<tr class="odd">
<td style="text-align: left;">SYM</td>
<td style="text-align: right;">2973</td>
</tr>
<tr class="even">
<td style="text-align: left;">TO</td>
<td style="text-align: right;">13481</td>
</tr>
<tr class="odd">
<td style="text-align: left;">UH</td>
<td style="text-align: right;">1574</td>
</tr>
<tr class="even">
<td style="text-align: left;">VB</td>
<td style="text-align: right;">20073</td>
</tr>
<tr class="odd">
<td style="text-align: left;">VBD</td>
<td style="text-align: right;">15754</td>
</tr>
<tr class="even">
<td style="text-align: left;">VBG</td>
<td style="text-align: right;">9895</td>
</tr>
<tr class="odd">
<td style="text-align: left;">VBN</td>
<td style="text-align: right;">10111</td>
</tr>
<tr class="even">
<td style="text-align: left;">VBP</td>
<td style="text-align: right;">13647</td>
</tr>
<tr class="odd">
<td style="text-align: left;">VBZ</td>
<td style="text-align: right;">13824</td>
</tr>
<tr class="even">
<td style="text-align: left;">WDT</td>
<td style="text-align: right;">2388</td>
</tr>
<tr class="odd">
<td style="text-align: left;">WP</td>
<td style="text-align: right;">2470</td>
</tr>
<tr class="even">
<td style="text-align: left;">WP$</td>
<td style="text-align: right;">73</td>
</tr>
<tr class="odd">
<td style="text-align: left;">WRB</td>
<td style="text-align: right;">2728</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
</div>
<p>Consulting the <a href="https://catalog.ldc.upenn.edu/docs/LDC95T7/cl93.html">PENN Tagset online</a>, we can see that the <code>pos</code> variable includes a number of non-words or other elements to exclude including:</p>
<ul>
<li>‘CD’ - Cardinal number</li>
<li>‘FW’ - Foreign word</li>
<li>‘LS’ - List item marker</li>
<li>‘SYM’ - Symbol</li>
</ul>
<p>This modified tagset has grouped the punctuation tags into a single tag, ‘PUNCT’.</p>
<p>We can use this information to remove lemmas that are tagged with either of these values. We can do this by filtering the data frame to only include lemmas that are not tagged with the <code>pos</code> values listed above, as seen in <a href="#exm-eda-masc-count-filter">Example&nbsp;<span>8.6</span></a>.</p>
<div id="exm-eda-masc-count-filter" class="theorem example">
<p><span class="theorem-title"><strong>Example 8.6 </strong></span>&nbsp;</p>
<div class="cell" data-hash="exploration_cache/html/eda-masc-count-filter_1fff8ac9181d464038658044b9411bb1">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Filter out lemmas with PUNCT or SYM for pos</span></span>
<span><span class="va">masc_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">masc_tbl</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="op">!</span><span class="op">(</span><span class="va">pos</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"CD"</span>, <span class="st">"FW"</span>, <span class="st">"LS"</span>, <span class="st">"SYM"</span>, <span class="st">"PUNCT"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Lemma count, sorted (again)</span></span>
<span><span class="va">masc_tbl</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">count</span><span class="op">(</span><span class="va">lemma</span>, sort <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 26,166 × 2
&gt;    lemma     n
&gt;    &lt;chr&gt; &lt;int&gt;
&gt;  1 the   26137
&gt;  2 be    19405
&gt;  3 to    13548
&gt;  4 and   12528
&gt;  5 of    12005
&gt;  6 a     10461
&gt;  7 in     8374
&gt;  8 i      7783
&gt;  9 that   7082
&gt; 10 you    5276
&gt; # ℹ 26,156 more rows</code></pre>
</div>
</div>
</div>
<p>Now we are only viewing the most frequent words in the dataset, which reduces the number of observations to around 26k. Let’s now explore the frequency distribution of the tokens. In <a href="#fig-eda-masc-count-plots">Figure&nbsp;<span>8.1</span></a>, I’ve created three plots which include: 1) all the types, 2) the top 100 types, and 3) the top 10 types in the dataset.</p>
<div>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># [ ] consider how to present the 'all types' plot better, more concisely</span></span>
<span></span>
<span><span class="co"># Plot lemma count for all types</span></span>
<span><span class="va">masc_tbl</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">count</span><span class="op">(</span><span class="va">lemma</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">arrange</span><span class="op">(</span><span class="fu">desc</span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/reorder.factor.html">reorder</a></span><span class="op">(</span><span class="va">lemma</span>, <span class="fu">desc</span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span>, y <span class="op">=</span> <span class="va">n</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_col</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Types"</span>, y <span class="op">=</span> <span class="st">"Token frequency"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>axis.text.x <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot lemma count for top 100 types</span></span>
<span><span class="va">masc_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">count</span><span class="op">(</span><span class="va">lemma</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">arrange</span><span class="op">(</span><span class="fu">desc</span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">100</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/reorder.factor.html">reorder</a></span><span class="op">(</span><span class="va">lemma</span>, <span class="fu">desc</span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span>, y <span class="op">=</span> <span class="va">n</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_col</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Types"</span>, y <span class="op">=</span> <span class="st">"Token frequency"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>axis.text.x <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>angle <span class="op">=</span> <span class="fl">90</span>, hjust <span class="op">=</span> <span class="fl">1.3</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot lemma count for top 10 types</span></span>
<span><span class="va">masc_tbl</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">count</span><span class="op">(</span><span class="va">lemma</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">arrange</span><span class="op">(</span><span class="fu">desc</span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/reorder.factor.html">reorder</a></span><span class="op">(</span><span class="va">lemma</span>, <span class="fu">desc</span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span>, y <span class="op">=</span> <span class="va">n</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_col</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Types"</span>, y <span class="op">=</span> <span class="st">"Token frequency"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>axis.text.x <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>angle <span class="op">=</span> <span class="fl">65</span>, hjust <span class="op">=</span> <span class="fl">1.3</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-eda-masc-count-plots" class="cell quarto-layout-panel" data-hash="exploration_cache/html/fig-eda-masc-count-plots_514593db748e846f9eb20a9f07b508d8">
<figure class="figure"><div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-eda-masc-count-plots-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="exploration_files/figure-html/fig-eda-masc-count-plots-1.png" class="img-fluid figure-img" data-ref-parent="fig-eda-masc-count-plots" width="384"></p>
<figcaption class="figure-caption">(a) All types</figcaption></figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-eda-masc-count-plots-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="exploration_files/figure-html/fig-eda-masc-count-plots-2.png" class="img-fluid figure-img" data-ref-parent="fig-eda-masc-count-plots" width="384"></p>
<figcaption class="figure-caption">(b) Top 100 types</figcaption></figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-eda-masc-count-plots-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="exploration_files/figure-html/fig-eda-masc-count-plots-3.png" class="img-fluid figure-img" data-ref-parent="fig-eda-masc-count-plots" width="384"></p>
<figcaption class="figure-caption">(c) Top 10 types</figcaption></figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;8.1: Frequency plots of tokens in the MASC dataset</figcaption><p></p>
</figure>
</div>
</div>
<p>The distributions we see in <a href="#fig-eda-masc-count-plots">Figure&nbsp;<span>8.1</span></a> are highly right-skewed (in <a href="#fig-eda-masc-count-plots-1">Figure&nbsp;<span>8.1 (a)</span></a> in a very extreme way!). This is typical of natural language distributions, notably documented by George Kingsley Zipf <span class="citation" data-cites="Zipf1949">(<a href="references.html#ref-Zipf1949" role="doc-biblioref">Zipf 1949</a>)</span>. This type of distribution approaches the theoretical Zipf distribution. A Zipf (or Zipfian) distribution is characterized by the fact that the frequency of any word is inversely proportional to its rank in the frequency table. In other words, the most frequent word occurs approximately twice as often as the second most frequent word, three times as often as the third most frequent word, and so on.</p>
<p>As we can see, our distribuions to not follow the Zipf distribution exactly. This is because the Zipf distribution is a theoretical distribution, and the actual distribution of words in a corpus is affected by various sampling factors, including the size of the corpus. The larger the corpus, the closer the distribution will be to the Zipf distribution.</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-medal" aria-label="medal"></i> Dive deeper</strong></p>
<p>As stated above, Zipfian distributions are typical of natural language and are observed a various linguistic levels. This is because natural language is a complex system, and complex systems tend to exhibit Zipfian distributions. Other examples of complex systems that exhibit Zipfian distributions include the size of cities, the frequency of species in ecological communities, the frequency of links in the World Wide Web, <em>etc.</em></p>
</div>
</div>
</div>
<p>The observation captured in the Zipf distribution is key to understanding quantitative text analysis. It demonstrates that most of the types in a corpus occur (relatively) infrequently, while a small number of types occur very frequently. In fact, if we calculate the cumulative frequency of the lemmas in the <code>masc_tbl</code> data frame, we can see that the top 10 types account for over 20% of the lemmas used in the dataset –by 100 types that increases to over 40%, as seen in <a href="#exm-eda-masc-count-cumulative">Example&nbsp;<span>8.7</span></a>.</p>
<div id="exm-eda-masc-count-cumulative" class="theorem example">
<p><span class="theorem-title"><strong>Example 8.7 </strong></span>&nbsp;</p>
<div class="cell" data-hash="exploration_cache/html/fig-eda-masc-count-cumulative_e9afee5820589450cbe6497473d233fd">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate cumulative frequency</span></span>
<span><span class="va">lemma_cumul_freq</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">masc_tbl</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">count</span><span class="op">(</span><span class="va">lemma</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">arrange</span><span class="op">(</span><span class="fu">desc</span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>cumulative <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cumsum.html">cumsum</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>percent <span class="op">=</span> <span class="va">cumulative</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">lemma_cumul_freq</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">2000</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/reorder.factor.html">reorder</a></span><span class="op">(</span><span class="va">lemma</span>, <span class="fu">desc</span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span>, y <span class="op">=</span> <span class="va">percent</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_col</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">10</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">100</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># annotate("text", x = 10+10, y = 0.5, label = "10 lemmas") +</span></span>
<span>  <span class="co"># annotate("text", x = 100+10, y = 0.5, label = "100 lemmas") +</span></span>
<span>  <span class="fu">scale_y_continuous</span><span class="op">(</span>labels <span class="op">=</span> <span class="fu">scales</span><span class="fu">::</span><span class="va"><a href="https://scales.r-lib.org/reference/percent_format.html">percent</a></span>, limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Types"</span>, y <span class="op">=</span> <span class="st">"Cumulative frequency percent"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>axis.text.x <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-eda-masc-count-cumulative" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="exploration_files/figure-html/fig-eda-masc-count-cumulative-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">Figure&nbsp;8.2: Cumulative frequency of lemmas in the MASC dataset</figcaption></figure>
</div>
</div>
</div>
</div>
<p>If we look at the types that appear within the first 100 most frequent, you can likely also appreciate another thing about language use. Let’s list the top 100 types in <a href="#exm-eda-masc-count-top-100">Example&nbsp;<span>8.8</span></a>.</p>
<!---
  [ ] work on text output
--->
<div id="exm-eda-masc-count-top-100" class="theorem example">
<p><span class="theorem-title"><strong>Example 8.8 </strong></span>&nbsp;</p>
<div class="cell" data-hash="exploration_cache/html/eda-masc-count-top-100_5b24657f8c9858c13836cc7553b6553b">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Top 100 types</span></span>
<span><span class="va">lemma_cumul_freq</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">100</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">pull</span><span class="op">(</span><span class="va">lemma</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">str_c</span><span class="op">(</span>collapse <span class="op">=</span> <span class="st">", "</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">str_view</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; [1] │ the, be, to, and, of, a, in, i, that, you, have, it, for, on, do, with, we, as, this, not, at, from, he, but, by, will, my, or, they, your, an, n't, say, one, what, so, his, if, 's, can, go, all, there, me, would, about, know, get, make, out, up, think, our, she, more, time, just, no, when, their, like, her, who, which, other, see, people, new, s, take, now, work, some, year, how, them, use, come, into, well, than, look, its, may, right, then, could, because, only, us, these, want, any, also, two, first, need, way, where, back</code></pre>
</div>
</div>
</div>
<p>For the most part, the most frequent words are not content words, but rather function words (<em>e.g.</em> determiners, prepositions, pronouns, auxiliary verbs). Function words include a closed class of relatively few words that are used to express grammatical relationships between content words. It then is no surprise that they are the comprise many of the most frequent words in a corpus.</p>
<p>Another key observation is that among the most frequency content words (<em>e.g.</em> nouns, verbs, adjectives, adverbs) are words that are quite semantically generic –that is, they are words that are used in a wide range of contexts and take a wide range of meanings. Take for example the adjective ‘good’. It can be used to describe a wide range of nouns, such as ‘good food’, ‘good people’, ‘good times’, <em>etc</em>. A sometimes near-synonym of ‘good’, for example ‘good student’, is the word ‘studious’. Yet, ‘studious’ is not as frequent as ‘good’ as it is used to describe a narrower range of nouns, such as ‘studious student’, ‘studious scholar’, ‘studious researcher’, <em>etc</em>. In this way, ‘studious’ is more semantically specific than ‘good’.</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-lightbulb" aria-label="lightbulb"></i> Consider this</strong></p>
<p>Based on what you now know about the expected distribution of words in a corpus, what if your were asked to predict what the most frequency English word used is in each U.S. State? What would you predict? How confident would you be in your prediction? What if you were asked to predict what the most frequency word used is in the language of a given country? What would you want to know before making your prediction?</p>
</div>
</div>
</div>
<p>So common across corpus samples, in some analyses these usual suspects of the most common words are considered irrelvant and are filtered out. In our ELL materials task, however, we might exclude them for this simple fact that it will be a given that we will teach these words given their grammatical importance. If we want to focus on the most common content words, we can filter out the function words.</p>
<p>One approach to filtering out these words is to use a pre-determined list of <strong>stopwords</strong>. The <code>tidytext</code> package includes a data frame <code>stop_words</code> of stopword lexicons for English. We can select a lexicon from <code>stop_words</code> and use <code>anti_join()</code> to filter out the words that appear in the <code>word</code> variable from the <code>lemma</code> variable in the <code>masc_tbl</code> data frame. In <a href="#exm-eda-masc-count-stop-words">Example&nbsp;<span>8.9</span></a>, I perform this filtering and then re-run the frequency analysis for the top 100 lemmas.</p>
<div id="exm-eda-masc-count-stop-words" class="theorem example">
<p><span class="theorem-title"><strong>Example 8.9 </strong></span>&nbsp;</p>
<div class="cell" data-hash="exploration_cache/html/fig-eda-masc-count-stop-words_ffe488cce0f393040b5f14c286616331">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load package</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/juliasilge/tidytext">tidytext</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Select stopword lexicon</span></span>
<span><span class="va">stopwords</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">stop_words</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">lexicon</span> <span class="op">==</span> <span class="st">"SMART"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Filter out stop words</span></span>
<span><span class="fu">anti_join</span><span class="op">(</span></span>
<span>  x <span class="op">=</span> <span class="va">masc_tbl</span>,</span>
<span>  y <span class="op">=</span> <span class="va">stopwords</span>,</span>
<span>  by <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"lemma"</span> <span class="op">=</span> <span class="st">"word"</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">count</span><span class="op">(</span><span class="va">lemma</span>, sort <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">100</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/reorder.factor.html">reorder</a></span><span class="op">(</span><span class="va">lemma</span>, <span class="fu">desc</span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span>, y <span class="op">=</span> <span class="va">n</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_col</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Types"</span>, y <span class="op">=</span> <span class="st">"Token frequency"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_y_continuous</span><span class="op">(</span>labels <span class="op">=</span> <span class="fu">scales</span><span class="fu">::</span><span class="va"><a href="https://scales.r-lib.org/reference/comma.html">comma</a></span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>axis.text.x <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>angle <span class="op">=</span> <span class="fl">90</span>, hjust <span class="op">=</span> <span class="fl">1.3</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-eda-masc-count-stop-words" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="exploration_files/figure-html/fig-eda-masc-count-stop-words-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">Figure&nbsp;8.3: Frequency of tokens in the MASC dataset after filtering out stopwords</figcaption></figure>
</div>
</div>
</div>
</div>
<p>The resulting plot in <a href="#fig-eda-masc-count-stop-words">Figure&nbsp;<span>8.3</span></a> paints a very different picture of the most frequent words in the dataset. The most frequent words are now content words, and the most frequent words are more semantically specific. Also note that the distribution of the lemmas is now a bit more balanced, relative to the distribution in <a href="#fig-eda-masc-count-plots-2">Figure&nbsp;<span>8.1 (b)</span></a>.</p>
<p>Eliminating words in this fashion, however, may not always be the best approach. Available lists of stopwords vary in their contents and are determined by other researchers for other potential uses. We may instead opt to create our own stopword list that is tailored to the task, or we may opt to use a statistical approach based on their distribution in the dataset using a combination of frequency and dispersion measures, as we will see in the next section.</p>
<p>For our case, however, we have another strategy to apply. Since our task is to identify relevant vocabulary, beyond the fundamental function words in English, we can use the part-of-speech tags to reduce our dataset to just the content words, that is nouns, verbs, adjectives, and adverbs. We need to consult the Penn Tagset again, to ensure we are selecting the correct tags. I will assign this data frame to <code>masc_content_tbl</code> to keep it separate from our main data frame <code>masc_tbl</code>, seen in <span class="quarto-unresolved-ref">?exm-eda-masc-filter-pos</span>.</p>
<div id="exm-eda-masc-filte-pos" class="theorem example">
<p><span class="theorem-title"><strong>Example 8.10 </strong></span>&nbsp;</p>
<div class="cell" data-hash="exploration_cache/html/eda-masc-filter-pos_80f57de9d5c2509dc5e220a3da58067f">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Penn Tagset for content words</span></span>
<span><span class="co"># Nouns: NN, NNS,</span></span>
<span><span class="co"># Verbs: VB, VBD, VBG, VBN, VBP, VBZ</span></span>
<span><span class="co"># Adjectives: JJ, JJR, JJS</span></span>
<span><span class="co"># Adverbs: RB, RBR, RBS</span></span>
<span></span>
<span><span class="va">content_pos</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"NN"</span>, <span class="st">"NNS"</span>, <span class="st">"VB"</span>, <span class="st">"VBD"</span>, <span class="st">"VBG"</span>, <span class="st">"VBN"</span>, <span class="st">"VBP"</span>, <span class="st">"VBZ"</span>, <span class="st">"JJ"</span>, <span class="st">"JJR"</span>, <span class="st">"JJS"</span>, <span class="st">"RB"</span>, <span class="st">"RBR"</span>, <span class="st">"RBS"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Select content words</span></span>
<span><span class="va">masc_content_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">masc_tbl</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">pos</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="va">content_pos</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>We now have reduced the number of observations by 50% focusing on the content words. We are getting closer to identifying the vocabulary that we want to include in our ELL materials, but we will need some more tools to help us identify the most relevant vocabulary.</p>
</section><section id="sec-eda-frequency-dispersion" class="level5"><h5 class="anchored" data-anchor-id="sec-eda-frequency-dispersion">Dispersion</h5>
<!-- Dispersion 
Dispersion measures: 
  - $df$ (document frequency)
`   - $idf$ (inverse document frequency)
  - Gries' $DP$ Deviation of Proportions (DP)
    - 1 - $DP$ normalized
-->
<p><strong>Dispersion</strong> is a measure of how evenly distributed a linguistic unit is across a dataset. This is a key concept in text analysis, as important as frequency. It is important to recognize that frequency and dispersion are measures of different characteristics. We can have two words that occur with the same frequency, but one word may be more evenly distributed across a dataset than the other. Depending on the researcher’s aims, this may be an important distinction to make. For our task, it is likely the case that we want to capture words that are well-dispersed across the dataset, for the most part, as words that have a high frequency and a low dispersion tend to be connected to a particular context, whether that be a particular genre, a particular speaker, a particular topic, <em>etc</em>. In other research, aim may be the reverse; to identify words that are highly frequent and highly concentrated in a particular context to identify words that are distinctive to that context.</p>
<p>To estimate the distribution of types across a dataset there are basic measures, such as the number of documents a type appears in, or more complex measures in which the spread of terms in a given document and the documents’ lengths are taken into account.</p>
<p>To calculate document frequency (<span class="math inline">\(DF\)</span>), we can use the <code>count()</code> function to count the number of documents a lemma appears in. We can then sort the results in descending order by the number of documents, as seen in <a href="#exm-eda-masc-df">Example&nbsp;<span>8.11</span></a>.</p>
<div id="exm-eda-masc-df" class="theorem example">
<p><span class="theorem-title"><strong>Example 8.11 </strong></span>&nbsp;</p>
<div class="cell" data-hash="exploration_cache/html/eda-masc-df_ed4846e70804aec58a1a7e083961ea93">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Document frequency</span></span>
<span><span class="va">masc_content_tbl</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">count</span><span class="op">(</span><span class="va">lemma</span>, <span class="va">doc_id</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">count</span><span class="op">(</span><span class="va">lemma</span>, sort <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 19,200 × 2
&gt;    lemma     n
&gt;    &lt;chr&gt; &lt;int&gt;
&gt;  1 be      384
&gt;  2 have    336
&gt;  3 do      239
&gt;  4 not     232
&gt;  5 make    214
&gt;  6 more    206
&gt;  7 other   202
&gt;  8 time    193
&gt;  9 year    187
&gt; 10 know    183
&gt; # ℹ 19,190 more rows</code></pre>
</div>
</div>
</div>
<p><span class="math inline">\(DF\)</span> does not take into account the length of the documents in which the lemma appears nor the spread of the lemma within each document. To take these factors into account, we can use Gries’ Deviation of Proportions (<span class="math inline">\(DP\)</span>) measure <span class="citation" data-cites="Gries2023">(<a href="references.html#ref-Gries2023" role="doc-biblioref">Gries 2023, 87–88</a>)</span>.</p>
<p>The <span class="math inline">\(DP\)</span> measure is calculated as the difference between the proportion of a tokens in a document and in tokens in the corpus. The metric can be subtracted from 1 to create a normalized measure of dispersion ranging between 0 and 1, with lower values being more dispersed.</p>
<p>The <code>qtalrkit</code> package includes the <code>calc_dispersion_metrics()</code> function which calculates the either or both <span class="math inline">\(DF\)</span> and <span class="math inline">\(DP\)</span> (normalized) measures. In <a href="#exm-eda-masc-dp">Example&nbsp;<span>8.12</span></a>,</p>
<div id="exm-eda-masc-dp" class="theorem example">
<p><span class="theorem-title"><strong>Example 8.12 </strong></span>&nbsp;</p>
<div class="cell" data-hash="exploration_cache/html/eda-masc-dp_643bb9baf656ff2d760388c413ef31df">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate dispersion metrics</span></span>
<span><span class="va">masc_lemma_disp</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">masc_content_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">calc_dispersion_metrics</span><span class="op">(</span><span class="va">lemma</span>, <span class="va">doc_id</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>idf <span class="op">=</span> <span class="fl">1</span> <span class="op">-</span> <span class="op">(</span><span class="va">df</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">arrange</span><span class="op">(</span><span class="va">dp</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="va">masc_lemma_disp</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 10 × 5
&gt;    type      n    df    dp   idf
&gt;    &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;
&gt;  1 be    19174   384 0.124 0    
&gt;  2 have   5136   336 0.190 0.125
&gt;  3 not    2279   232 0.240 0.396
&gt;  4 make   1149   214 0.267 0.443
&gt;  5 other   882   202 0.270 0.474
&gt;  6 more   1005   206 0.276 0.464
&gt;  7 only    627   169 0.286 0.560
&gt;  8 take    769   176 0.286 0.542
&gt;  9 time    931   193 0.314 0.497
&gt; 10 see     865   152 0.327 0.604</code></pre>
</div>
</div>
</div>
<p>So for our task, we would like to identify lemmas that are frequent and well-dispersed. But two questions arise, first which measure of dispersion is best to use, <span class="math inline">\(DF\)</span> or <span class="math inline">\(DP\)</span>? Second, what is the threshold for frequency and dispersion that we should use to identify the lemmas that we want to include in our ELL materials?</p>
<p>Let’s tackle the first question. We can compare the <span class="math inline">\(DF\)</span> and <span class="math inline">\(DP\)</span> measures by plotting them against each other, as seen in <a href="#fig-eda-masc-df-dp">Figure&nbsp;<span>8.4</span></a>.</p>
<div id="exm-eda-masc-df-dp" class="theorem example">
<p><span class="theorem-title"><strong>Example 8.13 </strong></span>&nbsp;</p>
<div class="cell" data-hash="exploration_cache/html/fig-eda-masc-df-dp_342e8a08a1192f4226106eb618074bac">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># cor.test for DF and DP</span></span>
<span><span class="va">c1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.test.html">cor.test</a></span><span class="op">(</span><span class="va">masc_lemma_disp</span><span class="op">$</span><span class="va">idf</span>, <span class="va">masc_lemma_disp</span><span class="op">$</span><span class="va">dp</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot DF and DP</span></span>
<span><span class="va">masc_lemma_disp</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">idf</span>, y <span class="op">=</span> <span class="va">dp</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_smooth</span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, se <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ylim</span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Inverse Document frequency"</span>, y <span class="op">=</span> <span class="st">"Deviation of Proportions"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-eda-masc-df-dp" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="exploration_files/figure-html/fig-eda-masc-df-dp-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">Figure&nbsp;8.4: Inverse document frequency and Deviation of Proportions for lemmas in the MASC dataset</figcaption></figure>
</div>
</div>
</div>
</div>
<p>Statistically, there is a high correlation between <span class="math inline">\(IDF\)</span> and <span class="math inline">\(DP\)</span> with an <span class="math inline">\(R^2\)</span> value of 0.752 and a <span class="math inline">\(p\)</span>-value less than .001. However, we can see that there is a trade-off between <span class="math inline">\(IDF\)</span> and <span class="math inline">\(DP\)</span>. For less dispersed lemmas, <span class="math inline">\(DP\)</span> is more sensitive to differences than <span class="math inline">\(IDF\)</span>. For more dispersed lemmas, <span class="math inline">\(IDF\)</span> is more sensitive to differences than <span class="math inline">\(DP\)</span>. The upshot, then, is that if your interest is in distinguishing between less dispersed types, <span class="math inline">\(DP\)</span> can provide a more sensitive measure. If your interest is in distinguishing between more dispersed types, <span class="math inline">\(IDF\)</span> can provide a more sensitive measure.</p>
<p>The second issue is to decide what the threshold for dispersion should be. Let’s create a density plot to see if there is a natural break in the distribution of dispersion measures, as seen in <a href="#fig-eda-masc-dp-density">Figure&nbsp;<span>8.5</span></a>.</p>
<div id="exm-eda-masc-dp-density" class="theorem example">
<p><span class="theorem-title"><strong>Example 8.14 </strong></span>&nbsp;</p>
<div class="cell" data-hash="exploration_cache/html/fig-eda-masc-dp-density_0ce30429c38eaafe4a40baa8397e61cd">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Density plot of DP</span></span>
<span><span class="va">masc_lemma_disp</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">dp</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_density</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_x_continuous</span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">.1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Deviation of Proportions"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-eda-masc-dp-density" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="exploration_files/figure-html/fig-eda-masc-dp-density-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">Figure&nbsp;8.5: Density plot of Deviation of Proportions for lemmas in the MASC dataset</figcaption></figure>
</div>
</div>
</div>
</div>
<p>What we are looking for is a natural break in the distribution of dispersion measures. In <a href="#fig-eda-masc-dp-density">Figure&nbsp;<span>8.5</span></a>, we can see that there is a natural break in the distribution between .85 and .97. We can split the difference and use this as a threshold to filter out lemmas that are less dispersed. In <a href="#exm-eda-masc-dp-filter">Example&nbsp;<span>8.15</span></a>, I filter out lemmas that have a dispersion measure less than .91 and then re-run the frequency analysis for the top 100 lemmas.</p>
<div id="exm-eda-masc-dp-filter" class="theorem example">
<p><span class="theorem-title"><strong>Example 8.15 </strong></span>&nbsp;</p>
<div class="cell" data-hash="exploration_cache/html/fig-eda-masc-dp-filter_5f4955eef3ef6e0f826ef5accb1ad328">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Filter out lemmas with DP &lt;= .91</span></span>
<span><span class="va">masc_lemma_disp_thres</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">masc_lemma_disp</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">dp</span> <span class="op">&lt;=</span> <span class="fl">.91</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">arrange</span><span class="op">(</span><span class="fu">desc</span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Re-run frequency analysis</span></span>
<span><span class="va">masc_lemma_disp_thres</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">100</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/reorder.factor.html">reorder</a></span><span class="op">(</span><span class="va">type</span>, <span class="fu">desc</span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span>, y <span class="op">=</span> <span class="va">n</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_col</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Types"</span>, y <span class="op">=</span> <span class="st">"Token frequency"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_y_continuous</span><span class="op">(</span>labels <span class="op">=</span> <span class="fu">scales</span><span class="fu">::</span><span class="va"><a href="https://scales.r-lib.org/reference/comma.html">comma</a></span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>axis.text.x <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>angle <span class="op">=</span> <span class="fl">90</span>, hjust <span class="op">=</span> <span class="fl">1.3</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">masc_lemma_disp_thres</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">50</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">pull</span><span class="op">(</span><span class="va">type</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span>ncol <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt;      [,1]   [,2]   [,3]    [,4]     [,5]   [,6]    [,7]   [,8]   [,9]    [,10] 
&gt; [1,] "be"   "say"  "think" "other"  "s"    "well"  "want" "here" "thing" "many"
&gt; [2,] "have" "go"   "more"  "see"    "work" "look"  "also" "t"    "tell"  "man" 
&gt; [3,] "do"   "know" "just"  "people" "year" "then"  "way"  "new"  "first" "ask" 
&gt; [4,] "not"  "get"  "time"  "take"   "come" "right" "need" "find" "help"  "very"
&gt; [5,] "n't"  "make" "so"    "now"    "use"  "only"  "back" "give" "day"   "much"</code></pre>
</div>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">masc_lemma_disp_thres</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_tail</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">50</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">pull</span><span class="op">(</span><span class="va">type</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span>ncol <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt;      [,1]         [,2]         [,3]        [,4]         [,5]        
&gt; [1,] "dump"       "ignorance"  "liability" "unleash"    "blur"      
&gt; [2,] "instrument" "mainstream" "tuition"   "buzz"       "resistance"
&gt; [3,] "triumph"    "wildly"     "hook"      "prosperous" "absurd"    
&gt; [4,] "harsh"      "awaken"     "fetch"     "presume"    "qualify"   
&gt; [5,] "sting"      "dismiss"    "brave"     "summarize"  "liberty"   
&gt;      [,6]         [,7]           [,8]           [,9]         [,10]        
&gt; [1,] "going"      "wound"        "shy"          "protective" "wax"        
&gt; [2,] "awkward"    "alright"      "sandy"        "preside"    "faith-based"
&gt; [3,] "afterwards" "evolutionary" "proximity"    "rethink"    "decidedly"  
&gt; [4,] "eve"        "envy"         "interfere"    "strictly"   "resolute"   
&gt; [5,] "devote"     "nostalgic"    "accidentally" "explored"   "evidently"</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-eda-masc-dp-filter" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="exploration_files/figure-html/fig-eda-masc-dp-filter-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">Figure&nbsp;8.6: Frequency of tokens in the MASC dataset after filtering out lemmas with a Deviation of Proportions less than .91</figcaption></figure>
</div>
</div>
</div>
</div>
<!-- Weights 
Weights:
- $tf-idf$ (term frequency-inverse document frequency)
- 1 - DP_normalized
-->
</section><section id="sec-eda-frequency-relative" class="level5"><h5 class="anchored" data-anchor-id="sec-eda-frequency-relative">Relative frequency</h5>
<!-- Corpus and sub-corpus comparisons 

- Term frequency
- Observed relative frequency
-->
<p>Although much can be learned from the distribution of linguistic units in a dataset as a whole, most frequency analyses aim to contrast the frequency of linguistic units across distinct corpora or sub-corpora of a corpus. In the MASC dataset, we can explore potential differences between the spoken and written discourses.</p>
<p>Let’s start by following a similar approach to the one we took above for the corpus as a whole. However, this time we will add another variable to the <code>count()</code> function to group the tokens by the <code>modality</code> variable and then use this variable in the <code>facet_wrap()</code> function to create a separate plot for each modality, as seen in <a href="#exm-eda-masc-count-modality">Example&nbsp;<span>8.16</span></a>.</p>
<div id="exm-eda-masc-count-modality" class="theorem example">
<p><span class="theorem-title"><strong>Example 8.16 </strong></span>&nbsp;</p>
<div class="cell" data-hash="exploration_cache/html/fig-eda-masc-count-modality_e367c7bedb87fa692bb4c50e0619dbfd">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Token count by modality, sorted</span></span>
<span><span class="va">masc_tbl</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">count</span><span class="op">(</span><span class="va">modality</span>, <span class="va">token</span>, sort <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">50</span>, by <span class="op">=</span> <span class="va">modality</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/reorder.factor.html">reorder</a></span><span class="op">(</span><span class="va">token</span>, <span class="fu">desc</span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span>, y <span class="op">=</span> <span class="va">n</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_col</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Types"</span>, y <span class="op">=</span> <span class="st">"Token frequency"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_y_continuous</span><span class="op">(</span>labels <span class="op">=</span> <span class="fu">scales</span><span class="fu">::</span><span class="va"><a href="https://scales.r-lib.org/reference/comma.html">comma</a></span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span> <span class="va">modality</span>, ncol <span class="op">=</span> <span class="fl">1</span>, scales <span class="op">=</span> <span class="st">"free"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>axis.text.x <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>angle <span class="op">=</span> <span class="fl">90</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">masc_tbl</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">modality</span>, <span class="va">token</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">summarise</span><span class="op">(</span>n <span class="op">=</span> <span class="fu">n</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">arrange</span><span class="op">(</span><span class="va">modality</span>, <span class="fu">desc</span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">top_n</span><span class="op">(</span><span class="fl">100</span>, <span class="va">n</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/reorder.factor.html">reorder</a></span><span class="op">(</span><span class="va">token</span>, <span class="fu">desc</span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span>, y <span class="op">=</span> <span class="va">n</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_col</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Types"</span>, y <span class="op">=</span> <span class="st">"Token frequency"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_y_continuous</span><span class="op">(</span>labels <span class="op">=</span> <span class="fu">scales</span><span class="fu">::</span><span class="va"><a href="https://scales.r-lib.org/reference/comma.html">comma</a></span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span> <span class="va">modality</span>, ncol <span class="op">=</span> <span class="fl">1</span>, scales <span class="op">=</span> <span class="st">"free"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>axis.text.x <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>angle <span class="op">=</span> <span class="fl">90</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-eda-masc-count-modality-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="exploration_files/figure-html/fig-eda-masc-count-modality-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">Figure&nbsp;8.7: Frequency of tokens in the MASC dataset by modality</figcaption></figure>
</div>
</div>
<div class="cell-output-display">
<div id="fig-eda-masc-count-modality-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="exploration_files/figure-html/fig-eda-masc-count-modality-2.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">Figure&nbsp;8.8: Frequency of tokens in the MASC dataset by modality</figcaption></figure>
</div>
</div>
</div>
</div>
<p>frequency analysis can also be used to identify units that are linguistically distinctive or distinctive to a particular group or sub-group in the dataset. For example, we might be interested in identifying words that are distinctive to spoken versus written discourses.</p>
</section></section><section id="sec-eda-co-occurrence" class="level4"><h4 class="anchored" data-anchor-id="sec-eda-co-occurrence">Co-occurrence analysis</h4>
<p>ELL: we want to identify verb particle constructions that are distinctive to spoken versus written discourses. These are verbs that appear as a phrase with a preposition or adverb, such as ‘look up’, ‘look after’. These are common in English, but we want to know two things: which verb particle constructions are most common and do they vary by modality?</p>
<!-- (grammaticalization, syntactic alternations, discourse analysis, etc.) -->
<!--  
- Co-occurrence analysis
  - Are there domain specific collocations?
    - What are common verbs that appear in hedging constructions?
      - Use 'may', 'might', 'will', 'would' to identify hedging constructions
-->
<ul>
<li>Concordance
<ul>
<li>KWIC (keyword in context) This section will discuss keyword in context (KWIC) analyses, which is used to identify meaningful keywords in a given text. It will discuss various ways to analyse a text and extract keywords, as well as discuss various practical applications of KWIC in linguistics.</li>
</ul>
</li>
<li>Collocation
<ul>
<li>PMI (pointwise mutual information)</li>
<li>…</li>
</ul>
</li>
</ul>
<div class="cell" data-hash="exploration_cache/html/masc-transformed-phrasal-verbs_3de2b33f41e7f225286f93589d28fdd6">
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">masc_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">arrange</span><span class="op">(</span><span class="va">doc_id</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">doc_id</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span></span>
<span>    next_lemma <span class="op">=</span> <span class="fu">lead</span><span class="op">(</span><span class="va">lemma</span><span class="op">)</span>,</span>
<span>    next_pos <span class="op">=</span> <span class="fu">lead</span><span class="op">(</span><span class="va">pos</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">pos</span> <span class="op">==</span> <span class="st">"VB"</span> <span class="op">&amp;</span> <span class="va">next_pos</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"RP"</span>, <span class="st">"IN"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 3,094 × 9
&gt; # Groups:   doc_id [304]
&gt;    doc_id modality genre   token_num token  lemma  pos   next_lemma next_pos
&gt;    &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;   
&gt;  1 1      Written  Letters       252 know   know   VB    for        IN      
&gt;  2 10     Written  Email         127 buy    buy    VB    from       IN      
&gt;  3 10     Written  Email         167 buy    buy    VB    from       IN      
&gt;  4 10     Written  Email         248 use    use    VB    as         IN      
&gt;  5 10     Written  Email         309 know   know   VB    if         IN      
&gt;  6 101    Written  Email          87 head   head   VB    down       IN      
&gt;  7 101    Written  Email          92 meet   meet   VB    up         RP      
&gt;  8 102    Written  Email         268 comply comply VB    with       IN      
&gt;  9 103    Written  Email          84 see    see    VB    that       IN      
&gt; 10 103    Written  Email         130 be     be     VB    on         IN      
&gt; # ℹ 3,084 more rows</code></pre>
</div>
</div>
</section></section><section id="sec-eda-unsupervised" class="level3" data-number="8.2.2"><h3 data-number="8.2.2" class="anchored" data-anchor-id="sec-eda-unsupervised">
<span class="header-section-number">8.2.2</span> Unsupervised learning</h3>
<ul class="task-list">
<li>
<input type="checkbox">Overview of unsupervised learning</li>
</ul>
<p>Unsupervised learning which is a machine learning approach that does not assume any particular relationship between variables in a dataset … (expand on this definition)</p>
<ul class="task-list">
<li>
<input type="checkbox">An overview of the some of the questions we will entertain in this section.</li>
</ul>
<section id="sec-eda-clustering" class="level4"><h4 class="anchored" data-anchor-id="sec-eda-clustering">Clustering</h4>
<p>ELL: we want to identify and group genres based on linguistic features or co-occurrence patterns. The better we can identify and group genres, the better we can identify and group linguistic features or co-occurrence patterns that are distinctive to a particular genre.</p>
<!--  

- Clustering
  - Are there discernible clusters that separate spoken from written discourses based on linguistic features or co-occurrence patterns?
        - Use k-means clustering to identify clusters of linguistic features or co-occurrence patterns
        - Use hierarchical clustering to identify clusters of linguistic features or co-occurrence patterns

-->
<p>This section will discuss clustering techniques, which are used to partition data into clusters based on similarity. It will discuss various approaches to clustering, such as k-means and hierarchical clustering, as well as discuss their use cases in linguistics.</p>
<ul>
<li>K-means (pre-defined number of clusters)</li>
<li>Hierarchical clustering (dendrogram)</li>
</ul></section><section id="sec-eda-topic-modeling" class="level4"><h4 class="anchored" data-anchor-id="sec-eda-topic-modeling">Topic modeling</h4>
<p>ELL: we want to identify themes or topics that are distinctive to genres or a particular genre. This will help us design a textbook with relevant topics for each genre and the most relevant vocabulary for each topic.</p>
<!--  
- Topic modeling
    - Are there discernible topics that separate spoken from written discourses based on linguistic features or co-occurrence patterns?
        - Use LDA to identify topics of linguistic features or co-occurrence patterns
-->
<p>This section will discuss topic modeling techniques, which are used to identify and group semantically similar topics in unstructured data. It will discuss various approaches to topic modelling, such as Latent Dirichlet Allocation (LDA), and discuss their applications in linguistics.</p>
<ul>
<li>LDA (latent Dirichlet allocation)</li>
<li>LSA (latent semantic analysis)</li>
</ul></section><section id="sec-eda-word-embedding" class="level4"><h4 class="anchored" data-anchor-id="sec-eda-word-embedding">Word embedding</h4>
<p>ELL: we want to meaning similarities and potential differences between spoken and written discourses. This will help provide students with a more nuanced understanding of potential synonyms within and differences between spoken and written discourses.</p>
<!--  
- Word embeddings
  - Do certain words have different nearest neighbors in the embedding space when appear in spoken versus written discourses? What could this tell us about the differences between spoken and written discourses?
    - Use word2vec to identify nearest neighbors of words in spoken and written discourses by training a model on each modality. Compare the nearest neighbors of words in each modality.
  - If I consider hedges to be a semantic class, what are the nearest neighbors of hedges in the embedding space? What could this tell us about the semantic class of hedges?
    - Use word2vec to identify nearest neighbors of hedges by training a model on the entire dataset. Compare the nearest neighbors of hedges to the nearest neighbors of other words.
-->
<p>This section will discuss word embedding techniques, which are used to represent words in a vector space. It will discuss various approaches to word embedding, such as Word2Vec and GloVe, and discuss their applications in linguistics.</p>
<ul>
<li>Word2vec (skip-gram)</li>
<li>GloVe (global vectors for word representation)</li>
</ul></section></section></section><section id="summary" class="level2" data-number="8.3"><h2 data-number="8.3" class="anchored" data-anchor-id="summary">
<span class="header-section-number">8.3</span> Summary</h2>
<p>Exploratory data analysis is a set of methods that can be used to explore a dataset and to identify new questions and new variables of interest. The methods can be used to describe a dataset and to identify linguistic units that are distinctive to a particular group or sub-group in the dataset. The methods can also be used to identify semantically similar topics in unstructured data. The results of exploratory analysis can be used to inform the development of a hypothesis or to inform the design of a machine learning model.</p>
</section><section id="activities" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="activities">Activities</h2>
<!-- [ ] Add description of the activites -->
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-file-code" aria-label="file-code"></i> Recipe</strong></p>
<p><strong>What</strong>: <a href="https://lin380.github.io/tadr/articles/recipe_11.html">Exploratory methods: descriptive and unsupervised learning analysis methods</a><br><strong>How</strong>: Read Recipe 10 and participate in the Hypothes.is online social annotation.<br><strong>Why</strong>: To illustrate how to prepare a dataset for descriptive and unsupervised machine learning methods and evaluate the results for exploratory data analysis.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-flask" aria-label="flask"></i> Lab</strong></p>
<!-- Analyze, evaluate, and create verbs: https://tips.uark.edu/blooms-taxonomy-verb-chart/ -->
<!-- [ ] update lab -->
<p><strong>What</strong>: <a href="https://github.com/lin380/lab_11">Exploratory Data Analysis</a><br><strong>How</strong>: Clone, fork, and complete the steps in Lab 9.<br><strong>Why</strong>: To gain experience working with coding strategies to prepare, feature engineer, explore, and evaluate results from exploratory data analyses, practice transforming datasets into new object formats and visualizing relationships, and implement organizational strategies for organizing and reporting results in a reproducible fashion.</p>
</div>
</div>
</div>
</section><section id="questions" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="questions">Questions</h2>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><i class="fa-solid fa-wrench" aria-label="wrench"></i> <strong>Conceptual questions</strong></p>
<ol type="1">
<li>What is exploratory data analysis?</li>
<li>How can exploratory data analysis be used to uncover patterns and associations?</li>
<li>Describe the workflow of exploratory data analysis?</li>
<li>What are the advantages and disadvantages of descriptive analysis?</li>
<li>What are the advantages and disadvantages of unsupervised learning?</li>
<li>What is the difference between supervised and unsupervised learning?</li>
<li>How does exploratory data analysis differ from traditional hypothesis testing?</li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><i class="fa-solid fa-wrench" aria-label="wrench"></i> <strong>Technical questions</strong></p>
<ol type="1">
<li>Write a function in R to conduct a hierarchical cluster analysis on a dataset.</li>
<li>Implement a k-means algorithm in R to identify clusters within a dataset.</li>
<li>Implement a Principal Component Analysis (PCA) algorithm in R to identify patterns and associations within a dataset.</li>
<li>Write a function in R to produce a descriptive summary of a dataset.</li>
<li>Conduct a correlation analysis in R to identify relationships between variables in a dataset.</li>
<li>Load a dataset into R and conduct a frequency analysis on the dataset.</li>
<li>Load a dataset into R and conduct a keyword in context analysis on the dataset.</li>
<li>Load a dataset into R and conduct a keyword analysis on the dataset.</li>
<li>Load a dataset into R and conduct a sentiment analysis on the dataset.</li>
<li>Load a dataset into R and conduct a topic modelling analysis on the dataset.</li>
</ol>
</div>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-Gries2023" class="csl-entry" role="listitem">
Gries, Stefan Th. 2023. <span>“Statistical Methods in Corpus Linguistics.”</span> In <em>Readings in Corpus Linguistics: A Teaching and Research Guide for Scholars in Nigeria and Beyond,</em> 78–114.
</div>
<div id="ref-Zipf1949" class="csl-entry" role="listitem">
Zipf, George Kingsley. 1949. <em>Human Behavior and the Principle of Least Effort</em>. Oxford, England: Addison-Wesley Press.
</div>
</div>
</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./analysis.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Analysis</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./prediction.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Prediction</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>
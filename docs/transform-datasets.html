<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>An Introduction to Quantitative Text Analysis for Linguistics - 7&nbsp; Transform datasets</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./analysis.html" rel="next">
<link href="./curate-datasets.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="site_libs/kePrint-0.0.1/kePrint.js"></script><link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><link rel="stylesheet" href="assets/css/mini.css">
</head>
<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./preparation.html">Preparation</a></li><li class="breadcrumb-item"><a href="./transform-datasets.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Transform datasets</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">An Introduction to Quantitative Text Analysis for Linguistics</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/qtalr/book" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./qtalr-manuscript.pdf" rel="" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./orientation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Orientation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./text-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Text analysis in context</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./understanding-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Understanding data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./approaching-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Approaching analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./framing-research.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Framing research</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./preparation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preparation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./acquire-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Acquire data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./curate-datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Curate datasets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./transform-datasets.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Transform datasets</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Analysis</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./exploration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Exploration</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Inference</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./communication.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Communication</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reporting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Reports</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./collaboration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Collaboration</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./feedback.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Feedback <i class="fa-solid fa-comment" aria-label="comment"></i></span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#sec-td-normalization" id="toc-sec-td-normalization" class="nav-link active" data-scroll-target="#sec-td-normalization"><span class="header-section-number">7.1</span> Normalization</a>
  <ul class="collapse">
<li><a href="#sec-td-normalization-orientation" id="toc-sec-td-normalization-orientation" class="nav-link" data-scroll-target="#sec-td-normalization-orientation"><span class="header-section-number">7.1.1</span> Orientation</a></li>
  <li><a href="#sec-td-normalization-application" id="toc-sec-td-normalization-application" class="nav-link" data-scroll-target="#sec-td-normalization-application"><span class="header-section-number">7.1.2</span> Application</a></li>
  </ul>
</li>
  <li>
<a href="#sec-td-recoding" id="toc-sec-td-recoding" class="nav-link" data-scroll-target="#sec-td-recoding"><span class="header-section-number">7.2</span> Recoding</a>
  <ul class="collapse">
<li><a href="#sec-td-recoding-orientation" id="toc-sec-td-recoding-orientation" class="nav-link" data-scroll-target="#sec-td-recoding-orientation"><span class="header-section-number">7.2.1</span> Orientation</a></li>
  <li><a href="#sec-td-recoding-application" id="toc-sec-td-recoding-application" class="nav-link" data-scroll-target="#sec-td-recoding-application"><span class="header-section-number">7.2.2</span> Application</a></li>
  </ul>
</li>
  <li>
<a href="#sec-td-tokenization" id="toc-sec-td-tokenization" class="nav-link" data-scroll-target="#sec-td-tokenization"><span class="header-section-number">7.3</span> Tokenization</a>
  <ul class="collapse">
<li><a href="#sec-td-tokenization-orientation" id="toc-sec-td-tokenization-orientation" class="nav-link" data-scroll-target="#sec-td-tokenization-orientation"><span class="header-section-number">7.3.1</span> Orientation</a></li>
  <li><a href="#sec-td-tokenization-application" id="toc-sec-td-tokenization-application" class="nav-link" data-scroll-target="#sec-td-tokenization-application"><span class="header-section-number">7.3.2</span> Application</a></li>
  </ul>
</li>
  <li>
<a href="#sec-td-generation" id="toc-sec-td-generation" class="nav-link" data-scroll-target="#sec-td-generation"><span class="header-section-number">7.4</span> Generation</a>
  <ul class="collapse">
<li><a href="#sec-td-generation-orientation" id="toc-sec-td-generation-orientation" class="nav-link" data-scroll-target="#sec-td-generation-orientation"><span class="header-section-number">7.4.1</span> Orientation</a></li>
  <li><a href="#sec-td-generation-application" id="toc-sec-td-generation-application" class="nav-link" data-scroll-target="#sec-td-generation-application"><span class="header-section-number">7.4.2</span> Application</a></li>
  </ul>
</li>
  <li>
<a href="#sec-td-merging" id="toc-sec-td-merging" class="nav-link" data-scroll-target="#sec-td-merging"><span class="header-section-number">7.5</span> Merging</a>
  <ul class="collapse">
<li><a href="#sec-td-merging-orientation" id="toc-sec-td-merging-orientation" class="nav-link" data-scroll-target="#sec-td-merging-orientation"><span class="header-section-number">7.5.1</span> Orientation</a></li>
  <li><a href="#sec-td-merging-application" id="toc-sec-td-merging-application" class="nav-link" data-scroll-target="#sec-td-merging-application"><span class="header-section-number">7.5.2</span> Application</a></li>
  </ul>
</li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  <li><a href="#activities" id="toc-activities" class="nav-link" data-scroll-target="#activities">Activities</a></li>
  <li><a href="#questions" id="toc-questions" class="nav-link" data-scroll-target="#questions">Questions</a></li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/qtalr/book/edit/main/transform-datasets.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/qtalr/book/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title"><span id="sec-transform-datasets" class="quarto-section-identifier"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Transform datasets</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><div class="callout callout-style-default callout-caution callout-titled" title="Caution">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p><i class="fa-solid fa-route" aria-label="route"></i> In progress…</p>
</div>
</div>
<!--

Content:

- [x] Add normalization section
- [x] Add recoding section
- [ ] Add tokenization section
- [ ] Add generation section
- [ ] Add merging section

Exercises:

- [ ] add concept questions to Activities
- [ ] add exercises to Activities
- [ ] add thought questions/ case studies to prose sections

Formatting:

- [ ] Add a description of the importance of the unit of analysis and unit of observation in the transformation process.
  - In the curation process, the original data and utility of the dataset is priority. In the transformation process, the focus is on the analysis and the unit of analysis and unit of observation are the primary considerations.
- [ ] Point out that some units of observation will require that the data have more textual context (e.g. syntactic parsing) than others (e.g. word frequencies). It is important that the presentation of the transformation steps are no necessarily in the order in which they are applied.

-->
<blockquote class="blockquote">
<p>Nothing is lost. Everything is transformed.</p>
<p>— Michael Ende, The Neverending Story</p>
</blockquote>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-list-alt" aria-label="list-alt"></i> Outcomes</strong></p>
<!-- Remember and understand verbs: https://tips.uark.edu/blooms-taxonomy-verb-chart/ -->
<!-- [ ] update to outcomes -->
<ul>
<li>What is the role of data transformation in a text analysis project?</li>
<li>What are the general processes for preparing datasets for analysis?</li>
<li>How do each of these general processes transform datasets?</li>
</ul>
</div>
</div>
</div>
<!-- 
- Transformation: goals
  - Prepare curated dataset for analysis
  - Manipulate dataset row-wise and/ or column-wise
  - Focus on particular analysis needs: unit of analysis, unit of observation, operationalization of variables, etc.
-->
<p>In this chapter, we will focus on transforming a curated dataset to refine and possibly expand its relational characteristics to align with our research. The transformation process is divided into four categories: text normalization, variable recoding, text tokenization, variable generation, and observation/ variable merging. These categories are not sequential but may occur in any order based on the researcher’s evaluation of the dataset characteristics and the desired outcome.</p>
<p>It is sometimes necessary to create several transformed datasets from one curated dataset in cases where there are multiple analyses to be performed. This why we start with a curated dataset rather than directly deriving a transformed dataset from the original data. It allows for various transformation methods to produce different formats for different analyses.</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-terminal" aria-label="terminal"></i> Swirl lesson</strong></p>
<!-- Remember and understand verbs: https://tips.uark.edu/blooms-taxonomy-verb-chart/ -->
<!-- 
- [ ] Update lesson name, 
- [ ] update lesson purpose
-->
<p><strong>What</strong>: <a href="https://github.com/qtalr/lessons">Reshape dataset rows, Reshape dataset columns</a><br><strong>How</strong>: In the R Console pane load <code>swirl</code>, run <code>swirl()</code>, and follow prompts to select the lesson.<br><strong>Why</strong>: …</p>
</div>
</div>
</div>
<!-- 

- Normalization (column-wise):  to standardize or simplify the text to reduce variability
  - Artifact removal
- Recoding (column-wise)
  - Classify
  - Derive
- Tokenization (row-wise): to segment the text into meaningful components
  - Words, n-grams, sentences
- Generation (row-wise and column-wise)
  - Lexical annotation
  - Syntactic annotation
- Merging (row-wise/ column-wise)
  - Joining datasets

---

- Summary
- Activities

-->
<section id="sec-td-normalization" class="level2" data-number="7.1"><h2 data-number="7.1" class="anchored" data-anchor-id="sec-td-normalization">
<span class="header-section-number">7.1</span> Normalization</h2>
<!--  

column-wise: 

- Standardize text and remove unwanted variation
  - Artifact removal
  - Case conversion (lowercasing)
  - Punctuation and extraneous character removal
  - Adjustment of forms (e.g. contractions, numbers, abbreviations,  )

- Data:
  - Europarl

- R: 
  - stringr::str_replace_all()
  - stringr::str_remove_all()
-->
<p>The process of normalizing datasets in essence is to sanitize the values of variable or set of variables such that there are no artifacts that will contaminate subsequent processing. It may be the case that non-linguistic metadata may require normalization but more often than not linguistic information is the most common target for normalization as text often includes artifacts from the acquisition process which will not be desired in the analysis.</p>
<section id="sec-td-normalization-orientation" class="level3" data-number="7.1.1"><h3 data-number="7.1.1" class="anchored" data-anchor-id="sec-td-normalization-orientation">
<span class="header-section-number">7.1.1</span> Orientation</h3>
<p>To explore some of the strategies of normalization, we will look at the Europarl Corpus. As we are working working towards transforming a curated dataset, we will start by getting oriented to the dataset. Following the reproducible research principles, I will assume that the curated dataset and its associated data dictionary are in the <em>data/derived/</em> directory, as seen in <a href="#exm-td-europarl-curated-structure">Example&nbsp;<span>7.1</span></a>.</p>
<div id="exm-td-europarl-curated-structure" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.1 </strong></span>&nbsp;</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">data/</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> analysis/</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> derived/</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>   ├── europarl_curated_dd.csv</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>   └── europarl/</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>       └── europarl_curated.csv</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="ex">└──</span> original/</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The contents of the data dictionary for this dataset appears in <a href="#tbl-td-europarl-dd">Table&nbsp;<span>7.1</span></a>.</p>
<div class="cell" data-hash="transform-datasets_cache/html/tbl-td-europarl-dd_38c5f48a11ec0de73dcf07bc152a3685">
<div class="cell-output-display">
<div id="tbl-td-europarl-dd" class="anchored">
<table class="table table-sm table-striped small" data-quarto-postprocess="true">
<caption>Table&nbsp;7.1: Data dictionary for the Europarl Corpus.</caption>
<thead><tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">variable</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">name</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">variable_type</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">doc_id</td>
<td style="text-align: left;">Document ID</td>
<td style="text-align: left;">numeric</td>
<td style="text-align: left;">Unique identification number for each document</td>
</tr>
<tr class="even">
<td style="text-align: left;">type</td>
<td style="text-align: left;">Document Type</td>
<td style="text-align: left;">categorical</td>
<td style="text-align: left;">Type of document; either 'Source' (Spanish) or 'Target' (English)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">line_id</td>
<td style="text-align: left;">Line ID</td>
<td style="text-align: left;">numeric</td>
<td style="text-align: left;">Unique identification number for each line in each document type</td>
</tr>
<tr class="even">
<td style="text-align: left;">lines</td>
<td style="text-align: left;">Lines</td>
<td style="text-align: left;">categorical</td>
<td style="text-align: left;">Content of the lines in the document</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
<p>This dataset contains transcribed source language (Spanish) and translated target language (English) from the proceedings of the European Parliament. The unit of observation is the <code>lines</code> variable whose values are are lines of dialog.</p>
<p>Let’s read in the dataset CSV file with <code>read_csv()</code> and inspect the first lines of the dataset with <code>slice_head()</code> in <a href="#exm-tb-europarl-preview">Example&nbsp;<span>7.2</span></a>.</p>
<div id="exm-tb-europarl-preview" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.2 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-europarl-read-show_0ff77764a35dd1bdeac9a5759cbf410e">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Read in the dataset</span></span>
<span><span class="va">europarl_curated_tbl</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">read_csv</span><span class="op">(</span>file <span class="op">=</span> <span class="st">"../data/derived/europarl_curated.csv"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview the first 10 lines</span></span>
<span><span class="va">europarl_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-hash="transform-datasets_cache/html/td-europarl-read-run_9c9ce96fff502b287c97fb1bcb18f0ed">
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 10 × 4
&gt;     doc_id type   line_id lines                                                 
&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;                                                 
&gt;  1 1965735 Source       1 "Reanudación del período de sesiones"                 
&gt;  2       1 Target       1 "Resumption of the session"                           
&gt;  3 1965736 Source       2 "Declaro reanudado el período de sesiones del Parlame…
&gt;  4       2 Target       2 "I declare resumed the session of the European Parlia…
&gt;  5 1965737 Source       3 "Como todos han podido comprobar, el gran \"efecto de…
&gt;  6       3 Target       3 "Although, as you will have seen, the dreaded 'millen…
&gt;  7 1965738 Source       4 "Sus Señorías han solicitado un debate sobre el tema …
&gt;  8       4 Target       4 "You have requested a debate on this subject in the c…
&gt;  9 1965739 Source       5 "A la espera de que se produzca, de acuerdo con mucho…
&gt; 10       5 Target       5 "In the meantime, I should like to observe a minute' …</code></pre>
</div>
</div>
</div>
<p>Simply looking at the first 10 lines of this dataset gives us a clearer sense of the dataset structure, but, in terms of normalization procedures we might apply, it is likely not sufficient. We want to get a sense of any potential inconsistencies in the dataset, in particular in the <code>lines</code> variable. Since this is a large dataset with 3931468 observations, we will need to explore the dataset in manageable chunks. The <code>slice_sample()</code> function will allow us to randomly sample a subset of the dataset of a certain number of observations specified by the <code>n =</code> argument, as seen in <a href="#exm-td-europarl-sample-1">Example&nbsp;<span>7.3</span></a>.</p>
<div id="exm-td-europarl-sample-1" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.3 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-europarl-sample-1_5c28c73edb03d6666ae58ee9a4e4e12a">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Randomly sample 5 observations</span></span>
<span><span class="va">europarl_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_sample</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 5 × 4
&gt;    doc_id type   line_id lines                                                  
&gt;     &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;                                                  
&gt; 1 1979130 Source   13396 Nosotros no apostamos aquí, en este Parlamento, por lo…
&gt; 2 3322228 Source 1356494 (SK) Señor Presidente, me he abstenido de votar porque…
&gt; 3  140652 Target  140652 It is these last two, however, together with Finland, …
&gt; 4 2145661 Source  179927 Son las mujeres de esos mismos países: Egipto, Somalia…
&gt; 5 2269815 Source  304081 Permítanme añadir que, en nuestro último llamamiento p…</code></pre>
</div>
</div>
</div>
<p>We should run the code in <a href="#exm-td-europarl-sample-1">Example&nbsp;<span>7.3</span></a> multiple times to get a sense of the variation in the dataset.</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-hand-point-up" aria-label="hand-point-up"></i> Tip</strong></p>
<p>R functions which return samples (<em>e.g.</em> <code>slice_sample()</code>) are generated using pseudo-random number generators. These generators are initialized with a seed value. You can control the seed value R uses to generate the random numbers by using the <code><a href="https://rdrr.io/r/base/Random.html">set.seed()</a></code> function and setting the seed value to a number of your choice. It is important to note that setting a seed only affects the subsequent random number generation.</p>
<p>Using <code><a href="https://rdrr.io/r/base/Random.html">set.seed()</a></code> is useful when you want to ensure that the same random numbers are generated each time you run the code. This is particularly helpful when you want to reproduce results in a report or other document.</p>
</div>
</div>
</div>
<p>In the case of the Europarl corpus dataset, it may be useful to see the source and target lines in the same sample. Do do this, we can first sample from the <code>line_id</code> variable and then filter the <code>europarl_curated_tbl</code> wit the <code><a href="https://rdrr.io/r/stats/filter.html">filter()</a></code> function and the <code>%in%</code> operator to select the lines that match the sampled <code>line_id</code> values, as seen in <a href="#exm-td-europarl-sample-2">Example&nbsp;<span>7.4</span></a>.</p>
<div id="exm-td-europarl-sample-2" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.4 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-europarl-sample-2_c092e311c37be76d1966c76fe4278539">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Randomly sample 5 line_id values</span></span>
<span><span class="va">line_id_sample_vec</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">europarl_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">distinct</span><span class="op">(</span><span class="va">line_id</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">slice_sample</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">5</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">pull</span><span class="op">(</span><span class="va">line_id</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Select the lines that match the sampled line_id values</span></span>
<span><span class="va">europarl_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">line_id</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="va">line_id_sample_vec</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 10 × 4
&gt;     doc_id type   line_id lines                                                 
&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;                                                 
&gt;  1 1992525 Source   26791 La sociedad del conocimiento es algo más, y también p…
&gt;  2   26791 Target   26791 The knowledge society is more than that, and it may a…
&gt;  3 2247038 Source  281304 Especialmente en la industria de alta tecnología pued…
&gt;  4  281304 Target  281304 Particularly in the technical and hi-tech industry, t…
&gt;  5 2325587 Source  359853 - (IT) Señora Presidenta, Comisario, Señorías, quiero…
&gt;  6  359853 Target  359853 . (IT) Madam President, Commissioner, ladies and gent…
&gt;  7 2573895 Source  608161 En consecuencia, nuestro Grupo ha votado en contra.   
&gt;  8  608161 Target  608161 Consequently, our group voted against.                
&gt;  9 2581569 Source  615835 Al margen de ello, es todo el club de los seis, esos …
&gt; 10  615835 Target  615835 Beyond that, it is the whole club of six, these count…</code></pre>
</div>
</div>
</div>
<p>After running the code in <a href="#exm-td-europarl-sample-1">Example&nbsp;<span>7.3</span></a> and <a href="#exm-td-europarl-sample-2">Example&nbsp;<span>7.4</span></a> multiple times, I identified a number of artifacts that we will want to consider addressing. These are included in <a href="#tbl-td-europarl-normalization">Table&nbsp;<span>7.2</span></a>.</p>
<div id="tbl-td-europarl-normalization" class="anchored">
<table class="table-sm table-striped small table">
<caption>Table&nbsp;7.2: Characteristics of the Europarl Corpus dataset that may require normalization.</caption>
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead><tr class="header">
<th style="text-align: left;">Description</th>
<th style="text-align: left;">Examples</th>
<th style="text-align: left;">Concern</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Non-speech annotations</td>
<td style="text-align: left;">
<code>(Abucheos)</code>, <code>(A4-0247/98)</code>, <code>(The sitting was opened at 09:00)</code>
</td>
<td style="text-align: left;">Not of interest for our analysis</td>
</tr>
<tr class="even">
<td style="text-align: left;">Inconsistent whitespace</td>
<td style="text-align: left;">
<code>5 % ,</code>, <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code>, <code>Palacio' s</code>
</td>
<td style="text-align: left;">May be problematic for tokenization</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Non-sentence punctuation</td>
<td style="text-align: left;"><code>-</code></td>
<td style="text-align: left;">May be problematic for tokenization</td>
</tr>
<tr class="even">
<td style="text-align: left;">Abbreviations</td>
<td style="text-align: left;">
<code>Mr.</code>, <code>Sr.</code>, <code>Mme.</code>, <code>Mr</code>, <code>Sr</code>, <code>Mme</code>, <code>Mister</code>, <code>Señor</code>, <code>Madam</code>
</td>
<td style="text-align: left;">May be problematic for tokenization</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Text case</td>
<td style="text-align: left;">
<code>The</code>, <code>the</code>, <code>White</code>, <code>white</code>
</td>
<td style="text-align: left;">May be problematic for tokenization</td>
</tr>
</tbody>
</table>
</div>
<p>The first three items in <a href="#tbl-td-europarl-normalization">Table&nbsp;<span>7.2</span></a> are relatively straightforward. Non-speech annotations most likely are not relevant for our research. Inconsistent whitespace and non-sentence punctuation may be problematic for tokenization that depends on whitespace and punctuation regularities.</p>
<p>The other two considerations are more contingent on our research aims. The existence of various forms for the same word, abbreviated and unabreviated, introduces variability may not be of interest for our analysis. Secondly, common conventions for capitalization in prose can introduce unwanted variability. If we leave the text as is, the tokens <code>The</code> and <code>the</code> will be treated as distinct. If we convert the text to lowercase, the tokens <code>White</code> and <code>white</code> will be treated as the same, even if <code>White</code> corresponds to a proper noun (<em>e.g.</em> <code>White House</code>).</p>
<p>These observations provide us a roadmap for the normalization process. For demonstration, let’s focus only on a couple of these cases: removing parlimentary session descriptions and extra whitespace.</p>
</section><section id="sec-td-normalization-application" class="level3" data-number="7.1.2"><h3 data-number="7.1.2" class="anchored" data-anchor-id="sec-td-normalization-application">
<span class="header-section-number">7.1.2</span> Application</h3>
<p>Identifying our normalization goals is an important first step. The next step is to identify the procedures that will accomplish these goals. The majority of text normalization procedures can be accomplished with the <code>stringr</code> package <span class="citation" data-cites="R-stringr">(<a href="references.html#ref-R-stringr" role="doc-biblioref">Wickham 2022</a>)</span>. This package provides a number of functions for manipulating text. The workhorse functions we will use for our tasks are the <code>str_remove()</code> and <code>str_replace()</code> functions. As the these functions give us the ability to remove or replace text. Our task is to identify the patterns we want to remove or replace.</p>
<p>Before we modify any lines, let’s try craft a search pattern to identify the text of interest. This is done to avoid over- or under-generalizing the search pattern. If we are too general, we may end up removing or replacing text that we want to keep. If we are too specific, we may not remove or replace all the text we want to remove or replace.</p>
<!-- non-speech -->
<p>Let’s start by identifying non-parlimentary speech. Two functions from the <code>stringr</code> package come in handy here: <code>str_detect()</code> and <code>str_extract()</code>. <code>str_detect()</code> detects a pattern in a character vector and returns a logical vector, <code>TRUE</code> if the pattern is detected and <code>FALSE</code> if it is not. <code>str_extract()</code> extracts the text in a character vector that matches a pattern.</p>
<p><code>str_detect()</code> pairs well with the <code><a href="https://rdrr.io/r/stats/filter.html">filter()</a></code> function to return observations that match a pattern in a character vector. <code>str_extract()</code> pairs well with the <code>mutate()</code> function to create a new variable which contains character vector that match a pattern.</p>
<p>Let’s start with the <code>str_detect()</code> function. We will use this function to identify the lines that contain the parliamentary session descriptions. From the examples above, we can see that these instances are wrapped with parentheses <code>(</code> and <code>)</code>. The text within the parentheses can vary, so we need a Regular Expression to do the heavy lifting. To start out we can match any one or multiple characters with <code>.+</code>. But it is important to recognize the <code>+</code> (and also the <code>*</code>) operators are ‘greedy’, meaning that if there are multiple matches, the longest match will be returned. In this case, we want to match the shortest match. To do this we can use the <code>?</code> operator to make the <code>+</code> operator ‘lazy’. This will match the shortest match.</p>
<p>Our test code appears in <a href="#exm-td-europarl-search-non-speech">Example&nbsp;<span>7.5</span></a>.</p>
<div id="exm-td-europarl-search-non-speech" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.5 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-europarl-search-non-speech_75bfec11cb1c22464debd01d5b95e883">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Identify non-speech lines</span></span>
<span><span class="va">europarl_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="fu">str_detect</span><span class="op">(</span><span class="va">lines</span>, <span class="st">"\\(.+?\\)"</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_sample</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 10 × 4
&gt;     doc_id type   line_id lines                                                 
&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;                                                 
&gt;  1 3225772 Source 1260038 (PT) Señor Presidente, quisiera plantear dos pregunta…
&gt;  2 3715842 Source 1750108 (El Parlamento decide la devolución a la Comisión)    
&gt;  3 1961715 Target 1961715 (Parliament adopted the resolution)                   
&gt;  4 1429470 Target 1429470 27, originally Greens/EFA amendment in FEMM); binding…
&gt;  5   51632 Target   51632 Question No 8 by (H-0376/00):                         
&gt;  6 2482671 Source  516937 La Comisión propone proporcionar a las Agencias nacio…
&gt;  7 1059628 Target 1059628 (The President cut off the speaker)                   
&gt;  8 1507254 Target 1507254 in writing. - (LT) I welcomed this document, because …
&gt;  9 2765325 Source  799591 (Aplausos)                                            
&gt; 10 2668536 Source  702802 &nbsp;&nbsp; Las preguntas que, por falta de tiempo, no han rec…</code></pre>
</div>
</div>
</div>
<p>The results from <a href="#exm-td-europarl-search-non-speech">Example&nbsp;<span>7.5</span></a> show that we have identified the lines that contain at least one of the parliamentary session description annotations. A more targeted search to identify specific instances of the parliamentary session descriptions can be accomplished adding the <code>str_extract()</code> function as seen in <a href="#exm-td-europarl-search-non-speech-2">Example&nbsp;<span>7.6</span></a>.</p>
<div id="exm-td-europarl-search-non-speech-2" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.6 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-europarl-search-non-speech-2_87420e7b18bf281a565fede4b6c38f5f">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Extract non-speech fragments</span></span>
<span><span class="va">europarl_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="fu">str_detect</span><span class="op">(</span><span class="va">lines</span>, <span class="st">"\\(.+?\\)"</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>non_speech <span class="op">=</span> <span class="fu">str_extract</span><span class="op">(</span><span class="va">lines</span>, <span class="st">"\\(.+?\\)"</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_sample</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 10 × 5
&gt;     doc_id type   line_id lines                                       non_speech
&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;                                       &lt;chr&gt;     
&gt;  1 3225772 Source 1260038 (PT) Señor Presidente, quisiera plantear d… (PT)      
&gt;  2 3715842 Source 1750108 (El Parlamento decide la devolución a la C… (El Parla…
&gt;  3 1961715 Target 1961715 (Parliament adopted the resolution)         (Parliame…
&gt;  4 1429470 Target 1429470 27, originally Greens/EFA amendment in FEM… (para. 53)
&gt;  5   51632 Target   51632 Question No 8 by (H-0376/00):               (H-0376/0…
&gt;  6 2482671 Source  516937 La Comisión propone proporcionar a las Age… (correspo…
&gt;  7 1059628 Target 1059628 (The President cut off the speaker)         (The Pres…
&gt;  8 1507254 Target 1507254 in writing. - (LT) I welcomed this documen… (LT)      
&gt;  9 2765325 Source  799591 (Aplausos)                                  (Aplausos)
&gt; 10 2668536 Source  702802 &nbsp;&nbsp; Las preguntas que, por falta de tiempo,… (Véase el…</code></pre>
</div>
</div>
</div>
<p>The results from <a href="#exm-td-europarl-search-non-speech-2">Example&nbsp;<span>7.6</span></a> show that we have identified the lines that contain parliamentary session description annotations and extracted this text –or have we? What if a given line contains more than one parliamentary session description annotation? It turns out that <code>str_extract()</code> only returns the first match. To return all matches we can use the <code>str_extract_all()</code> function. Let’s try again, in <a href="#exm-td-europarl-search-non-speech-3">Example&nbsp;<span>7.7</span></a>.</p>
<div id="exm-td-europarl-search-non-speech-3" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.7 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-europarl-search-non-speech-3_5d4d52bfe56571eebc8a2f886670d00b">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Extract non-speech fragments</span></span>
<span><span class="va">europarl_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="fu">str_detect</span><span class="op">(</span><span class="va">lines</span>, <span class="st">"\\(.+?\\)"</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>non_speech <span class="op">=</span> <span class="fu">str_extract_all</span><span class="op">(</span><span class="va">lines</span>, <span class="st">"\\(.+?\\)"</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">slice_sample</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 10 × 5
&gt;     doc_id type   line_id lines                                       non_speech
&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;                                       &lt;list&gt;    
&gt;  1 3225772 Source 1260038 (PT) Señor Presidente, quisiera plantear d… &lt;chr [1]&gt; 
&gt;  2 3715842 Source 1750108 (El Parlamento decide la devolución a la C… &lt;chr [1]&gt; 
&gt;  3 1961715 Target 1961715 (Parliament adopted the resolution)         &lt;chr [1]&gt; 
&gt;  4 1429470 Target 1429470 27, originally Greens/EFA amendment in FEM… &lt;chr [1]&gt; 
&gt;  5   51632 Target   51632 Question No 8 by (H-0376/00):               &lt;chr [1]&gt; 
&gt;  6 2482671 Source  516937 La Comisión propone proporcionar a las Age… &lt;chr [2]&gt; 
&gt;  7 1059628 Target 1059628 (The President cut off the speaker)         &lt;chr [1]&gt; 
&gt;  8 1507254 Target 1507254 in writing. - (LT) I welcomed this documen… &lt;chr [1]&gt; 
&gt;  9 2765325 Source  799591 (Aplausos)                                  &lt;chr [1]&gt; 
&gt; 10 2668536 Source  702802 &nbsp;&nbsp; Las preguntas que, por falta de tiempo,… &lt;chr [1]&gt;</code></pre>
</div>
</div>
</div>
<p>OK, that might not be what you expected. The <code>str_extract_all()</code> function returns a list of character vectors. This is because for any given line in <code>lines</code> there may be a different number of matches. To maintain the data frame as rectangular, a list is returned for each value of <code>non_speech</code>. We could expand the list into a data frame with the <code>unnest()</code> function from the <code>tidyr</code> package if our goal were to work with these matches. But that is not our aim. Rather, we want to know if we have multiple matches per line. Note that the information provided for the <code>non_speech</code> column by the tibble object tells use that we have some lines with muliple matches, as we can see in line 6 of our small sample. So good thing we checked!</p>
<p>Let’s now remove these parliamentary session description annotations from each line in the <code>lines</code> column. We turn to <code>str_remove_all()</code>, a variant of <code>str_remove()</code>, that, as you expect, will remove multiple matches in a single line. We will use the <code>mutate()</code> function to overwrite the <code>lines</code> column with the modified text. The code is seen in <a href="#exm-td-europarl-remove-non-speech">Example&nbsp;<span>7.8</span></a>.</p>
<div id="exm-td-europarl-remove-non-speech" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.8 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-europarl-remove-non-speech_c2d6c1185e0bded241bef985c7383ead">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Remove non-speech fragments</span></span>
<span><span class="va">europarl_curated_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">europarl_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>lines <span class="op">=</span> <span class="fu">str_remove_all</span><span class="op">(</span><span class="va">lines</span>, <span class="st">"\\(.+?\\)"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>I recommend spot checking the results of this normalization step by running the code in <a href="#exm-td-europarl-search-non-speech">Example&nbsp;<span>7.5</span></a> again, if nothing appears we’ve done our job.</p>
<p>When you are content with the results, drop the observations that have no text in the <code>lines</code> column given the entire line was non-speech. This can be done with the <code><a href="https://rdrr.io/r/base/NA.html">is.na()</a></code> function and the <code><a href="https://rdrr.io/r/stats/filter.html">filter()</a></code> function as seen in <a href="#exm-td-europarl-drop-empty-lines">Example&nbsp;<span>7.9</span></a>.</p>
<div id="exm-td-europarl-drop-empty-lines" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.9 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-europarl-drop-empty-lines_ad584e7a95de1d2beadd0fc119a4bdf2">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Drop empty lines</span></span>
<span><span class="va">europarl_curated_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">europarl_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span class="op">(</span><span class="va">lines</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<!-- extra whitespace -->
<p>The second item of business to address is the extra whitespace we observed in <a href="#tbl-td-europarl-normalization">Table&nbsp;<span>7.2</span></a>. If we consider the extra whitespace cases, we can categorize them into two types: multiple spaces that should be a single space (<em>e.g.</em> <code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code>) and single spaces that occur within a word (<em>e.g.</em> <code>5 % ,</code> or <code>Palacio' s</code>).</p>
<p>To deal with muliple spaces, we can turn to the <code>str_replace_all()</code> function. This function will replace a pattern with a replacement string for every pattern match. In this case, we want to replace multiple spaces with a single space. We can use the <code>\\s+</code> pattern to match one or more spaces and then replace it with <code>\\s</code> or a single whitespace character <code>" "</code>.</p>
<p>Before we apply this normalization step, let’s assess how many instances of multiple spaces we have in the dataset. We can use the <code>str_count()</code> function to count the number of matches for a pattern. The pattern we want needs to be a bit more precise than <code>\\s+</code>, because this matches one or more. We want to match <em>two</em> or more. Using the regular expression operator <code>{,}</code> we can specify our pattern to be <code>\\s{2,}</code>, <em>i.e.</em> two or more continguous whitespaces. Let’s count and sum all these matches. The code is seen in <a href="#exm-td-europarl-count-whitespace">Example&nbsp;<span>7.10</span></a>.</p>
<div id="exm-td-europarl-count-whitespace" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.10 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-europarl-count-whitespace_f4b5f844a9fcb8b82952a75df115ede6">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Count multiple spaces</span></span>
<span><span class="va">europarl_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>multiple_spaces <span class="op">=</span> <span class="fu">str_count</span><span class="op">(</span><span class="va">lines</span>, <span class="st">"\\s{2,}"</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">summarize</span><span class="op">(</span>total_multiple_spaces <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">multiple_spaces</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 1 × 1
&gt;   total_multiple_spaces
&gt;                   &lt;int&gt;
&gt; 1                130628</code></pre>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-exclamation-triangle" aria-label="exclamation-triangle"></i> Warning</strong></p>
<p>You may be wondering what the extra parameter <code>na.rm = TRUE</code> is doing in the <code><a href="https://rdrr.io/r/base/sum.html">sum()</a></code> function. This parameter tells R to ignore values that are <code>NA</code> (not available). This is important because if we don’t ignore <code>NA</code> values, the <code><a href="https://rdrr.io/r/base/sum.html">sum()</a></code> function will return <code>NA</code> if there are any <code>NA</code> values in the vector. The code in <a href="#exm-td-europarl-count-whitespace">Example&nbsp;<span>7.10</span></a> will return <code>NA</code> when the <code>\\s{2,}</code> doesn’t match for a given line. This is because the <code>str_count()</code> function returns <code>NA</code> when there are no matches. If we don’t ignore these <code>NA</code> values, the <code><a href="https://rdrr.io/r/base/sum.html">sum()</a></code> function will return <code>NA</code> for the entire dataset.</p>
</div>
</div>
</div>
<p>The results from <a href="#exm-td-europarl-count-whitespace">Example&nbsp;<span>7.10</span></a> show that we have over 130k instances of multiple spaces. Let’s replace these with a single space. The code is seen in <a href="#exm-td-europarl-remove-multiple-whitespace">Example&nbsp;<span>7.11</span></a>.</p>
<div id="exm-td-europarl-remove-multiple-whitespace" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.11 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-europarl-remove-multiple-whitespace_5a81e47beee2d941134ee746ccabf74d">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Remove multiple spaces</span></span>
<span><span class="va">europarl_curated_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">europarl_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>lines <span class="op">=</span> <span class="fu">str_replace_all</span><span class="op">(</span><span class="va">lines</span>, <span class="st">"\\s{2,}"</span>, <span class="st">"\\s"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>To check our work, we can run the code in <a href="#exm-td-europarl-count-whitespace">Example&nbsp;<span>7.10</span></a> again. We should see that there are no more instances of multiple spaces.</p>
<p>Now let’s turn to the single spaces that occur within a word. We can use the <code>str_replace_all()</code> function again to replace these single spaces with no space –but is that what we want? Probably not, we want <em>most</em> of the single spaces to remain, otherwise we would have one very, very long string on each line.</p>
<p>Instead, we want to narrow our scope and focus in on whitespace that occurs in particular contexts. One context we can focus on is the single quote <code>'</code>, as in <code>Palacio' s</code>. In this use, the single quote is an apostrophe in a possessive form, but we might want to see if other forms, such as contractions, that also may have this extra whitespace. Let’s check using a regular expression that matches a character string <code>\\w+</code> with single quote <code>'</code> at the end followed by whitespace <code>\\s</code>. To give some more context I will add a character string <code>\\w+</code> after the whitespace. Using the <code>str_extract_all()</code> function we can extract all the matches for this pattern. It returns a list, so we <code>unnest()</code> the list. Then we can pull the vector of matches and list the unique matches to get a sense of the context we are working with. The code is seen in <a href="#exm-td-europarl-search-apostrophe">Example&nbsp;<span>7.12</span></a>.</p>
<div id="exm-td-europarl-search-apostrophe" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.12 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-europarl-search-apostrophe_eac69c35df074aec1f41f154445b744d">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Match apostrophe followed by whitespace</span></span>
<span><span class="va">europarl_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_sample</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>quote_whitespace <span class="op">=</span> <span class="fu">str_extract_all</span><span class="op">(</span><span class="va">lines</span>, <span class="st">"\\w+'\\s\\w+"</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">unnest</span><span class="op">(</span><span class="va">quote_whitespace</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">pull</span><span class="op">(</span><span class="va">quote_whitespace</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt;  [1] "States' neo"             "nobody' s"              
&gt;  [3] "Citizens' Freedoms"      "people' s"              
&gt;  [5] "States' ministers"       "Commission' s"          
&gt;  [7] "patients' rights"        "Pensioners' Party"      
&gt;  [9] "ministers' meetings"     "Ireland' s"             
&gt; [11] "America' s"              "representatives' report"
&gt; [13] "raptaglang' culture"</code></pre>
</div>
</div>
</div>
<p>In <a href="#exm-td-europarl-search-apostrophe">Example&nbsp;<span>7.12</span></a> we can see that we have many singular possessive forms we want to ammend and other forms that we may want to keep –in particular when the single quote is part of a quote or a plural or irregular singular possessive. From various runs of this code, it looks safe to remove whitespace between the single quote and the <code>s</code> in the possessive form We need to be careful not to remove whitespace in other contexts where the single quote is followed by <code>s</code>. To do this we can use the word boundary pattern <code>\\b</code> after the <code>s</code> in our pattern to ensure that the <code>s</code> is not part of a following word. The code is seen in <a href="#exm-td-europarl-remove-apostrophe">Example&nbsp;<span>7.13</span></a>.</p>
<div id="exm-td-europarl-remove-apostrophe" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.13 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-europarl-remove-apostrophe_8b65f6093926209b06e7c4f2a4bb1987">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Remove whitespace after apostrophe</span></span>
<span><span class="va">europarl_transformed_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">europarl_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>lines <span class="op">=</span> <span class="fu">str_replace_all</span><span class="op">(</span><span class="va">lines</span>, <span class="st">"'\\ss\\b"</span>, <span class="st">"'s"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>To check our work, we can run the code in <a href="#exm-td-europarl-search-apostrophe">Example&nbsp;<span>7.12</span></a> again. We should see that there are no more instances of whitespace after the single quote in possessive forms. Once we are satisfied with our work, we can continue with subsequent transformation procedures using the <code>europarl_transformed_tbl</code> data, or save it to a CSV file, create a data dictionary, and move on to the next transformation procedure.</p>
<p>Normalization goals will vary from dataset to dataset but the procedures often follow a similar line of attack to those outlined in this section. There are cases, however, in which normalization procedures are more easily accomplished after subsequent transformation steps or need to be post-poned to further the goals of other transformation steps. For example, standardizing abbreviated forms may be more easily accomplished after tokenization when each token is a word. Another example is the case of case conversion. Even if we are not directly interested in the case differences between words, certain generation procedures, Named Entity Recognition (NER) for example, may use case information to identify the names of people, locations, organizations, <em>etc.</em>. In these cases, it may be better to leave the case as is until after the generation step.</p>
</section></section><section id="sec-td-recoding" class="level2" data-number="7.2"><h2 data-number="7.2" class="anchored" data-anchor-id="sec-td-recoding">
<span class="header-section-number">7.2</span> Recoding</h2>
<p>Normalizing text can be seen as an extension of dataset curation to some extent in that the structure of the dataset is maintained. In the Europarl case, we saw this to be true. In the case of recoding, and other transformational steps, the aim will be to modify the dataset structure either by rows, columns, or both. Recoding processes can be characterized by the creation of structural changes which are derived from values in variables effectively recasting values as new variables to enable more direct access in our analyses.</p>
<section id="sec-td-recoding-orientation" class="level3" data-number="7.2.1"><h3 data-number="7.2.1" class="anchored" data-anchor-id="sec-td-recoding-orientation">
<span class="header-section-number">7.2.1</span> Orientation</h3>
<p>The Switchboard dialog Act Corpus corpus contains a number of variables describing conversations between speakers of American English. A subset of this dataset provides a good example of the recoding process. The data dictionary for this dataset appears in <a href="#tbl-td-swda-curated-dd">Table&nbsp;<span>7.3</span></a>.</p>
<div class="cell" data-hash="transform-datasets_cache/html/tbl-td-swda-curated-dd_c52d74ae237f1e669d8b7297d0b96d02">
<div class="cell-output-display">
<div id="tbl-td-swda-curated-dd" class="anchored">
<table class="table table-sm table-striped small" data-quarto-postprocess="true">
<caption>Table&nbsp;7.3: Data dictionary for the Switchboard dialog Act Corpus.</caption>
<thead><tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">variable</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">name</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">description</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">variable_type</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">doc_id</td>
<td style="text-align: left;">Document ID</td>
<td style="text-align: left;">The ID of the document in the dataset</td>
<td style="text-align: left;">numeric</td>
</tr>
<tr class="even">
<td style="text-align: left;">speaker_id</td>
<td style="text-align: left;">Speaker ID</td>
<td style="text-align: left;">The ID of the speaker in the dataset</td>
<td style="text-align: left;">numeric</td>
</tr>
<tr class="odd">
<td style="text-align: left;">sex</td>
<td style="text-align: left;">Sex</td>
<td style="text-align: left;">The gender of the speaker</td>
<td style="text-align: left;">character</td>
</tr>
<tr class="even">
<td style="text-align: left;">education</td>
<td style="text-align: left;">Education</td>
<td style="text-align: left;">The level of education of the speaker</td>
<td style="text-align: left;">numeric</td>
</tr>
<tr class="odd">
<td style="text-align: left;">birth_year</td>
<td style="text-align: left;">Birth Year</td>
<td style="text-align: left;">The year of birth of the speaker</td>
<td style="text-align: left;">numeric</td>
</tr>
<tr class="even">
<td style="text-align: left;">utt_id</td>
<td style="text-align: left;">Utterance ID</td>
<td style="text-align: left;">The ID of the utterance in the dataset</td>
<td style="text-align: left;">numeric</td>
</tr>
<tr class="odd">
<td style="text-align: left;">utt_text</td>
<td style="text-align: left;">Utterance Text</td>
<td style="text-align: left;">The text of the utterance</td>
<td style="text-align: left;">character</td>
</tr>
<tr class="even">
<td style="text-align: left;">damsl_tag</td>
<td style="text-align: left;">DAMSL Tag</td>
<td style="text-align: left;">The DAMSL tag associated with the utterance</td>
<td style="text-align: left;">character</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
<p>The data dictionary gives us a sense of the variables in the dataset. Let’s read in the dataset and preview the first 10 lines to get a sense of the values in the dataset, as in <a href="#exm-td-swda-dataset-read-show">Example&nbsp;<span>7.14</span></a>.</p>
<div id="exm-td-swda-dataset-read-show" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.14 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-swda-dataset-read-show_442986038e71ec2f8ca92467344be6d1">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Read in the dataset</span></span>
<span><span class="va">swda_curated_tbl</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">read_csv</span><span class="op">(</span><span class="st">"data/derived/swda/swda_curated.csv"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview the first 10 lines</span></span>
<span><span class="va">swda_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-hash="transform-datasets_cache/html/td-swda-dataset-read-run_900659541d0e5185e2cfbf9d165a03ee">
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 10 × 8
&gt;    doc_id speaker_id sex    education birth_year utt_id utt_text       damsl_tag
&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;    
&gt;  1   4325       1632 Female         2       1962      1 Okay.  /       o        
&gt;  2   4325       1632 Female         2       1962      2 {D So, }       qw       
&gt;  3   4325       1519 Female         1       1971      3 [ [ I guess, + qy^d     
&gt;  4   4325       1632 Female         2       1962      4 What kind of … +        
&gt;  5   4325       1519 Female         1       1971      5 I think, ] + … +        
&gt;  6   4325       1632 Female         2       1962      6 Does it say s… qy       
&gt;  7   4325       1519 Female         1       1971      7 I think it us… sd       
&gt;  8   4325       1519 Female         1       1971      8 You might try… ad       
&gt;  9   4325       1519 Female         1       1971      9 I don't know,… h        
&gt; 10   4325       1519 Female         1       1971     10 hold it down … ad</code></pre>
</div>
</div>
</div>
<p>Considering the data dictionary and the preview of the <code>swda_curated_tbl</code> dataset, we observe a number of metadata variables, such as <code>doc_id</code>, <code>speaker_id</code>, <code>sex</code>, <code>education</code>, <code>birth_year</code>, <code>utt_id</code>, <code>utt_text</code>, and <code>damsl_tag</code>.</p>
<p>Most of these variables and their values are readily interpretable. However, the <code>damsl_tag</code> variable and the annotation scheme that appears interleaved with the dialog in <code>utt_text</code> may require a bit more explanation. If we consult the data origin file and/ or the corpus website, we seee that the <code>damsl_tag</code> is a utterance-level annotation which indicates the dialog act type (<em>e.g.</em> statement, question, backchannel, <em>etc.</em>). The annotation interleaved with the dialog in <code>utt_text</code> is a <a href="https://staff.fnwi.uva.nl/r.fernandezrovira/teaching/DM-materials/DFL-book.pdf">disfluency annotation scheme</a>. This scheme includes annotation for non-sentence elements such as filled pauses (<em>e.g.</em> <code>{F uh}</code>), discourse markers (<em>e.g.</em> <code>{D well}</code>), repetitions/ restarts (<em>e.g.</em> <code>[I think + I believe]</code>), among others.</p>
<p>Let’s assume that we are interested in understanding the use of filled pauses in the Switchboard dialog. <span class="citation" data-cites="Tottie2011">Tottie (<a href="references.html#ref-Tottie2011" role="doc-biblioref">2011</a>)</span> investigates the relationship between speakers’ use of filled pauses <code>uh</code> and <code>um</code> and their socio-demographic background (sex, socio-economic status, and age) in British English. An American English comparison would be insightful. To do this, however, we will need to recode some of the variables in the dataset.</p>
<p>In this case, we will use <code>education</code> as a proxy for socio-economic status. As is, the values are numeric and are not maximally transparent. We can recode these values to be more interpretable. In the corpus documentation, the values for <code>education</code> are described in <a href="#tbl-td-swda-education">Table&nbsp;<span>7.4</span></a>.</p>
<div id="tbl-td-swda-education" class="anchored">
<table class="table-sm table-striped small table">
<caption>Table&nbsp;7.4: Values for the <code>education</code> variable in the Switchboard dialog Act Corpus.</caption>
<thead><tr class="header">
<th>Value</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>Less Than High School</td>
</tr>
<tr class="even">
<td>1</td>
<td>Less Than College</td>
</tr>
<tr class="odd">
<td>2</td>
<td>College</td>
</tr>
<tr class="even">
<td>3</td>
<td>More Than College</td>
</tr>
<tr class="odd">
<td>9</td>
<td>Unknown</td>
</tr>
</tbody>
</table>
</div>
<p>To derive a variable which reflects the age of each speaker, we will use the <code>birth_year</code> variable. This variable is a numeric value which indicates the year of birth for each speaker. We can derive a new variable <code>age</code> by subtracting the <code>birth_year</code> from the year of recordings, 1992.</p>
<p>Together <code>sex</code>, <code>education</code>, and <code>age</code> will provide us with the socio-demographic information we need to investigate the relationship between speakers’ use of filled pauses and their socio-demographic background. The last component we need to derive is the use of filled pauses. To do this we will need to extract the filled pauses from the <code>utt_text</code> variable. We also need to consider what we mean by ‘use’. In this case, we will operationalize the use of filled pauses as the number of times a filled pause is used per utterance.</p>
</section><section id="sec-td-recoding-application" class="level3" data-number="7.2.2"><h3 data-number="7.2.2" class="anchored" data-anchor-id="sec-td-recoding-application">
<span class="header-section-number">7.2.2</span> Application</h3>
<p>The plan to transform the <code>swda_curated_tbl</code> dataset is established. Now we need to implement the plan. We will start by recoding the <code>education</code> variable. Specifically, we want to map the numeric values to the descriptions in <a href="#tbl-td-swda-education">Table&nbsp;<span>7.4</span></a>.</p>
<p>To do this we will use the <code>case_when()</code> function from the <code>dplyr</code> package. This function allows us to specify a series of conditions and the values to return if the condition is met. <code>case_when()</code> evaluates the conditions and <code>mutate()</code> writes the variable, in this case overwrites it, as seen in <a href="#exm-td-swda-recoding-education">Example&nbsp;<span>7.15</span></a>.</p>
<div id="exm-td-swda-recoding-education" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.15 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-swda-recoding-education_955ad06919b0cf8629eec92b89594735">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Recode education</span></span>
<span><span class="va">swda_curated_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">swda_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span></span>
<span>    education <span class="op">=</span> <span class="fu">case_when</span><span class="op">(</span></span>
<span>      <span class="va">education</span> <span class="op">==</span> <span class="fl">0</span> <span class="op">~</span> <span class="st">"Less Than High School"</span>,</span>
<span>      <span class="va">education</span> <span class="op">==</span> <span class="fl">1</span> <span class="op">~</span> <span class="st">"Less Than College"</span>,</span>
<span>      <span class="va">education</span> <span class="op">==</span> <span class="fl">2</span> <span class="op">~</span> <span class="st">"College"</span>,</span>
<span>      <span class="va">education</span> <span class="op">==</span> <span class="fl">3</span> <span class="op">~</span> <span class="st">"More Than College"</span>,</span>
<span>      <span class="va">education</span> <span class="op">==</span> <span class="fl">9</span> <span class="op">~</span> <span class="st">"Unknown"</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="co"># Preview the first 10 lines</span></span>
<span><span class="va">swda_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 10 × 8
&gt;    doc_id speaker_id sex    education       birth_year utt_id utt_text damsl_tag
&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;                &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    
&gt;  1   4325       1632 Female College               1962      1 Okay.  / o        
&gt;  2   4325       1632 Female College               1962      2 {D So, } qw       
&gt;  3   4325       1519 Female Less Than Coll…       1971      3 [ [ I g… qy^d     
&gt;  4   4325       1632 Female College               1962      4 What ki… +        
&gt;  5   4325       1519 Female Less Than Coll…       1971      5 I think… +        
&gt;  6   4325       1632 Female College               1962      6 Does it… qy       
&gt;  7   4325       1519 Female Less Than Coll…       1971      7 I think… sd       
&gt;  8   4325       1519 Female Less Than Coll…       1971      8 You mig… ad       
&gt;  9   4325       1519 Female Less Than Coll…       1971      9 I don't… h        
&gt; 10   4325       1519 Female Less Than Coll…       1971     10 hold it… ad</code></pre>
</div>
</div>
</div>
<p>To create the <code>age</code> variable, all we need to do is subtract the <code>birth_year</code> from the year of recording, 1992. Again we will use <code>mutate()</code> to create the <code>age</code> variable. The values are created by a subtraction operation. Since we will not need the <code>birth_year</code> variable afterwards, we will drop it from the dataset. The code is seen in <a href="#exm-td-swda-recoding-age">Example&nbsp;<span>7.16</span></a>.</p>
<div id="exm-td-swda-recoding-age" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.16 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-swda-recoding-age_b02aa6981e6ec3e98a6bb6cdb47c2ea3">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Recode age</span></span>
<span><span class="va">swda_curated_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">swda_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>age <span class="op">=</span> <span class="fl">1992</span> <span class="op">-</span> <span class="va">birth_year</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="op">-</span><span class="va">birth_year</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview the first 10 lines</span></span>
<span><span class="va">swda_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 10 × 8
&gt;    doc_id speaker_id sex    education         utt_id utt_text    damsl_tag   age
&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;     &lt;dbl&gt;
&gt;  1   4325       1632 Female College                1 Okay.  /    o            30
&gt;  2   4325       1632 Female College                2 {D So, }    qw           30
&gt;  3   4325       1519 Female Less Than College      3 [ [ I gues… qy^d         21
&gt;  4   4325       1632 Female College                4 What kind … +            30
&gt;  5   4325       1519 Female Less Than College      5 I think, ]… +            21
&gt;  6   4325       1632 Female College                6 Does it sa… qy           30
&gt;  7   4325       1519 Female Less Than College      7 I think it… sd           21
&gt;  8   4325       1519 Female Less Than College      8 You might … ad           21
&gt;  9   4325       1519 Female Less Than College      9 I don't kn… h            21
&gt; 10   4325       1519 Female Less Than College     10 hold it do… ad           21</code></pre>
</div>
</div>
</div>
<p>Our final recoding step is to derive the frequency of filled pauses per utterance. In other words, we want to match the ‘uh’ and ‘um’ and return the number of matches for each utterance. There are a number of ways to do this. We could use an approach which applies the <code>str_extract_all()</code> function, which returns a list of matches, and then <code>unnest()</code> the list and count the number of matches. An alternative approach is to use the <code>str_count()</code> function to count the number of matches for a pattern. The later approach is more efficient for our purposes.</p>
<p>In either case, a pattern to match these annotations is needed. As always with pattern matching, we need to craft an expression that is as specific as possible to avoid over- or under-matching. We know from our observation and the corpus documentation that all filled pauses are wrapped by the <code>{F ...}</code> annotation. We can use this to our advantage. Before we jump into counting the filled pauses, let’s test a regular expression that matches the entire <code>{F ...}</code> annotation. An expression like <code>{F.*}</code> might be tempting, but this will be problematic for two reasons. First, since the <code>{</code> and <code>}</code> are regular expression operators we will need to escape them with the <code>\\</code> convention. Second, the <code>*</code> operator is greedy, meaning that it will match the longest possible string. So if in a given utterance there are multiple filled pauses, the <code>*</code> operator will match all of them at once, not individually. To avoid this, we can use the <code>?</code> operator to make the <code>*</code> operator lazy. With these considerations in mind, we can move forward with <code>\\{F.*?\\}</code> as our expression.</p>
<p>We will send each utterance to the <code>str_extract_all()</code> function to match the filled pauses. This function returns a list of matches, so we will need to <code>unnest()</code> the list to get a vector of matches. Afterwards we will apply the <code>count()</code> function to summarize the number of matches for each match variation. The code is seen in <a href="#exm-td-swda-recoding-filled-pauses-test">Example&nbsp;<span>7.17</span></a>.</p>
<div id="exm-td-swda-recoding-filled-pauses-test" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.17 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-swda-recoding-filled-pauses-test_c80ae8c62a6312caa6e886f7406967bb">
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Test filled pause pattern</span></span>
<span><span class="va">swda_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span></span>
<span>    matches <span class="op">=</span> <span class="fu">str_extract_all</span><span class="op">(</span></span>
<span>      <span class="va">utt_text</span>, </span>
<span>      <span class="st">"\\{F.*?\\}"</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">unnest</span><span class="op">(</span><span class="va">matches</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">count</span><span class="op">(</span><span class="va">matches</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 120 × 2
&gt;    matches            n
&gt;    &lt;chr&gt;          &lt;int&gt;
&gt;  1 "{F  Oh, }"        1
&gt;  2 "{F  uh, }"        1
&gt;  3 "{F \"Oh, }"       1
&gt;  4 "{F ((Oh)) }"      1
&gt;  5 "{F ((Oh, }"       1
&gt;  6 "{F ((Uh }"        1
&gt;  7 "{F ((Uh)), }"     1
&gt;  8 "{F ((Uh, }"       1
&gt;  9 "{F + ] Um, }"     1
&gt; 10 "{F + ] um, }"     1
&gt; # ℹ 110 more rows</code></pre>
</div>
</div>
</div>
<p>The result from our test indicates that the <code>\\{F .*?\\}</code> pattern matches a wide variety of filled pause annotations, 120 to be exact! We can see that there are a number of filled pause annotations that we are not be interested in, <em>e.g.</em> <code>{F Oh}</code>. Furthermore, the ‘uh’ and ‘um’ we are interested in sometimes include more annotation structure, <em>e.g.</em> <code>{F + ] Um, }</code>.</p>
<p>A more sophisticated pattern is needed. When faced with a pattern matching task such as this, I find it helpful to start with a simple pattern and then add complexity as needed. This is an iterative process. To speed up the process, I often extract the matches and use an online tool for developing regular expressions, such as <a href="https://regex101.com/">regex101.com</a>.</p>
<p>With a (monster) regular expression that matches each of the filled pauses we are interested in, and only those filled pauses, we can move forward with counting the number of matches for each utterance.</p>
<p>To do this we will use the <code>str_count()</code> function from the <code>stringr</code> package. This function counts the number of matches for a pattern in a character vector. We will use <code>mutate()</code> to create new variables <code>uh</code> and <code>um</code> which will contain the counts for the filled pauses <code>uh</code> and <code>um</code>, respectively. The code is seen in <a href="#exm-td-swda-recoding-filled-pauses">Example&nbsp;<span>7.18</span></a>.</p>
<div id="exm-td-swda-recoding-filled-pauses" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.18 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-swda-recoding-filled-pauses_921639465418af3390c3e900a58b533d">
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Recode filled pauses </span></span>
<span><span class="va">swda_curated_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">swda_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span></span>
<span>    uh <span class="op">=</span> <span class="fu">str_count</span><span class="op">(</span></span>
<span>      <span class="va">utt_text</span>, </span>
<span>      <span class="st">"\\{F\\s+[\\(+\\s\\]]*(u|U)h[\\)\\s,\\.\\?-]*\\}"</span></span>
<span>    <span class="op">)</span>,</span>
<span>    um <span class="op">=</span> <span class="fu">str_count</span><span class="op">(</span></span>
<span>      <span class="va">utt_text</span>, </span>
<span>      <span class="st">"\\{F\\s+[\\(+\\s\\]]*(u|U)m[\\)\\s,\\.\\?-]*\\}"</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="co"># Preview the first 10 lines </span></span>
<span><span class="va">swda_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 10 × 10
&gt;    doc_id speaker_id sex   education utt_id utt_text damsl_tag   age    uh    um
&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt; &lt;int&gt;
&gt;  1   4325       1632 Fema… College        1 Okay.  / o            30     0     0
&gt;  2   4325       1632 Fema… College        2 {D So, } qw           30     0     0
&gt;  3   4325       1519 Fema… Less Tha…      3 [ [ I g… qy^d         21     0     0
&gt;  4   4325       1632 Fema… College        4 What ki… +            30     0     0
&gt;  5   4325       1519 Fema… Less Tha…      5 I think… +            21     1     0
&gt;  6   4325       1632 Fema… College        6 Does it… qy           30     0     0
&gt;  7   4325       1519 Fema… Less Tha…      7 I think… sd           21     0     0
&gt;  8   4325       1519 Fema… Less Tha…      8 You mig… ad           21     1     0
&gt;  9   4325       1519 Fema… Less Tha…      9 I don't… h            21     0     0
&gt; 10   4325       1519 Fema… Less Tha…     10 hold it… ad           21     0     0</code></pre>
</div>
</div>
</div>
<p>Now we have two new columns, <code>uh</code> and <code>um</code> which indicate how many times the relevant pattern was matched for a given utterance. By choosing to focus on disfluencies, however, we have made a decision to change the unit of observation from the utterance to the use of filled pauses (<code>uh</code> and <code>um</code>). This means that as the dataset stands, it is not in tidy format –where each observation corresponds to the observational unit. When datasets are misaligned in this particular way, there are in what is known as ‘wide’ format. What we want to do, then, is to restructure our dataset such that each row corresponds to the unit of observation –in this case each filled pause type.</p>
<!-- [ ] may need a graphic or more explanation here (pivot_longer) -->
<p>To convert our current (wide) dataset to one where each filler type is listed and the counts are measured for each utterance we turn to the <code>pivot_longer()</code> function. This function creates two new columns, one in which the column names are listed and one for the values for each of the column names. The code is seen in <a href="#exm-td-swda-recoding-filled-pauses-longer">Example&nbsp;<span>7.19</span></a>.</p>
<div id="exm-td-swda-recoding-filled-pauses-longer" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.19 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-swda-recoding-filled-pauses-longer_e20ae2efb9ea8d1a0fc298969e4c3b87">
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Tidy filled pauses</span></span>
<span><span class="va">swda_curated_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">swda_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">pivot_longer</span><span class="op">(</span></span>
<span>    cols <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"uh"</span>, <span class="st">"um"</span><span class="op">)</span>, </span>
<span>    names_to <span class="op">=</span> <span class="st">"filler"</span>, </span>
<span>    values_to <span class="op">=</span> <span class="st">"count"</span></span>
<span>  <span class="op">)</span></span>
<span><span class="co"># Preview the first 10 lines</span></span>
<span><span class="va">swda_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 10 × 10
&gt;    doc_id speaker_id sex    education     utt_id utt_text damsl_tag   age filler
&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt; 
&gt;  1   4325       1632 Female College            1 Okay.  / o            30 uh    
&gt;  2   4325       1632 Female College            1 Okay.  / o            30 um    
&gt;  3   4325       1632 Female College            2 {D So, } qw           30 uh    
&gt;  4   4325       1632 Female College            2 {D So, } qw           30 um    
&gt;  5   4325       1519 Female Less Than Co…      3 [ [ I g… qy^d         21 uh    
&gt;  6   4325       1519 Female Less Than Co…      3 [ [ I g… qy^d         21 um    
&gt;  7   4325       1632 Female College            4 What ki… +            30 uh    
&gt;  8   4325       1632 Female College            4 What ki… +            30 um    
&gt;  9   4325       1519 Female Less Than Co…      5 I think… +            21 uh    
&gt; 10   4325       1519 Female Less Than Co…      5 I think… +            21 um    
&gt; # ℹ 1 more variable: count &lt;int&gt;</code></pre>
</div>
</div>
</div>
<p>Now we have a transformed dataset that is in tidy format. Each row corresponds to a filled pause type and the number of times it was used in a given utterance. It also includes the key socio-demographic variables we are interested in.</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-lightbulb" aria-label="lightbulb"></i> Consider this</strong></p>
<p>As confident as we may be in our recoding process, it is always a good idea to perform some data checks to ensure that the recoding process was successful. In the process, we can also gain some insight into the data. Considering the structure in the transformed Switchboard dialog Act Corpus dataset, what are some data checks we might want to perform? What are some insights we might gain from these data checks?</p>
</div>
</div>
</div>
<p>Finalize the transformation process by writing the dataset to a CSV file, create a data dictionary, and review and comment your code in the transformation script.</p>
</section></section><section id="sec-td-tokenization" class="level2" data-number="7.3"><h2 data-number="7.3" class="anchored" data-anchor-id="sec-td-tokenization">
<span class="header-section-number">7.3</span> Tokenization</h2>
<p>Another common transformation process that is particularly relevant for text analysis is tokenization. Tokenization is the process of segmenting units of language into components relevant for the research question. This includes breaking text in curated datasets into smaller units, such as words, <span class="math inline">\(n\)</span>-grams, sentences, <em>etc.</em> or combining text into larger units relative to the original text.</p>
<!-- [ ] Have I defined n-grams somewhere before this? If not, I need to figure out where to add it so it is not an opaque term to readers -->
<p>The process of tokenization is fundamentally row-wise. By scaling the text units up or down, we change the unit of observation. It is important both for the research and the text processing to operationalize our language units. For example, while it may appear obvious to you what ‘word’ or ‘sentence’ means, a computer, and your reproducible research, needs a definition. This can prove tricker than it seems. For example, in English, we can segment text into words by splitting on whitespace. This works fairly well but there are some cases where this is not ideal. For example, in the case of contractions, such as <code>don't</code>, <code>won't</code>, <code>can't</code>, <em>etc.</em> the apostrophe is not a whitespace character. If we want to consider these contractions as separate words, then we need to consider a different tokenization strategy.</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-lightbulb" aria-label="lightbulb"></i> Consider this</strong></p>
<p>Consider the following paragraph:</p>
<blockquote class="blockquote">
<p>“As the sun dipped below the horizon, the sky was set ablaze with shades of orange-red, illuminating the landscape. It’s a sight Mr.&nbsp;Johnson, a long-time observer, never tired of. On the lakeside, he’d watch with friends, enjoying the ever-changing hues—especially those around 6:30 p.m.—and reflecting on nature’s grand display. Even in the half-light, the water’s glimmer, coupled with the echo of distant laughter, created a timeless scene. The so-called ‘magic hour’ was indeed magical, yet fleeting, like a well-crafted poem; it was the essence of life itself.”</p>
</blockquote>
<p>What text conventions would pose issues for word tokenization based on a whitespace critieron?</p>
</div>
</div>
</div>
<p>Furthermore, tokenization strategies can vary between languages. For German words are often compounded together, meaning many ‘words’ will not be captured by the whitespace convention. Whitespace may not even be relevant for word tokenization in written languages, such as Chinese. The take home message is there is no one-size-fits-all tokenization strategy.</p>
<section id="sec-td-tokenization-orientation" class="level3" data-number="7.3.1"><h3 data-number="7.3.1" class="anchored" data-anchor-id="sec-td-tokenization-orientation">
<span class="header-section-number">7.3.1</span> Orientation</h3>
<p>Let’s look at a curated dataset from the CABNC Corpus to explore tokenization. The data dictionary for this dataset appears in <a href="#tbl-td-cabnc-dd">Table&nbsp;<span>7.5</span></a>.</p>
<div class="cell" data-hash="transform-datasets_cache/html/tbl-td-cabnc-dd_14c0abba32ea34be7f8ea301178667b7">
<div class="cell-output-display">
<div id="tbl-td-cabnc-dd" class="anchored">
<table class="table table-sm table-striped small" data-quarto-postprocess="true">
<caption>Table&nbsp;7.5: Data dictionary for the CABNC Corpus.</caption>
<thead><tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">variable</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">name</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">description</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">variable_type</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">doc_id</td>
<td style="text-align: left;">Document ID</td>
<td style="text-align: left;">Identification number for the document</td>
<td style="text-align: left;">character</td>
</tr>
<tr class="even">
<td style="text-align: left;">part_id</td>
<td style="text-align: left;">Part ID</td>
<td style="text-align: left;">Identification number for the part</td>
<td style="text-align: left;">character</td>
</tr>
<tr class="odd">
<td style="text-align: left;">sex</td>
<td style="text-align: left;">Sex</td>
<td style="text-align: left;">Gender of the individual</td>
<td style="text-align: left;">character</td>
</tr>
<tr class="even">
<td style="text-align: left;">age</td>
<td style="text-align: left;">Age</td>
<td style="text-align: left;">Age of the individual</td>
<td style="text-align: left;">numeric</td>
</tr>
<tr class="odd">
<td style="text-align: left;">utt_id</td>
<td style="text-align: left;">Utterance ID</td>
<td style="text-align: left;">Identification number for the utterance</td>
<td style="text-align: left;">numeric</td>
</tr>
<tr class="even">
<td style="text-align: left;">utt_text</td>
<td style="text-align: left;">Utterance Text</td>
<td style="text-align: left;">Text of the utterance</td>
<td style="text-align: left;">character</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
<p>The CABNC dataset contains a number of variables describing conversations between speakers of British English. Now let’s look at the dataset and preview the first 10 lines to get a sense of the values in the dataset, as in <a href="#exm-td-cabnc-dataset-read-show">Example&nbsp;<span>7.20</span></a>.</p>
<div id="exm-td-cabnc-dataset-read-show" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.20 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-cabnc-dataset-read-show_6a77ab1719c659d3a85d875c967679de">
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Read in the dataset</span></span>
<span><span class="va">cabnc_curated_tbl</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">read_csv</span><span class="op">(</span><span class="st">"data/derived/cabnc/cabnc_curated.csv"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview the first 10 lines</span></span>
<span><span class="va">cabnc_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-hash="transform-datasets_cache/html/td-cabnc-dataset-read-run_76ce76521b9c7a6e928bc0c9bf77ec66">
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 10 × 6
&gt;    doc_id   part_id sex      age utt_id utt_text                                
&gt;    &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                                   
&gt;  1 KB0RE000 PS002   female   721      0 You enjoyed yourself in America         
&gt;  2 KB0RE000 PS006   male     601      1 Eh                                      
&gt;  3 KB0RE000 PS002   female   721      2 did you                                 
&gt;  4 KB0RE000 PS006   male     601      3 Oh I covered a nice trip yes            
&gt;  5 KB0RE000 PS002   female   721      4 Oh very good yeah                       
&gt;  6 KB0RE000 PS006   male     601      5 Er saw Mary and Andrew and              
&gt;  7 KB0RE000 PS002   female   721      6 Yes you did                             
&gt;  8 KB0RE000 PS006   male     601      7 in fact the whole family was together f…
&gt;  9 KB0RE000 PS002   female   721      8 Oh very nice very nice yes It 's horrib…
&gt; 10 KB0RE000 PS006   male     601      9 It is horrible is n't</code></pre>
</div>
</div>
</div>
<p>Considering the data dictionary and the preview of the <code>cabnc_curated_tbl</code> dataset, we observe a number of metadata variables, such as <code>doc_id</code>, <code>part_id</code>, <code>sex</code>, <code>age</code>, and <code>utt_id</code> and the utterances in <code>utt_text</code>.</p>
<p>Let’s assume that we are performing an exploratory analysis with this dataset and would like to consider the use of words and word sequences (<span class="math inline">\(n\)</span>-grams). In this case we will be deriving multiple datasets with different units of observation.</p>
</section><section id="sec-td-tokenization-application" class="level3" data-number="7.3.2"><h3 data-number="7.3.2" class="anchored" data-anchor-id="sec-td-tokenization-application">
<span class="header-section-number">7.3.2</span> Application</h3>
<p>In the <code>cabnc_curated_tbl</code> data frame the <code>utt_text</code> variable contains the text we want to tokenize. We will start by tokenizing the text into words. Abstracting away from some of the metadata variables, if we envision what this should look like we might imagine something like <a href="#tbl-td-cabnc-tokenization-words-example">Table&nbsp;<span>7.6</span></a>.</p>
<div id="tbl-td-cabnc-tokenization-words-example" class="anchored">
<table class="table-sm table-striped small table">
<caption>Table&nbsp;7.6: Example of tokenizing the <code>utt_text</code> variable into words.</caption>
<thead><tr class="header">
<th>doc_id</th>
<th>utt_id</th>
<th>utt_word</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>KB0RE000</td>
<td>0</td>
<td>You</td>
</tr>
<tr class="even">
<td>KB0RE000</td>
<td>0</td>
<td>enjoyed</td>
</tr>
<tr class="odd">
<td>KB0RE000</td>
<td>0</td>
<td>yourself</td>
</tr>
<tr class="even">
<td>KB0RE000</td>
<td>0</td>
<td>in</td>
</tr>
<tr class="odd">
<td>KB0RE000</td>
<td>0</td>
<td>America</td>
</tr>
</tbody>
</table>
</div>
<p>Comparing <a href="#tbl-td-cabnc-tokenization-words-example">Table&nbsp;<span>7.6</span></a> to the first line of the output of <a href="#exm-td-swda-dataset-read-show">Example&nbsp;<span>7.14</span></a>, we can see that we want to segment the words in the <code>utt_text</code> and then have each segment appear as a separate observation, retaining the relevant metadata variables.</p>
<p>Before we work with tokenizing text in a data frame, let’s start with a character vector to get a sense of how tokenization works and what we will need to do to achieve the output in <a href="#tbl-td-cabnc-tokenization-words-example">Table&nbsp;<span>7.6</span></a>. Let’s start with a character vector which contains the first three utterances from <code>cabnc_curated_tbl</code>. I will use <code>slice_head(n = 3)</code> and then <code>pull()</code> to extract the <code>utt_text</code> character vector in <a href="#exm-td-cabnc-tokenization-words-vector">Example&nbsp;<span>7.21</span></a>.</p>
<div id="exm-td-cabnc-tokenization-words-vector" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.21 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-cabnc-tokenization-words-vector_9ee6139f763a041eb04d1367b821e85c">
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Pull a character vector</span></span>
<span><span class="va">cabnc_utts_chr</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">cabnc_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">pull</span><span class="op">(</span><span class="va">utt_text</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview the character vector</span></span>
<span><span class="va">cabnc_utts_chr</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; [1] "You enjoyed yourself in America" "Eh"                             
&gt; [3] "did you"</code></pre>
</div>
</div>
</div>
<p>We have the first three utterances in <code>cbanc_utts_chr</code>. Now we can tokenize the utterances into words using the <code><a href="https://docs.ropensci.org/tokenizers/reference/basic-tokenizers.html">tokenize_words()</a></code> function from the <code>tokenizers</code> package <span class="citation" data-cites="R-tokenizers">(<a href="references.html#ref-R-tokenizers" role="doc-biblioref">Mullen 2022</a>)</span>. It’s only required argument is a character vector, as seen in <a href="#exm-td-cabnc-tokenization-words-tokenize">Example&nbsp;<span>7.22</span></a>.</p>
<div id="exm-td-cabnc-tokenization-words-tokenize" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.22 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-cabnc-tokenization-words-tokenize_77b752d234e35e0a45cd113e636b05ea">
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load package</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://docs.ropensci.org/tokenizers/">tokenizers</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Tokenize the utterances into words</span></span>
<span><span class="va">cabnc_utts_chr</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://docs.ropensci.org/tokenizers/reference/basic-tokenizers.html">tokenize_words</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; [[1]]
&gt; [1] "you"      "enjoyed"  "yourself" "in"       "america" 
&gt; 
&gt; [[2]]
&gt; [1] "eh"
&gt; 
&gt; [[3]]
&gt; [1] "did" "you"</code></pre>
</div>
</div>
</div>
<p>The output shows that we get a list of length 3, one for each utterance. Each list element contains a character vector with different lengths based on the number of tokens created from the original utterance.</p>
<p>Now if we add the <code><a href="https://docs.ropensci.org/tokenizers/reference/basic-tokenizers.html">tokenize_words()</a></code> function to a <code>mutate()</code> call, we can create a new variable with the tokenized utterances. However, the value for each observation will be a list. To expand the character vectors within each list into separate observations, we can use the <code>unnest()</code> function on the new variable. I will assign the result to <code>cabnc_unigrams_tbl</code> as we will have one-word tokens, as seen in <a href="#exm-td-cabnc-tokenization-words">Example&nbsp;<span>7.23</span></a>.</p>
<div id="exm-td-cabnc-tokenization-words" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.23 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-cabnc-tokenization-words_297d2bb9d8b9c1d355963c31ce088aeb">
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Tokenize the utterances into words</span></span>
<span><span class="va">cabnc_unigrams_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">cabnc_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>utt_words <span class="op">=</span> <span class="fu"><a href="https://docs.ropensci.org/tokenizers/reference/basic-tokenizers.html">tokenize_words</a></span><span class="op">(</span><span class="va">utt_text</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">unnest</span><span class="op">(</span>cols <span class="op">=</span> <span class="va">utt_words</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview the first 10 lines</span></span>
<span><span class="va">cabnc_unigrams_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 10 × 7
&gt;    doc_id   part_id sex      age utt_id utt_text                       utt_words
&gt;    &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                          &lt;chr&gt;    
&gt;  1 KB0RE000 PS002   female   721      0 You enjoyed yourself in Ameri… you      
&gt;  2 KB0RE000 PS002   female   721      0 You enjoyed yourself in Ameri… enjoyed  
&gt;  3 KB0RE000 PS002   female   721      0 You enjoyed yourself in Ameri… yourself 
&gt;  4 KB0RE000 PS002   female   721      0 You enjoyed yourself in Ameri… in       
&gt;  5 KB0RE000 PS002   female   721      0 You enjoyed yourself in Ameri… america  
&gt;  6 KB0RE000 PS006   male     601      1 Eh                             eh       
&gt;  7 KB0RE000 PS002   female   721      2 did you                        did      
&gt;  8 KB0RE000 PS002   female   721      2 did you                        you      
&gt;  9 KB0RE000 PS006   male     601      3 Oh I covered a nice trip yes   oh       
&gt; 10 KB0RE000 PS006   male     601      3 Oh I covered a nice trip yes   i</code></pre>
</div>
</div>
</div>
<p>The <code>cabnc_unigrams_tbl</code> dataset is in the format we want, each row corresponds to a word token and each column contains the relevant metadata. The <code>tokenizers</code> package includes a variety of tokenization functions. For example, we can use the <code><a href="https://docs.ropensci.org/tokenizers/reference/ngram-tokenizers.html">tokenize_ngrams()</a></code> function to create <span class="math inline">\(n\)</span>-grams. The <code><a href="https://docs.ropensci.org/tokenizers/reference/ngram-tokenizers.html">tokenize_ngrams()</a></code> function takes a character vector and a value for <span class="math inline">\(n\)</span> and returns a list of <span class="math inline">\(n\)</span>-grams. Other functions can tokenize character <span class="math inline">\(n\)</span>-grams, sentences, paragraphs, lines, or even allow you to specify a custom tokenization function with a regular expression.</p>
<p>As we have seen the <code>tokenize_*()</code> set of functions take a character vector and return a list of tokens. And if we are working with a data frame, we can then work to expand the list into separate observations. This is a common pattern in text analysis. So common, in fact, that the <code>tidytext</code> package <span class="citation" data-cites="R-tidytext">(<a href="references.html#ref-R-tidytext" role="doc-biblioref">Robinson and Silge 2023</a>)</span> includes a function, <code><a href="https://rdrr.io/pkg/tidytext/man/unnest_tokens.html">unnest_tokens()</a></code> that wraps the <code>tokenize_*</code> functions and expand the list of tokens into separate observations in one step. The tokenization types available are <code>character</code>, <code>word</code>, <code>ngram</code>, <code>sentence</code>, <code>regex</code>, and <code>skip_ngram</code>. We will use the <code>word</code> tokenization type to recreate the <code>cabnc_unigrams_tbl</code> dataset, as seen in <a href="#exm-td-cabnc-tokenization-words-tidytext">Example&nbsp;<span>7.24</span></a>.</p>
<div id="exm-td-cabnc-tokenization-words-tidytext" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.24 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-cabnc-tokenization-words-tidytext_27201eb15505f647b9cff50e721f37cb">
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load package</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/juliasilge/tidytext">tidytext</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Tokenize the utterances into words</span></span>
<span><span class="va">cabnc_unigrams_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">cabnc_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tidytext/man/unnest_tokens.html">unnest_tokens</a></span><span class="op">(</span></span>
<span>    output <span class="op">=</span> <span class="va">utt_word</span>, </span>
<span>    input <span class="op">=</span> <span class="va">utt_text</span>, </span>
<span>    token <span class="op">=</span> <span class="st">"words"</span></span>
<span>  <span class="op">)</span></span>
<span><span class="co"># Preview the first 10 lines</span></span>
<span><span class="va">cabnc_unigrams_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 10 × 6
&gt;    doc_id   part_id sex      age utt_id utt_word
&gt;    &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   
&gt;  1 KB0RE000 PS002   female   721      0 you     
&gt;  2 KB0RE000 PS002   female   721      0 enjoyed 
&gt;  3 KB0RE000 PS002   female   721      0 yourself
&gt;  4 KB0RE000 PS002   female   721      0 in      
&gt;  5 KB0RE000 PS002   female   721      0 america 
&gt;  6 KB0RE000 PS006   male     601      1 eh      
&gt;  7 KB0RE000 PS002   female   721      2 did     
&gt;  8 KB0RE000 PS002   female   721      2 you     
&gt;  9 KB0RE000 PS006   male     601      3 oh      
&gt; 10 KB0RE000 PS006   male     601      3 i</code></pre>
</div>
</div>
</div>
<p>The <code>utt_word</code> column in the outputs from both <a href="#exm-td-cabnc-tokenization-words">Example&nbsp;<span>7.23</span></a> and <a href="#exm-td-cabnc-tokenization-words-tidytext">Example&nbsp;<span>7.24</span></a> are identical. One thing to note, however, is that the original <code>utt_text</code> variable is dropped in the <code><a href="https://rdrr.io/pkg/tidytext/man/unnest_tokens.html">unnest_tokens()</a></code> approach. This one of a few default values for parameters which inlcude <code>drop = TRUE</code> (dropping the original text variable) and <code>to_lower = TRUE</code>. In fact the <code>token = "words"</code> parameter is not needed as it is the default. We can change these defaults as we see fit.</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-medal" aria-label="medal"></i> Dive deeper</strong></p>
<p>The approach using either <code>tokenize_*()</code> or <code><a href="https://rdrr.io/pkg/tidytext/man/unnest_tokens.html">unnest_tokens()</a></code> approaches tokenization from a segmentation point of view. That is, the context separating our tokens is tarted and is removed. In some cases it may be more feasible to turn the approach around and instead target the tokens to extract. The <code>str_extract_all()</code> can be used for this purpose. Note, however, the former approach is often more effective and effecient. The later requires a regular expression, or set of, which can be tricky to develop for some tokenization tasks.</p>
</div>
</div>
</div>
<p>As we create derived datasets to explore, let’s also create bigram tokens. We can do this by changing the <code>token</code> parameter to <code>"ngrams"</code> and specifying the value for <span class="math inline">\(n\)</span> with the <code>n</code> parameter. I will assign the result to <code>cabnc_bigrams_tbl</code> as we will have two-word tokens, as seen in <a href="#exm-td-cabnc-tokenization-bigrams-tidytext">Example&nbsp;<span>7.25</span></a>.</p>
<div id="exm-td-cabnc-tokenization-bigrams-tidytext" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.25 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-cabnc-tokenization-bigrams-tidytext_96043ac434cbfd3b590466060c687b95">
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Tokenize the utterances into bigrams</span></span>
<span><span class="va">cabnc_bigrams_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">cabnc_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tidytext/man/unnest_tokens.html">unnest_tokens</a></span><span class="op">(</span></span>
<span>    output <span class="op">=</span> <span class="va">utt_bigram</span>, </span>
<span>    input <span class="op">=</span> <span class="va">utt_text</span>, </span>
<span>    token <span class="op">=</span> <span class="st">"ngrams"</span>,</span>
<span>    n <span class="op">=</span> <span class="fl">2</span></span>
<span>  <span class="op">)</span></span>
<span><span class="co"># Preview the first 10 lines</span></span>
<span><span class="va">cabnc_bigrams_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 10 × 6
&gt;    doc_id   part_id sex      age utt_id utt_bigram      
&gt;    &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;           
&gt;  1 KB0RE000 PS002   female   721      0 you enjoyed     
&gt;  2 KB0RE000 PS002   female   721      0 enjoyed yourself
&gt;  3 KB0RE000 PS002   female   721      0 yourself in     
&gt;  4 KB0RE000 PS002   female   721      0 in america      
&gt;  5 KB0RE000 PS006   male     601      1 &lt;NA&gt;            
&gt;  6 KB0RE000 PS002   female   721      2 did you         
&gt;  7 KB0RE000 PS006   male     601      3 oh i            
&gt;  8 KB0RE000 PS006   male     601      3 i covered       
&gt;  9 KB0RE000 PS006   male     601      3 covered a       
&gt; 10 KB0RE000 PS006   male     601      3 a nice</code></pre>
</div>
</div>
</div>
<p>The two-word token sequences for each uttterance appear as observations in the <code>cabnc_bigrams_tbl</code> dataset. You may notice that in row 5 the value for <code>utt_bigram</code> is <code>NA</code>. This is because the utterance only contains one word. The <code><a href="https://rdrr.io/pkg/tidytext/man/unnest_tokens.html">unnest_tokens()</a></code> function will not create a token for a sequence that does not exist.</p>
<p>If we don’t want to loose this information, we can modify the original <code>utt_text</code> variable to include a placeholder, some symbol that we will use to denote that a single word utterance is present. Another strategy which accomplishes the first goal and may enrich the bigram dataset is to add a start and end token to each utterance. This will allow us to identify the first and last word in each utterance. In either case we can turn to the <code>str_c()</code> function which will allow us to concatenate strings. In <a href="#exm-td-cabnc-tokenization-bigrams-tidytext-start-end">Example&nbsp;<span>7.26</span></a>, I will add a start and end token to each utterance and then tokenize the utterances into bigrams.</p>
<div id="exm-td-cabnc-tokenization-bigrams-tidytext-start-end" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.26 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-cabnc-tokenization-bigrams-tidytext-start-end_4865d7e625aa97a54e028fb1da7d7a51">
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Prepend and append (x) char to `utt_text`</span></span>
<span><span class="va">cabnc_derived_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">cabnc_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>utt_text <span class="op">=</span> <span class="fu">str_c</span><span class="op">(</span><span class="st">"x"</span>, <span class="va">utt_text</span>, <span class="st">"x"</span>, sep <span class="op">=</span> <span class="st">" "</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="co"># Tokenize the utterances into bigrams</span></span>
<span><span class="va">cabnc_bigrams_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">cabnc_derived_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tidytext/man/unnest_tokens.html">unnest_tokens</a></span><span class="op">(</span></span>
<span>    output <span class="op">=</span> <span class="va">utt_bigram</span>, </span>
<span>    input <span class="op">=</span> <span class="va">utt_text</span>, </span>
<span>    token <span class="op">=</span> <span class="st">"ngrams"</span>,</span>
<span>    n <span class="op">=</span> <span class="fl">2</span></span>
<span>  <span class="op">)</span></span>
<span><span class="co"># Preview the first 10 lines</span></span>
<span><span class="va">cabnc_bigrams_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 10 × 6
&gt;    doc_id   part_id sex      age utt_id utt_bigram      
&gt;    &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;           
&gt;  1 KB0RE000 PS002   female   721      0 x you           
&gt;  2 KB0RE000 PS002   female   721      0 you enjoyed     
&gt;  3 KB0RE000 PS002   female   721      0 enjoyed yourself
&gt;  4 KB0RE000 PS002   female   721      0 yourself in     
&gt;  5 KB0RE000 PS002   female   721      0 in america      
&gt;  6 KB0RE000 PS002   female   721      0 america x       
&gt;  7 KB0RE000 PS006   male     601      1 x eh            
&gt;  8 KB0RE000 PS006   male     601      1 eh x            
&gt;  9 KB0RE000 PS002   female   721      2 x did           
&gt; 10 KB0RE000 PS002   female   721      2 did you</code></pre>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-exclamation-triangle" aria-label="exclamation-triangle"></i> Warning</strong></p>
<p>In <a href="#exm-td-cabnc-tokenization-bigrams-tidytext-start-end">Example&nbsp;<span>7.26</span></a> I used <code>x</code> as the start and end token. My though process was that <code>x</code> will be a unique token that will not be present in the utterances. This is a good strategy, but it is not foolproof. Another, more meaningful strategy may be to encode the start and end with <code>#</code> and <code>$</code>, respectively. In this case, however, this option is not ideal as the <code><a href="https://rdrr.io/pkg/tidytext/man/unnest_tokens.html">unnest_tokens()</a></code> and <code><a href="https://docs.ropensci.org/tokenizers/reference/ngram-tokenizers.html">tokenize_ngrams()</a></code> functions strip punctuation by default. This means that the <code>#</code> and <code>$</code> will be removed.</p>
</div>
</div>
</div>
<p>The most common tokenization strategy is to segment text into smaller units, often words. However, there are times when we may want to segment text into larger units, effectively collapsing over rows. For example, if we are working with a curated dataset which is tokenized by words, we may want to segment the text into sentences. A couple considerations are in order, however. First, we need to be clear about what we mean by ‘sentence’ and how we will segment the text into sentences. In some cases key cues for sentence boundaries, such as sentencial punctuation have been stripped from the text, making a simple defnition of a sentence difficult or impossible to be performed computationally. Second, we also need to be clear how we will handle the metadata variables. In other words, when we collapse over rows, we need to be aware and intentional about how we group these new units of observation. For example, if we collapse the <code>cabnc_unigrams_tbl</code> dataset into sentences, will we group the sentences by <code>doc_id</code> or <code>part_id</code> or some other combination of metadata variables?</p>
<p>Let’s see how we might collapse text rows into larger units using the original curated CABNC data frame <code>cabnc_curated_tbl</code>. Refer back to the output in <a href="#exm-td-cabnc-dataset-read-show">Example&nbsp;<span>7.20</span></a>. The values in <code>utt_text</code> are utterances, which may map to sentences in some cases, but often not. Regardless, there is no sentential punctuation to help identify sentences, even across utterance observations. Furthermore, it may not even make sense to dicuss sentences in the context of spoken language.</p>
<p>A unit that may make more sense is utterances per speaker per document. Note this context ‘per speaker per document’. In effect this is a grouping parameter for our approach to collapsing the text in <code>utt_text</code>. With a goal in mind we can turn to the <code>group_by()</code> function to group our dataset and then <code>summarize()</code> to collapse the text in <code>utt_text</code> with the <code>str_c()</code> and the parameter <code>collapse = " "</code>. The code is seen in <a href="#exm-td-cabnc-tokenization-utterances">Example&nbsp;<span>7.27</span></a>.</p>
<div id="exm-td-cabnc-tokenization-utterances" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.27 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-cabnc-tokenization-utterances_35ed9417cf92d7f124502d453d67de0f">
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Collapse utterances by speaker by document</span></span>
<span><span class="va">cabnc_utterances_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">cabnc_curated_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">doc_id</span>, <span class="va">part_id</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">summarize</span><span class="op">(</span>utt_text <span class="op">=</span> <span class="fu">str_c</span><span class="op">(</span><span class="va">utt_text</span>, collapse <span class="op">=</span> <span class="st">" "</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">ungroup</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview the first 10 lines</span></span>
<span><span class="va">cabnc_utterances_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">slice_head</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 10 × 3
&gt;    doc_id   part_id utt_text                                                    
&gt;    &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;                                                       
&gt;  1 KB0RE000 KB0PSUN Hmm Hello                                                   
&gt;  2 KB0RE000 PS002   You enjoyed yourself in America did you Oh very good yeah Y…
&gt;  3 KB0RE000 PS006   Eh Oh I covered a nice trip yes Er saw Mary and Andrew and …
&gt;  4 KB0RE001 KB0PSUN Neck of lamb 's off Hello Morning                           
&gt;  5 KB0RE001 PS005   You can tape me by all means but they probably wo n't like …
&gt;  6 KB0RE001 PS007   They want to know what spoken English is like Er now what d…
&gt;  7 KB0RE002 PS003   No Was born in Brockly I was n't born sorry about that my f…
&gt;  8 KB0RE002 PS007   You 're not Welsh speaking at all are you Mm mm but you are…
&gt;  9 KB0RE003 PS006   It 's all supposed to be anonymous anyway Right now do you …
&gt; 10 KB0RE003 PS007   I do n't think I I 'm likely to say anything use use down a…</code></pre>
</div>
</div>
</div>
<p>Now we have a data frame where the utterances for each speaker for each document are collapsed into a single observation. Yet by collapsing the utterances in this way, we have lost the speaker metadata <code>sex</code> and <code>age</code>. We can add this information by one of two approaches. The first is to simply add <code>sex</code> and <code>age</code> to the grouping parameter in <code>group_by()</code>. Since these variables are descriptors of <code>part_id</code> they will not change the result of our collapsing the text, but will be retained in the resulting output. The second approach is to use a join operation to add the metadata back to the collapsed dataset. I won’t go into this approach here as we will cover joins head-on in <a href="#sec-td-merging"><span>Section&nbsp;7.5</span></a>.</p>
</section></section><section id="sec-td-generation" class="level2" data-number="7.4"><h2 data-number="7.4" class="anchored" data-anchor-id="sec-td-generation">
<span class="header-section-number">7.4</span> Generation</h2>
<p>The process of generation involves the addition of information to a dataset. This differs from the previous transformation procedures in that normalization, recoding, and tokenization involve manipulating, classifiying, and/ or deriving information based on characteristics explicit in a dataset. Instead, generation involves deriving new information based on characteristics implicit in a dataset.</p>
<p>The most common type of operation involved in the generation process is the addition of linguistic annotation. This process can be accomplished manually by a researcher or research team or automatically through the use of pre-trained linguistic resources and/ or software. Ideally the annotation of linguistic information can be conducted automatically.</p>
<p>There are important considerations, however, that need to be taken into account when choosing whether linguistic annotation can be conducted automatically. First and foremost has to do with the type of annotation desired. Information such as part of speech (grammatical category) and morpho-syntactic information are the the most common types of linguistic annotation that can be conducted automatically.</p>
<p>Second, the degree to which the resource that will be used to annotate the linguistic information is aligned with the language variety and/or register is also a key consideration. As noted, automatic linguistic annotation methods are contingent on pre-trained resources. The language and language variety used to develop these resources may not be available for the language under investigation, or if it does, the language variety and/ or register may not align. The degree to which a resource does not align with the linguistic information targeted for annotation is directly related to the quality of the final annotations. To be clear, no annotation method, whether manual or automatic is guaranteed to be perfectly accurate.</p>
<section id="sec-td-generation-orientation" class="level3" data-number="7.4.1"><h3 data-number="7.4.1" class="anchored" data-anchor-id="sec-td-generation-orientation">
<span class="header-section-number">7.4.1</span> Orientation</h3>
<p>As an example, we’ll posit that we are conducting translation research. Specifically, we will set up an investigation into the effect of translation on the syntactic simplification of text. The basic notion is that when translators translate text from one language to another, they subconsciously simplify the text, compared to native texts <span class="citation" data-cites="Liu2021">(<a href="references.html#ref-Liu2021" role="doc-biblioref">Liu and Afzaal 2021</a>)</span>.</p>
<p>To assess this hypothesis, we will need to identify comparable translated and native texts. The ENNTT corpus contains native and translated English. The texts are drawn from European Parliament proceedings ensuring that the texts are comparable in terms of register.</p>
<p>The data dictionary for the curated native dataset appears in <a href="#tbl-td-enntt-native-dd">Table&nbsp;<span>7.7</span></a>.</p>
<div class="cell" data-hash="transform-datasets_cache/html/tbl-td-enntt-native-dd_6765076f052d3e4251e8d6ddc1c0a879">
<div class="cell-output-display">
<div id="tbl-td-enntt-native-dd" class="anchored">
<table class="table table-sm table-striped small" data-quarto-postprocess="true">
<caption>Table&nbsp;7.7: Data dictionary for the curated native ENNTT dataset.</caption>
<thead><tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">variable</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">name</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">variable_type</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">session_id</td>
<td style="text-align: left;">Session ID</td>
<td style="text-align: left;">categorical</td>
<td style="text-align: left;">Unique identifier for each session</td>
</tr>
<tr class="even">
<td style="text-align: left;">speaker_id</td>
<td style="text-align: left;">Speaker ID</td>
<td style="text-align: left;">categorical</td>
<td style="text-align: left;">Unique identifier for each speaker</td>
</tr>
<tr class="odd">
<td style="text-align: left;">state</td>
<td style="text-align: left;">State</td>
<td style="text-align: left;">categorical</td>
<td style="text-align: left;">The country or region the speaker is from</td>
</tr>
<tr class="even">
<td style="text-align: left;">session_seq</td>
<td style="text-align: left;">Session Sequence</td>
<td style="text-align: left;">ordinal</td>
<td style="text-align: left;">The order in which the session occurred</td>
</tr>
<tr class="odd">
<td style="text-align: left;">text</td>
<td style="text-align: left;">Text</td>
<td style="text-align: left;">categorical</td>
<td style="text-align: left;">The spoken text during the session</td>
</tr>
<tr class="even">
<td style="text-align: left;">type</td>
<td style="text-align: left;">Type</td>
<td style="text-align: left;">categorical</td>
<td style="text-align: left;">The type of speaker. Natives in this dataset.</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
<p>Both the natives and translations datasets have the same variables. For the purposes of this investigation, the <code>text</code> and <code>type</code> variables are the most relevant. A variable to index the text, such as <code>doc_id</code>, will be useful as we move forward and will be added to the dataset.</p>
<p>The next step is to operationalize what we mean by syntactic simplification. There are many measures of syntactic complexity <span class="citation" data-cites="Szmrecsanyi2004">(<a href="references.html#ref-Szmrecsanyi2004" role="doc-biblioref">Szmrecsanyi 2004</a>)</span>. For our purposes, let’s focus on two: number of T-units and sentence length (in words). Length is straightforward to calculate after word tokenization but a T-unit is a bit more involved. A T-unit is a main clause and all of its subordinate clauses. To calculate the number of T-units, we will need to identify the main clauses and their subordinate clauses.</p>
<p>An idealized transformed dataset for this investigation would look something like <a href="#tbl-td-generation-idealized">Table&nbsp;<span>7.8</span></a>.</p>
<div id="tbl-td-generation-idealized" class="anchored">
<table class="table-sm table-striped small table">
<caption>Table&nbsp;7.8: Idealized transformed dataset for the syntactic simplification investigation.</caption>
<colgroup>
<col style="width: 4%">
<col style="width: 7%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 77%">
</colgroup>
<thead><tr class="header">
<th>doc_id</th>
<th>type</th>
<th>t_units</th>
<th>word_len</th>
<th>text</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>translated</td>
<td>1</td>
<td>5</td>
<td>I am happy right now.</td>
</tr>
<tr class="even">
<td>2</td>
<td>translated</td>
<td>3</td>
<td>11</td>
<td>I think that John believes that Mary is a good person.</td>
</tr>
<tr class="odd">
<td>3</td>
<td>native</td>
<td>2</td>
<td>8</td>
<td>She thinks I am not happy right now.</td>
</tr>
<tr class="even">
<td>4</td>
<td>native</td>
<td>4</td>
<td>21</td>
<td>Although she knew that the weather was bad, Mary decided to go for a walk, hoping that she would feel better.</td>
</tr>
</tbody>
</table>
</div>
<p>To identify the main clauses and their subordinate clauses, we will need to annotate the ENNTT texts with syntactic information. Specifically, we will need to identify and count the main clauses and their subordinate clauses.</p>
</section><section id="sec-td-generation-application" class="level3" data-number="7.4.2"><h3 data-number="7.4.2" class="anchored" data-anchor-id="sec-td-generation-application">
<span class="header-section-number">7.4.2</span> Application</h3>
<p>As fun as it would be to hand-annotate the ENNTT corpus, we will instead turn to automatic linguistic annotation. Specifically, we will use the <code>udpipe</code> package <span class="citation" data-cites="R-udpipe">(<a href="references.html#ref-R-udpipe" role="doc-biblioref">Wijffels 2023</a>)</span> which provides an interface for annotating text using pre-trained models from the <a href="https://universaldependencies.org/">Universal Dependencies</a> (UD) project <span class="citation" data-cites="Nivre2020">(<a href="references.html#ref-Nivre2020" role="doc-biblioref">Nivre et al. 2020</a>)</span>. The UD project is an effort to develop cross-linguistically consistent treebank annotation for a variety of languages.</p>
<p>Our first step, then, is to peruse the available pre-trained models for the languages we are interested in and selected the most register-aligned models. The models, model names, and licensing information are documented in the <code>udpipe</code> package and can be accessed by running <code>?udpipe::udpipe_download_model()</code> in the R console. For illustrative purposes, the <code>english</code> treebank model from the <em>https://github.com/bnosac/udpipe.models.ud</em> repository which is released under the <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC-BY-SA license</a>. This model is trained on various sources including news, Wikipedia, and web data of various genres.</p>
<p>Let’s set the stage by providing an overview of the annotation process.</p>
<ol type="1">
<li>Load the <code>udpipe</code> package.</li>
<li>Select the pre-trained model to use and the directory where the model will be stored in your local environment.</li>
<li>Prepare the dataset to be annotated (if necessary). This includes ensuring that the dataset has a column of text to be annotated and a grouping column. By default, the names of these columns are expected to be <code>text</code> and <code>doc_id</code>, respectively. The <code>text</code> column needs to be a character vector and the <code>doc_id</code> column needs to be a unique index for each text to be annotated.</li>
<li>Annotate the dataset. The result returns a data frame.</li>
</ol>
<p>Steps 3 and 4 are repeated for the <code>enntt_natives_curated</code> and the <code>enntt_translations_curated</code> datasets. For brevity, I will only show the code for the dataset for the natives. Additionally, I will subset the dataset to 10,000 randomly selected lines for both dataset, as in <a href="#exm-td-generation-subset-natives">Example&nbsp;<span>7.28</span></a> for the natives. Syntactic annotation is a computationally expensive operation and the natives and translations datasets contain 116,341 and 738,597 observations, respectively.</p>
<div id="exm-td-generation-subset-natives" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.28 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-generation-subset-natives_65ba136a91b96524e4fc8133ade06674">
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Subset the natives ENNTT dataset</span></span>
<span><span class="va">enntt_natives_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">enntt_natives_curated_tbl</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">slice_sample</span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10000</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-hand-point-up" aria-label="hand-point-up"></i> Tip</strong> Computational Performance</p>
<p>In your own research computationally expensive cannot be avoided, but it can be managed. One strategy is to work with a subset of the data until your code is working as expected. Once you are confident that your code is working as expected, then you can scale up to the full dataset.</p>
<p>If you are using Quarto, you can use the <code>cache: true</code> metadata field in your code blocks to cache the results of computationally expensive code blocks. This will allow you to run your code once and then use the cached results for subsequent runs.</p>
<p>Parallel processing is another strategy for managing computationally expensive code. Some packages, such as <code>udpipe</code>, have built-in support for parallel processing. Other packages, such as <code>tidytext</code>, do not. In these cases, you can use the <code>future</code> package <span class="citation" data-cites="R-future">(<a href="references.html#ref-R-future" role="doc-biblioref">Bengtsson 2023</a>)</span> to parallelize your code.</p>
</div>
</div>
</div>
<p>With the <code>enntt_natives_tbl</code> object, let’s execute steps 1-4, as seen in <a href="#exm-td-generation-udpipe-natives">Example&nbsp;<span>7.29</span></a>.</p>
<div id="exm-td-generation-udpipe-natives" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.29 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-generation-udpipe-natives-show_528be2d397e24450c9d671e689514e41">
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load package</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://bnosac.github.io/udpipe/en/index.html">udpipe</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Model and directory</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="st">"english"</span></span>
<span><span class="va">model_dir</span> <span class="op">&lt;-</span> <span class="st">"../data/"</span></span>
<span></span>
<span><span class="co"># Prepare the dataset to be annotated</span></span>
<span><span class="va">enntt_natives_prepped_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">enntt_natives_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>doc_id <span class="op">=</span> <span class="fu">row_number</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">doc_id</span>, <span class="va">text</span>, <span class="va">type</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Annotate the dataset</span></span>
<span><span class="va">enntt_natives_ann</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/udpipe/man/udpipe.html">udpipe</a></span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="va">enntt_natives_prepped_tbl</span>, </span>
<span>    object <span class="op">=</span> <span class="va">model</span>, </span>
<span>    model_dir <span class="op">=</span> <span class="va">model_dir</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview </span></span>
<span><span class="fu">glimpse</span><span class="op">(</span><span class="va">enntt_natives_anno</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-hash="transform-datasets_cache/html/td-generation-udpipe-natives-run_e2ed3dca2bdb0860068eb7095e164508">
<div class="cell-output cell-output-stdout">
<pre><code>&gt; Rows: 264,124
&gt; Columns: 17
&gt; $ doc_id        &lt;chr&gt; "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "…
&gt; $ paragraph_id  &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…
&gt; $ sentence_id   &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…
&gt; $ sentence      &lt;chr&gt; "It is extremely important that action is taken to ensur…
&gt; $ start         &lt;int&gt; 1, 4, 7, 17, 27, 32, 39, 42, 48, 51, 58, 63, 66, 73, 77,…
&gt; $ end           &lt;int&gt; 2, 5, 15, 25, 30, 37, 40, 46, 49, 56, 61, 64, 71, 75, 82…
&gt; $ term_id       &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…
&gt; $ token_id      &lt;chr&gt; "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11",…
&gt; $ token         &lt;chr&gt; "It", "is", "extremely", "important", "that", "action", …
&gt; $ lemma         &lt;chr&gt; "it", "be", "extremely", "important", "that", "action", …
&gt; $ upos          &lt;chr&gt; "PRON", "AUX", "ADV", "ADJ", "SCONJ", "NOUN", "AUX", "VE…
&gt; $ xpos          &lt;chr&gt; "PRP", "VBZ", "RB", "JJ", "IN", "NN", "VBZ", "VBN", "TO"…
&gt; $ feats         &lt;chr&gt; "Case=Nom|Gender=Neut|Number=Sing|Person=3|PronType=Prs"…
&gt; $ head_token_id &lt;chr&gt; "4", "4", "4", "0", "8", "8", "8", "4", "10", "8", "13",…
&gt; $ dep_rel       &lt;chr&gt; "expl", "cop", "advmod", "root", "mark", "nsubj:pass", "…
&gt; $ deps          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
&gt; $ misc          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …</code></pre>
</div>
</div>
</div>
<p>There is quite a bit of information which is returned from <code><a href="https://rdrr.io/pkg/udpipe/man/udpipe.html">udpipe()</a></code>. Note that the input lines have been tokenized by word. Each token includes the <code>token</code>, <code>lemma</code>, part of speech (<code>upos</code> and <code>xpos</code>), morphological features (<code>feats</code>), and syntactic relationships (<code>head_token_id</code> and <code>dep_rel</code>). The <code>token_id</code> keeps track of the token’s position in the sentence and the <code>sentence_id</code> keeps track of the sentence’s position in the original text. In the case of the Europarl dataset, most values of <code>lines</code> are just one sentence, but there are some cases where the <code>lines</code> variable contains multiple sentences in which the <code>sid</code> will be incremented. Finally, the <code>doc_id</code> column and its values correspond to the <code>doc_id</code> in the <code>enntt_natives_tbl</code> dataset.</p>
<p>The number of variables in the <code><a href="https://rdrr.io/pkg/udpipe/man/udpipe.html">udpipe()</a></code> annotation output is quite overwhelming. However, these attributes come in handy for manipulating, extracting, and plotting information based on lexical and syntactic patterns. See the dependency tree in <a href="#fig-td-generation-udpipe-english-plot-tree">Figure&nbsp;<span>7.1</span></a> for an example of the syntactic information that can be extracted from the <code><a href="https://rdrr.io/pkg/udpipe/man/udpipe.html">udpipe()</a></code> annotation output.</p>
<div class="cell" data-hash="transform-datasets_cache/html/fig-td-generation-udpipe-english-plot-tree_7b950d137e5c88a0258e0e251005aacc">
<div class="cell-output-display">
<div id="fig-td-generation-udpipe-english-plot-tree" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="transform-datasets_files/figure-html/fig-td-generation-udpipe-english-plot-tree-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">Figure&nbsp;7.1: Plot of the syntactic tree for a sentence in the ENNTT natives dataset.</figcaption></figure>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-medal" aria-label="medal"></i> Dive deeper</strong></p>
<p>The plot in <a href="#fig-td-generation-udpipe-english-plot-tree">Figure&nbsp;<span>7.1</span></a> was created using the <code>rsyntax</code> package <span class="citation" data-cites="R-rsyntax">(<a href="references.html#ref-R-rsyntax" role="doc-biblioref">Welbers and van Atteveldt 2022</a>)</span>. In addition to creating dependency tree plots, the <code>rsyntax</code> package can be used to extract syntactic patterns from the <code><a href="https://rdrr.io/pkg/udpipe/man/udpipe.html">udpipe()</a></code> annotation output. <a href="https://github.com/vanatteveldt/rsyntax">See the documentation for more information</a>.</p>
</div>
</div>
</div>
<p>In <a href="#fig-td-generation-udpipe-english-plot-tree">Figure&nbsp;<span>7.1</span></a> we see the syntactic tree for a sentence in the ENNTT natives dataset. Each node is labeled with the <code>token_id</code> which provides the linear ordering of the sentence. Above the nodes the <code>dep_relation</code>, or dependency relationship label is provided. These labels are based on the UD project’s <a href="https://universaldependencies.org/u/dep/index.html">dependency relations</a>. We can see that the ‘ROOT’ relation is at the top of the tree and corresponds to the verb ‘brought’. ‘ROOT’ relations mark predicates in the sentence. Not seen in the example tree, ‘cop’ relation is a copular, or non-verbal predicate and should be included. These are the key syntactic pattern we will use to identify main clauses for T-units. Now we need to identify the subordinate clauses. In the UD project’s listings, the relations ‘ccomp’ (clausal complement), ‘xcomp’ (open clausal complement), and ‘acl:relcl’ (relative clause), as seen in <a href="#fig-td-generation-udpipe-english-plot-tree">Figure&nbsp;<span>7.1</span></a>) are subordinate clauses.</p>
<p>To calculate the number of T-units and words per sentence we turn to the <code>dplyr</code> package. We will use the <code>group_by()</code> function to group the dataset by <code>doc_id</code> and <code>sentence_id</code> and then use the <code>summarize()</code> function to calculate the number of T-units and words per sentence, where a T-unit is the combination of the sum of main clauses and sum of subordinante clauses. The code is seen in <a href="#exm-td-generation-udpipe-natives-tunits-words">Example&nbsp;<span>7.30</span></a>.</p>
<div id="exm-td-generation-udpipe-natives-tunits-words" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.30 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-generation-udpipe-natives-tunits-words_aa36d762821fb70fddb24ea9e9d1b041">
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate the number of T-units and words per sentence</span></span>
<span><span class="va">enntt_natives_ann_tunits_words_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">enntt_natives_ann</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">doc_id</span>, <span class="va">sentence_id</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">summarize</span><span class="op">(</span></span>
<span>    main_clauses <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">dep_rel</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"ROOT"</span>, <span class="st">"cop"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    subord_clauses <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">dep_rel</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"ccomp"</span>, <span class="st">"xcomp"</span>, <span class="st">"acl:relcl"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    t_units <span class="op">=</span> <span class="va">main_clauses</span> <span class="op">+</span> <span class="va">subord_clauses</span>,</span>
<span>    word_len <span class="op">=</span> <span class="fu">n</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">ungroup</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="fu">glimpse</span><span class="op">(</span><span class="va">enntt_natives_ann_tunits_words_tbl</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; Rows: 10,199
&gt; Columns: 6
&gt; $ doc_id         &lt;chr&gt; "1", "10", "100", "1000", "10000", "1001", "1002", "100…
&gt; $ sentence_id    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…
&gt; $ main_clauses   &lt;int&gt; 1, 0, 0, 0, 2, 0, 0, 1, 1, 0, 1, 1, 1, 0, 2, 0, 1, 1, 1…
&gt; $ subord_clauses &lt;int&gt; 3, 2, 1, 0, 1, 2, 1, 1, 0, 2, 1, 0, 3, 2, 0, 4, 2, 1, 1…
&gt; $ t_units        &lt;int&gt; 4, 2, 1, 0, 3, 2, 1, 2, 1, 2, 2, 1, 4, 2, 2, 4, 3, 2, 2…
&gt; $ word_len       &lt;int&gt; 21, 25, 27, 15, 40, 43, 29, 23, 13, 30, 33, 9, 68, 35, …</code></pre>
</div>
</div>
</div>
<p>A quick spot check of some sentences calculations <code>enntt_natives_ann_tunits_words_tbl</code> dataset against the <code>enntt_natives_ann</code> is good to ensure that the calculation is working as expected. In <a href="#fig-td-generation-udpipe-natives-tunits">Figure&nbsp;<span>7.2</span></a> we see a sentence that has a word length of 13 and a T-unit value of 5.</p>
<div class="cell" data-hash="transform-datasets_cache/html/fig-td-generation-udpipe-natives-tunits_bf0045b6b46fbe6b467414a3c9341661">
<div class="cell-output-display">
<div id="fig-td-generation-udpipe-natives-tunits" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="transform-datasets_files/figure-html/fig-td-generation-udpipe-natives-tunits-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">Figure&nbsp;7.2: Sentence with a word length of 13 and a T-unit value of 5.</figcaption></figure>
</div>
</div>
</div>
<p>Now we can drop the columns that we don’t need by using the <code>select()</code> function. I will assign the result to <code>enntt_natives_syn_comp</code> as we will be working with translated texts, as seen in <a href="#exm-td-generation-udpipe-natives-tunits-words-select">Example&nbsp;<span>7.31</span></a>.</p>
<div id="exm-td-generation-udpipe-natives-tunits-words-select" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.31 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-generation-udpipe-natives-tunits-words-select_873891f1780bd7b112fe9d64eba06dfa">
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Drop columns</span></span>
<span><span class="va">enntt_natives_syn_comp</span> <span class="op">&lt;-</span> </span>
<span>  <span class="va">enntt_natives_ann_tunits_words_tbl</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">doc_id</span>, <span class="va">t_units</span>, <span class="va">word_len</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>Now we can repeat the process for the ENNTT translated dataset. I will assign the result to <code>enntt_translations_syn_comp</code> as we will be working with native texts from this corpus. The next step is to join the <code>sentences</code> from the Europarl, and ENNTT, into our dataset so that we have the information we set out to generate for both datasets. Then we will concatenate both the <code>enntt_natives_syn_comp</code> and <code>enntt_translations_syn_comp</code> datasets into a single dataset. Both the join and the contactenation will be covered in the next section.</p>
</section></section><section id="sec-td-merging" class="level2" data-number="7.5"><h2 data-number="7.5" class="anchored" data-anchor-id="sec-td-merging">
<span class="header-section-number">7.5</span> Merging</h2>
<p>One final class of transformations that can be applied to curated datasets to enhance their informativeness for a research project is the process of merging two or more datasets. There are two primary types of merging: joins and concatenation. <strong>Joins</strong> can be row- or column-wise operations that combine datasets based on a common attribute or set of attributes. <strong>Concatenation</strong> is exclusively a row-wise operation that combines datasets that share the same attributes.</p>
<p>Of the two types of merges, joins are the most powerful and sometimes more difficult to understand. When two datasets are joined at least one common variable must be shared between the two datasets. The common variable(s) are referred to as <strong>keys</strong>. The keys are used to match observations in one dataset with observations in another dataset by serving as an index.</p>
<p>There are a number of join types. The most common are left, full, semi, and anti. The type of join determines which observations are retained in the resulting dataset. Let’s see this in practice. First, let’s create two datasets to join with a common variable <code>key</code>, as seen in <a href="#exm-td-merging-join-dfs">Example&nbsp;<span>7.33</span></a>.</p>
<div id="exm-td-merging-join-dfs" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.33 </strong></span>&nbsp;</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div id="exm-td-merging-join-a-df" class="theorem example quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><span class="theorem-title"><strong>Example 7.32 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-merging-join-a-df_5ccc82c1dd5ad3f1cca2b92c0fcb27e6">
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">a_tbl</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu">tibble</span><span class="op">(</span></span>
<span>    key <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">3</span>, <span class="fl">5</span>, <span class="fl">8</span><span class="op">)</span>,</span>
<span>    a <span class="op">=</span> <span class="va">letters</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="va">a_tbl</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 5 × 2
&gt;     key a    
&gt;   &lt;dbl&gt; &lt;chr&gt;
&gt; 1     1 a    
&gt; 2     2 b    
&gt; 3     3 c    
&gt; 4     5 d    
&gt; 5     8 e</code></pre>
</div>
</div>
</div>
<div id="second" class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="cell" data-hash="transform-datasets_cache/html/td-merging-join-b-df_af7699360503e7627f4b6102b2e7435d">
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">b_tbl</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">tibble</span><span class="op">(</span></span>
<span>    key <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">4</span>, <span class="fl">6</span>, <span class="fl">8</span><span class="op">)</span>,</span>
<span>    b <span class="op">=</span> <span class="va">letters</span><span class="op">[</span><span class="fl">6</span><span class="op">:</span><span class="fl">10</span><span class="op">]</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="va">b_tbl</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 5 × 2
&gt;     key b    
&gt;   &lt;dbl&gt; &lt;chr&gt;
&gt; 1     1 f    
&gt; 2     2 g    
&gt; 3     4 h    
&gt; 4     6 i    
&gt; 5     8 j</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<p>The <code>a_tbl</code> and the <code>b_tbl</code> datasets share the <code>key</code> variable, but the values in the <code>key</code> variable are not identical. The two datasets share values <code>1</code>, <code>2</code>, and <code>8</code>. The <code>a_tbl</code> dataset has values <code>3</code> and <code>5</code> in the <code>key</code> variable and the <code>b_tbl</code> dataset has values <code>4</code> and <code>6</code> in the <code>key</code> variable.</p>
<p>If we apply a left join to the <code>a_tbl</code> and <code>b_tbl</code> datasets, the result will be a dataset that retains all of the observations in the <code>a_tbl</code> dataset and only those observations in the <code>b_tbl</code> dataset that have a match in the <code>a_tbl</code> dataset. The result is seen in <a href="#exm-td-merging-join-left">Example&nbsp;<span>7.34</span></a>.</p>
<div id="exm-td-merging-join-left" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.34 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-merging-join-left_e3d52681a55f351e70e01831ed86b0c6">
<div class="sourceCode" id="cb60"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">left_join</span><span class="op">(</span>x <span class="op">=</span> <span class="va">a_tbl</span>, y <span class="op">=</span> <span class="va">b_tbl</span>, by <span class="op">=</span> <span class="st">"key"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 5 × 3
&gt;     key a     b    
&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;
&gt; 1     1 a     f    
&gt; 2     2 b     g    
&gt; 3     3 c     &lt;NA&gt; 
&gt; 4     5 d     &lt;NA&gt; 
&gt; 5     8 e     j</code></pre>
</div>
</div>
</div>
<p>Now, if the key variable has the same name, R will recognize and assume that this is the variable to join on and we don’t need the <code>by =</code> argument, but if there are multiple potential key variables, we use <code>by =</code> to specify which one to use.</p>
<p>A full join retains all observations in both datasets, as seen in <a href="#exm-td-merging-join-full">Example&nbsp;<span>7.35</span></a>.</p>
<div id="exm-td-merging-join-full" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.35 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-merging-join-full_b8fd0a899a3fa12361f31c89cfa68556">
<div class="sourceCode" id="cb62"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">full_join</span><span class="op">(</span>x <span class="op">=</span> <span class="va">a_tbl</span>, y <span class="op">=</span> <span class="va">b_tbl</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 7 × 3
&gt;     key a     b    
&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;
&gt; 1     1 a     f    
&gt; 2     2 b     g    
&gt; 3     3 c     &lt;NA&gt; 
&gt; 4     5 d     &lt;NA&gt; 
&gt; 5     8 e     j    
&gt; 6     4 &lt;NA&gt;  h    
&gt; 7     6 &lt;NA&gt;  i</code></pre>
</div>
</div>
</div>
<p>Left and full joins maintain or increase the number of observations. On the other hand, semi and anti joins aim to decrease the number of observations. A semi join retains only those observations in the left dataset that have a match in the right dataset, as seen in <a href="#exm-td-merging-join-semi">Example&nbsp;<span>7.36</span></a>.</p>
<div id="exm-td-merging-join-semi" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.36 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-merging-join-semi_3e66444e35f7242036b792d7aa5ccd3e">
<div class="sourceCode" id="cb64"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">semi_join</span><span class="op">(</span>x <span class="op">=</span> <span class="va">a_tbl</span>, y <span class="op">=</span> <span class="va">b_tbl</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 3 × 2
&gt;     key a    
&gt;   &lt;dbl&gt; &lt;chr&gt;
&gt; 1     1 a    
&gt; 2     2 b    
&gt; 3     8 e</code></pre>
</div>
</div>
</div>
<p>And an anti join retains only those observations in the left dataset that do not have a match in the right dataset, as seen in <a href="#exm-td-merging-join-anti">Example&nbsp;<span>7.37</span></a>.</p>
<div id="exm-td-merging-join-anti" class="theorem example">
<p><span class="theorem-title"><strong>Example 7.37 </strong></span>&nbsp;</p>
<div class="cell" data-hash="transform-datasets_cache/html/td-merging-join-anti_36c17ceabe12cf8fca0a0e571db81405">
<div class="sourceCode" id="cb66"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">anti_join</span><span class="op">(</span>x <span class="op">=</span> <span class="va">a_tbl</span>, y <span class="op">=</span> <span class="va">b_tbl</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 2 × 2
&gt;     key a    
&gt;   &lt;dbl&gt; &lt;chr&gt;
&gt; 1     3 c    
&gt; 2     5 d</code></pre>
</div>
</div>
</div>
<p>Of these join types, the left join and the anti join are some of the most common to encounter in research projects.</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-lightbulb" aria-label="lightbulb"></i> Consider this</strong></p>
<p>In addition to datasets that are part of an acquired resource or derived from a corpus resource, there are also a number of datasets that are included in R packages that are particularly relevant for text analysis. For example, the <code>tidytext</code> package includes <code>sentiments</code> and <code>stop_words</code> datasets. The <code>lexicon</code> package <span class="citation" data-cites="R-lexicon">(<a href="references.html#ref-R-lexicon" role="doc-biblioref">Rinker 2019</a>)</span> includes large number of datasets that include sentiment lexicons, stopword lists, contractions, and more.</p>
<p>Consider the <code><a href="https://rdrr.io/pkg/lexicon/man/key_contractions.html">lexicon::key_contractions</a></code> dataset. This dataset includes a list of common contractions and their expanded forms.</p>
<p>What needs to be done to join these two datasets? What are the keys? What type of join should be used? What is the resulting dataset?</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div id="first" class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="cell" data-hash="transform-datasets_cache/html/tbl-td-merging-join-lexicon-contractions-list_f8904ab304ff1485ab6e5d74ead68dec">
<div class="cell-output-display">
<div id="tbl-td-merging-join-lexicon-contractions-list" class="anchored">
<table class="table table-sm table-striped small" data-quarto-postprocess="true">
<caption>Table&nbsp;7.9: Common contractions and expanded forms.</caption>
<thead><tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">contraction</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">expanded</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">'cause</td>
<td style="text-align: left;">because</td>
</tr>
<tr class="even">
<td style="text-align: left;">'tis</td>
<td style="text-align: left;">it is</td>
</tr>
<tr class="odd">
<td style="text-align: left;">'twas</td>
<td style="text-align: left;">it was</td>
</tr>
<tr class="even">
<td style="text-align: left;">ain't</td>
<td style="text-align: left;">am not</td>
</tr>
<tr class="odd">
<td style="text-align: left;">aren't</td>
<td style="text-align: left;">are not</td>
</tr>
<tr class="even">
<td style="text-align: left;">can't</td>
<td style="text-align: left;">can not</td>
</tr>
<tr class="odd">
<td style="text-align: left;">could've</td>
<td style="text-align: left;">could have</td>
</tr>
<tr class="even">
<td style="text-align: left;">it's</td>
<td style="text-align: left;">it is</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
</div>
<div id="tbl-td-merging-join-lexicon-contractions" class="quarto-layout-cell anchored" style="flex-basis: 50.0%;justify-content: center;">
<table class="table-sm table-striped small table">
<caption>Table&nbsp;7.10: Example tokenized dataset with contractions.</caption>
<thead><tr class="header">
<th style="text-align: left;">doc_id</th>
<th style="text-align: left;">sent_id</th>
<th style="text-align: left;">token_id</th>
<th style="text-align: left;">token</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">I</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">can’t</td>
</tr>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">believe</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">that</td>
</tr>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">it’s</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">not</td>
</tr>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">butter</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">!</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
</div>
</div>
<section id="sec-td-merging-orientation" class="level3" data-number="7.5.1"><h3 data-number="7.5.1" class="anchored" data-anchor-id="sec-td-merging-orientation">
<span class="header-section-number">7.5.1</span> Orientation</h3>
<p>With this in mind, let’s return to our syntactic simplification investigation. Recall that we started with two curated ENNTT datasets: the natives and translations. We manipulated these datasets subsetting them to 10,000 randomly selected lines, prepped them for annotation by adding a <code>doc_id</code> column and dropping all columns except <code>doc_id</code>, <code>text</code>, and <code>type</code>, and then annotated them using the <code>udpipe</code> package. We then calculated the number of T-units and words per sentence.</p>
<p>These steps produced four datasets that we will want to compile together into one ahead of analysis, two datasets for the natives and two datasets for the translations. The first dataset for each is the prepped dataset with the <code>doc_id</code>, <code>text</code>, and <code>type</code> columns. The second datasets are the datasets with the <code>doc_id</code>, <code>t_units</code>, and <code>word_len</code> columns.</p>
<p>In the end, we want a dataset that looks something like <a href="#tbl-td-merging-idealized">Table&nbsp;<span>7.11</span></a>.</p>
<div id="tbl-td-merging-idealized" class="anchored">
<table class="table-sm table-striped small table">
<caption>Table&nbsp;7.11: Idealized merged dataset for the syntactic simplification investigation.</caption>
<colgroup>
<col style="width: 6%">
<col style="width: 12%">
<col style="width: 8%">
<col style="width: 9%">
<col style="width: 62%">
</colgroup>
<thead><tr class="header">
<th>doc_id</th>
<th>type</th>
<th>t_units</th>
<th>word_len</th>
<th>text</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>natives</td>
<td>1</td>
<td>5</td>
<td>I am happy right now.</td>
</tr>
<tr class="even">
<td>2</td>
<td>translation</td>
<td>3</td>
<td>11</td>
<td>I think that John believes that Mary is a good person.</td>
</tr>
</tbody>
</table>
</div>
<p>To create this unified dataset, we will need to apply joins and concatenation. First, we will join the prepped datasets with the annotated datasets. Then we will concatenate the two resulting datasets.</p>
</section><section id="sec-td-merging-application" class="level3" data-number="7.5.2"><h3 data-number="7.5.2" class="anchored" data-anchor-id="sec-td-merging-application">
<span class="header-section-number">7.5.2</span> Application</h3>
<p>…</p>
</section></section><section id="summary" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="summary">Summary</h2>
<p>In this chapter we covered the process of transforming datasets. The goal is to manipulate the curated dataset to make it align better for analysis. There are four general types of transformation steps: normalization, recoding, tokenization, generation, and merging. In any given research project some or all of these steps will be employed –but not necessarily in the order presented in this chapter. Furthermore, there may also be various datasets generated in at this stage each with a distinct analysis focus in mind.</p>
<!--  

?? Add at the end of the chapter?

[x] Add data checks
[ ] Reminder on writing the dataset and data dictionary to *data/derived/* directory
  [ ] There may be multiple transformed datasets, so it is important to di  stinguish them from one another and document them separately.
[ ] Reminder to review and document code added to the *code/* directory, within the *3-transform-dataset.qmd* file.

-->
<p>In any case, it is important to write these datasets to disk and to document them according to reproducible research principles.</p>
<p>This chapter concludes the section on data/ dataset preparation. The next section we turn to analyzing datasets. This is the stage where we interrogate the datasets to derive knowledge and insight either through exploratory, predictive, or inferential methods.</p>
</section><section id="activities" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="activities">Activities</h2>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-file-code" aria-label="file-code"></i> Recipe</strong></p>
<!-- Understand, apply, and analyze verbs: https://tips.uark.edu/blooms-taxonomy-verb-chart/ -->
<!-- [ ] update recipe -->
<p><strong>What</strong>: <a href="https://lin380.github.io/tadr/articles/recipe_8.html">Dataset manipulation: tokenization and joining datasets</a><br><strong>How</strong>: Read Recipe 8 and participate in the Hypothes.is online social annotation.<br><strong>Why</strong>: To work with to primary types of transformations, tokenization and joins. Tokenization is the process of recasting textual units as smaller textual units. The process of joining datasets aims to incorporate other datasets to augment or filter the dataset of interest.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-flask" aria-label="flask"></i> Lab</strong></p>
<!-- Analyze, evaluate, and create verbs: https://tips.uark.edu/blooms-taxonomy-verb-chart/ -->
<!-- [ ] update lab -->
<p><strong>What</strong>: <a href="https://github.com/lin380/lab_8">Dataset manipulation: tokenization and joining datasets</a><br><strong>How</strong>: Clone, fork, and complete the steps in Lab 8.<br><strong>Why</strong>: To gain experience working with coding strategies for transforming datasets using tidyverse functions and regular expressions, practice reading/ writing data from/ to disk, and implement organizational strategies for organizing and documenting a dataset in reproducible fashion.</p>
</div>
</div>
</div>
</section><section id="questions" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="questions">Questions</h2>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><i class="fa-solid fa-wrench" aria-label="wrench"></i> <strong>Conceptual questions</strong></p>
<ol type="1">
<li>…</li>
<li>…</li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><i class="fa-solid fa-wrench" aria-label="wrench"></i> <strong>Technical questions</strong></p>
<ol type="1">
<li>…</li>
<li>…</li>
</ol>
</div>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-R-future" class="csl-entry" role="listitem">
Bengtsson, Henrik. 2023. <em>Future: Unified Parallel and Distributed Processing in r for Everyone</em>. <a href="https://CRAN.R-project.org/package=future">https://CRAN.R-project.org/package=future</a>.
</div>
<div id="ref-Liu2021" class="csl-entry" role="listitem">
Liu, Kanglong, and Muhammad Afzaal. 2021. <span>“Syntactic Complexity in Translated and Non-Translated Texts: A Corpus-Based Study of Simplification.”</span> Edited by Diego Raphael Amancio. <em>PLOS ONE</em> 16 (6): e0253454. <a href="https://doi.org/10.1371/journal.pone.0253454">https://doi.org/10.1371/journal.pone.0253454</a>.
</div>
<div id="ref-R-tokenizers" class="csl-entry" role="listitem">
Mullen, Lincoln. 2022. <em>Tokenizers: Fast, Consistent Tokenization of Natural Language Text</em>. <a href="https://CRAN.R-project.org/package=tokenizers">https://CRAN.R-project.org/package=tokenizers</a>.
</div>
<div id="ref-Nivre2020" class="csl-entry" role="listitem">
Nivre, Joakim, Marie-Catherine De Marneffe, Filip Ginter, Jan Hajič, Christopher D. Manning, Sampo Pyysalo, Sebastian Schuster, Francis Tyers, and Daniel Zeman. 2020. <span>“Universal Dependencies V2: An Evergrowing Multilingual Treebank Collection.”</span> <em>arXiv Preprint arXiv:2004.10643</em>. <a href="https://arxiv.org/abs/2004.10643">https://arxiv.org/abs/2004.10643</a>.
</div>
<div id="ref-R-lexicon" class="csl-entry" role="listitem">
Rinker, Tyler. 2019. <em>Lexicon: Lexicons for Text Analysis</em>. <a href="https://github.com/trinker/lexicon">https://github.com/trinker/lexicon</a>.
</div>
<div id="ref-R-tidytext" class="csl-entry" role="listitem">
Robinson, David, and Julia Silge. 2023. <em>Tidytext: Text Mining Using Dplyr, Ggplot2, and Other Tidy Tools</em>. <a href="https://github.com/juliasilge/tidytext">https://github.com/juliasilge/tidytext</a>.
</div>
<div id="ref-Szmrecsanyi2004" class="csl-entry" role="listitem">
Szmrecsanyi, Benedikt. 2004. <span>“On Operationalizing Syntactic Complexity.”</span> In <em>Le Poids Des Mots. Proceedings of the 7th International Conference on Textual Data Statistical Analysis. Louvain-La-Neuve</em>, 2:1032–39.
</div>
<div id="ref-Tottie2011" class="csl-entry" role="listitem">
Tottie, Gunnel. 2011. <span>“Uh and Um as Sociolinguistic Markers in British English.”</span> <em>International Journal of Corpus Linguistics</em> 16 (2): 173–97.
</div>
<div id="ref-R-rsyntax" class="csl-entry" role="listitem">
Welbers, Kasper, and Wouter van Atteveldt. 2022. <em>Rsyntax: Extract Semantic Relations from Text by Querying and Reshaping Syntax</em>.
</div>
<div id="ref-R-stringr" class="csl-entry" role="listitem">
Wickham, Hadley. 2022. <em>Stringr: Simple, Consistent Wrappers for Common String Operations</em>. <a href="https://CRAN.R-project.org/package=stringr">https://CRAN.R-project.org/package=stringr</a>.
</div>
<div id="ref-R-udpipe" class="csl-entry" role="listitem">
Wijffels, Jan. 2023. <em>Udpipe: Tokenization, Parts of Speech Tagging, Lemmatization and Dependency Parsing with the UDPipe ’NLP’ Toolkit</em>. <a href="https://CRAN.R-project.org/package=udpipe">https://CRAN.R-project.org/package=udpipe</a>.
</div>
</div>
</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./curate-datasets.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Curate datasets</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./analysis.html" class="pagination-link">
        <span class="nav-page-text">Analysis</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>
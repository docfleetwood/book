<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>An Introduction to Quantitative Text Analysis for Linguistics - 9&nbsp; Prediction</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./inference.html" rel="next">
<link href="./exploration.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script async="" src="https://hypothes.is/embed.js"></script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><link rel="stylesheet" href="assets/css/mini.css">
</head>
<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./analysis.html">Analysis</a></li><li class="breadcrumb-item"><a href="./prediction.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Prediction</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">An Introduction to Quantitative Text Analysis for Linguistics</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/qtalr/book" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./qtalr-manuscript.pdf" rel="" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./orientation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Orientation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./text-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Text analysis in context</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./understanding-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Understanding data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./approaching-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Approaching analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./framing-research.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Framing research</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./preparation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preparation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./acquire-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Acquire data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./curate-datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Curate datasets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./transform-datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Transform datasets</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Analysis</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./exploration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Exploration</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./prediction.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Inference</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./communication.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Communication</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reporting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Reports</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./collaboration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Collaboration</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./feedback.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Feedback <i class="fa-solid fa-comment" aria-label="comment"></i></span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#sec-pda-orientation" id="toc-sec-pda-orientation" class="nav-link active" data-scroll-target="#sec-pda-orientation"><span class="header-section-number">9.1</span> Orientation</a>
  <ul class="collapse">
<li><a href="#sec-pda-research-goal" id="toc-sec-pda-research-goal" class="nav-link" data-scroll-target="#sec-pda-research-goal"><span class="header-section-number">9.1.1</span> Research goal</a></li>
  <li><a href="#sec-pda-approach" id="toc-sec-pda-approach" class="nav-link" data-scroll-target="#sec-pda-approach"><span class="header-section-number">9.1.2</span> Approach</a></li>
  </ul>
</li>
  <li>
<a href="#sec-pda-analysis" id="toc-sec-pda-analysis" class="nav-link" data-scroll-target="#sec-pda-analysis"><span class="header-section-number">9.2</span> Analysis</a>
  <ul class="collapse">
<li><a href="#sec-pda-text-classification" id="toc-sec-pda-text-classification" class="nav-link" data-scroll-target="#sec-pda-text-classification"><span class="header-section-number">9.2.1</span> Text classification</a></li>
  <li><a href="#sec-pda-text-regression" id="toc-sec-pda-text-regression" class="nav-link" data-scroll-target="#sec-pda-text-regression"><span class="header-section-number">9.2.2</span> Text regression</a></li>
  </ul>
</li>
  <li><a href="#sec-pda-summary" id="toc-sec-pda-summary" class="nav-link" data-scroll-target="#sec-pda-summary"><span class="header-section-number">9.3</span> Summary</a></li>
  <li>
<a href="#pda-analysis" id="toc-pda-analysis" class="nav-link" data-scroll-target="#pda-analysis"><span class="header-section-number">9.4</span> Analysis</a>
  <ul class="collapse">
<li><a href="#pda-classification" id="toc-pda-classification" class="nav-link" data-scroll-target="#pda-classification"><span class="header-section-number">9.4.1</span> Classification</a></li>
  <li><a href="#pda-regression" id="toc-pda-regression" class="nav-link" data-scroll-target="#pda-regression"><span class="header-section-number">9.4.2</span> Regression</a></li>
  </ul>
</li>
  <li><a href="#pda-reporting" id="toc-pda-reporting" class="nav-link" data-scroll-target="#pda-reporting"><span class="header-section-number">9.5</span> Reporting</a></li>
  <li><a href="#pda-summary" id="toc-pda-summary" class="nav-link" data-scroll-target="#pda-summary"><span class="header-section-number">9.6</span> Summary</a></li>
  <li><a href="#activities" id="toc-activities" class="nav-link" data-scroll-target="#activities">Activities</a></li>
  <li><a href="#questions" id="toc-questions" class="nav-link" data-scroll-target="#questions">Questions</a></li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/qtalr/book/edit/main/prediction.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/qtalr/book/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title"><span id="sec-prediction" class="quarto-section-identifier"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Prediction</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><div class="callout callout-style-default callout-caution callout-titled" title="Caution">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>Under development.</p>
</div>
</div>
<!-- 

Content:

- [ ] Note on hypothesis testing?
  - Confidence intervals?
  - MuPDAR approach (Multifactorial Prediction and Deviation Analysis with Regressions) [@Deshors2016; @Gries2014] and @Baayen2011
    - Training on group
    - Testing on another group (or groups)

Exercises:

- [ ] add concept questions to Activities
- [ ] add exercises to Activities
- [ ] add thought questions/ case studies to prose sections

Formatting:

- [ ] Global: object naming conventions
- [ ] Object types:
    - _tbl or _df for tibbles and data frames?
    - _vec for vectors? or _num, _chr?
    - _mod for models? or _fit?
    - _lst for lists?
    - + other conventions? _tdm, 
  - [ ] Object content: 
    - _spk_ for spoken data?
    - _wrt_ for written data?
    - _tok_ for tokenized data?
    - _lem_ for lemmatized data?
    - _pos_ for part-of-speech tagged data?
    - + other conventions? _trn_ for training data? _tst_ for test data?

-->
<blockquote class="blockquote">
<p>All models are wrong, but some are useful.</p>
<p>— George E.P. Box</p>
</blockquote>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-list-alt" aria-label="list-alt"></i> Outcomes</strong></p>
<!-- Remember and understand verbs: https://tips.uark.edu/blooms-taxonomy-verb-chart/ -->
<ul>
<li>…</li>
</ul>
</div>
</div>
</div>
<p>In this chapter, I introduce supervised learning as an approach to data analysis, specifically focusing on its applications in text analysis. Supervised learning aims to establish a relationship between a target (or outcome) variable and a set of feature variables derived from text data. By leveraging this relationship, statistical generalizations (models) can be created to accurately predict values of the target variable based on the values of the feature variables. Throughout the chapter, we explore practical tasks and theoretical applications of statistical learning in text analysis. We also cover the standard workflow for building predictive models, testing and evaluating model performance, improving model accuracy, and interpreting and reporting findings.</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-solid fa-terminal" aria-label="terminal"></i> Lessons</strong></p>
<!-- Remember and understand verbs: https://tips.uark.edu/blooms-taxonomy-verb-chart/ -->
<!-- 
- [ ] Update lesson name, 
- [ ] update lesson purpose
-->
<p><strong>What</strong>: <a href="https://github.com/qtalr/lessons">Supervised Learning</a><br><strong>How</strong>: In the R Console pane load <code>swirl</code>, run <code>swirl()</code>, and follow prompts to select the lesson.<br><strong>Why</strong>: … <i class="fa-solid fa-wrench" aria-label="wrench"></i></p>
</div>
</div>
</div>
<section id="sec-pda-orientation" class="level2" data-number="9.1"><h2 data-number="9.1" class="anchored" data-anchor-id="sec-pda-orientation">
<span class="header-section-number">9.1</span> Orientation</h2>
<p>In this section, I introduce the concept of supervised learning and provide a brief overview of the workflow for building predictive models for text analysis. First we will discuss the research goals that are typically addressed using supervised learning, contrasting them with the goals of exploratory and inferential analysis. Next, we will discuss the approaches that are typically used to address these goals, including the types of data structures and algorithms that are used. Finally, we will discuss the workflow for building predictive models, including the steps for preparing data, training and testing models, and evaluating and reporting results.</p>
<section id="sec-pda-research-goal" class="level3" data-number="9.1.1"><h3 data-number="9.1.1" class="anchored" data-anchor-id="sec-pda-research-goal">
<span class="header-section-number">9.1.1</span> Research goal</h3>
<p>Predictive data analysis (PDA) is a powerful analysis method for linguists and other researchers interested in making predictions about new or future data based on patterns in existing data. As discussed in <a href="approaching-analysis.html#sec-aa-predict"><span>Section&nbsp;3.2.2</span></a> and <a href="framing-research.html#sec-fr-plan"><span>Section&nbsp;4.4.1</span></a>, PDA is a type of supervised learning, which means that it involves training a model on a labeled dataset where the input data and desired output are both provided. The model is able to make predictions or classifications based on the input data by learning the relationships between the input and output data. Supervised machine learning is an important tool for linguists studying language and communication, as it allows us to analyze language data to identify patterns or trends in language use, verify hypotheses, and prescribe actions.</p>
<p>In contrast to EDA, PDA does require that we have a particular goal in mind from the outset. This goal is typically to predict a particular outcome variable based on a set of predictor variables. The status of predictor variables, however, depends on the research goal. In some cases, the predictor variables are mutable, meaning that they can be changed to see how they affect the outcome. This points to the inductive, exploratory application of PDA which can aid in generating new insight and questions. In other cases, the predictor variables may be pre-defined. In this light, PDA serves a deductive purpose, as we are testing a hypothesis about the relationship between the predictor variables and the outcome variable.</p>
</section><section id="sec-pda-approach" class="level3" data-number="9.1.2"><h3 data-number="9.1.2" class="anchored" data-anchor-id="sec-pda-approach">
<span class="header-section-number">9.1.2</span> Approach</h3>
<!--  Identify, Inspect, Interrogate, Interpret -->
<!-- Outcome variable 
- Categorical
- Numeric
-->
<p>… There are two main types of supervised machine learning algorithms: classification, which is used to predict a categorical outcome such as the genre of a text, and regression, which is used to predict a continuous outcome such as the sentiment of a text, syntactic complexity score, test score, etc.</p>
<ul>
<li>Supervised learning
<ul>
<li>Classification
<ul>
<li>Categorical outcome variable</li>
</ul>
</li>
<li>Regression
<ul>
<li>Continuous outcome variable</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>…</p>
<!-- Predictor variables/ features
Purpose(s):  
- Exploratory-oriented prediction
- Hypothesis-driven prediction
-->
<p>It is important to be clear from the outset what the purpose of the analysis is, as this will determine the approach that is taken. For exploratory-oriented prediction, the approach to feature selection, engineering, and extraction will be more open-ended, much like unsupervised learning, with the caveat that an outcome variable is defined. In this approach, the researcher is also free to re-define the features to see how they affect the prediction model.</p>
<p>For hypothesis-driven prediction, the approach to feature selection, engineering, and extraction will be more focused, much like inferential analysis. The relationship between outcome and predictor variables is the focus of the analysis, and the researcher is not free to re-define the features.</p>
<!-- Validation -->
<p>In either approach, predictive data analysis incorporates a validation step to ensure that the model is robust. To validate the model, the data is split into training and testing sets. The training set is used to train the model, and the testing set is used to evaluate the model’s performance. The testing set is reserved and not used to train the model, so that the model’s performance can be evaluated on data that it has not seen before. In some cases, the data is split into three sets: training, validation, and testing. The validation set is used to evaluate the model’s performance during the training phase, and the testing set is used to evaluate the model’s performance after the training phase.</p>
<!-- Interrogate -->
<p>Model training is the next step towards building a predictive model. In this step, an algorithm is used to train the model on the training data. The choice of algorithm first and foremost depends on the nature of the outcome variable. If categorical, classification algorithms such as logistic regression, decision trees, or Naive Bayes are used. If continuous, regression algorithms such as linear regression, decision trees, or neural networks are natural choices. The nature of the predictor variables also plays a role in the choice of algorithm.</p>
<p>. For regression, the most common algorithms are linear regression, decision trees, and neural networks. The choice of algorithm also depends on the nature of the predictor variables. For example, if the predictor variables are categorical, then a decision tree algorithm may be a good choice. If the predictor variables are continuous, then a linear regression algorithm may be a good choice. If the predictor variables are text, then a Naive Bayes algorithm may be a good choice.</p>
<!-- Interpret -->
<!-- 
- Quantitative measures: 
  - Classification: accuracy, precision, recall, F1
  - Regression: R2, RMSE 
-->
<p>For all applications of PDA the interpretation of the prediction model includes some metric or metrics of accuracy comparing the extent to which the models predictions and the actual targets align. The standard form for evaluating a model’s performance differs between classification models (naive bayes) and regression models (linear regression).</p>
<p>For classification models, a cross-tabulation of the predicted and actual classes results in a <strong>contingency table</strong> which can be used to calculate <strong>accuracy</strong> which is the sum of all the correctly predicted observations divided by the total number of observations in the test set. In addition to accuracy, there are various other measures which aim to assess a model’s performance to gain more insight into the potential over- or under-generalization of the model (<em>Precision</em> and <em>Recall</em>).</p>
<p>For regression models, differences between predicted and actual values can be assessed using a <strong>coefficient of correlation</strong> (typically <span class="math inline">\(R^2\)</span>). Again, more fine-grained detail about the model’s performance can be calculated (<em>Root Mean Square Error</em>).</p>
<!--  
- Model evaluation
  - Cross-validation
  - Holdout
  - Bootstrap
-->
<p>Another component worthy of consideration when evaluating a model’s performance is how do we determine if the performance is actually good. One the one hand, accuracy rates into the 90+% range on the test set is usually a good sign that the model is performing well. No model will perform with perfect accuracy, however, and depending on the goal of the research particular error patterns may be more important, and problematic, than the overall prediction accuracy.</p>
<p>On the other hand, another eventuality is that the model performs very well on the training set but that on the test set (new data) the performance drops significantly. This is a sign that during the training phrase the machine learning algorithm learned nuances in the data (‘noise’) that obscure the signal pattern to be learned. This problem is called <strong>overfitting</strong> and to avoid it researchers iteratively run evaluations of the training data using resampling.</p>
<p>The two most common resampling methods are <strong>bootstrapping</strong> (resampling with replacement) and <strong>cross-validation</strong> (resampling without replacement). The performance of these multiple models are summarized and the error between them is assessed. The goal is to minimize the performance differences between the models while maximizing the overall performance. These measures go a long way to avoiding overfitting and therefore maximizing the chance that the training phase will produce a model which is robust.</p>
<!--  
In cases in which the inner workings of the model are of interest, a researcher can dive into features and their contributions to the prediction model in an exploratory fashion according to the research goals. The exploration of features, then, varies, so at this time let's focus on the metrics of prediction accuracy.
-->
<!-- Workflow -->
<ol type="1">
<li>Identify …</li>
<li>Inspect …</li>
<li>Interrogate …</li>
<li>Interpret …</li>
<li>(Optional) Iterate …</li>
</ol>
<p>Prerequisites: - A working research question or hypothesis - A dataset which aligns with the research question or hypothesis in terms of its sampling frame and the variables it contains or can be derived from the text and a target variable to be predicted. - A set of preliminary features to be derived from the text that are used to predict the target variable</p>
</section></section><section id="sec-pda-analysis" class="level2" data-number="9.2"><h2 data-number="9.2" class="anchored" data-anchor-id="sec-pda-analysis">
<span class="header-section-number">9.2</span> Analysis</h2>
<!-- Goals of this section -->
<!-- Research questions -->
<!-- Procedure -->
<ul class="task-list">
<li>
<input type="checkbox">Add a visual representation of the workflow? Or too much?</li>
</ul>
<p>The steps of this analysis are as follows:</p>
<div id="tbl-pda-analysis-steps" class="anchored">
<table class="table-striped table">
<caption>Table&nbsp;9.1: Steps of a supervised machine learning analysis</caption>
<colgroup>
<col style="width: 18%">
<col style="width: 40%">
<col style="width: 40%">
</colgroup>
<thead><tr class="header">
<th>Step</th>
<th>Name</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Create corpus</td>
<td>Create a corpus of texts with an outcome variable and a feature variable representing the text</td>
</tr>
<tr class="even">
<td>2</td>
<td>Split data</td>
<td>Split the data into training and testing sets</td>
</tr>
<tr class="odd">
<td>3</td>
<td>Create recipe</td>
<td>Define a recipe to specify how to preprocess and engineer the feature variable, as well as the outcome variable</td>
</tr>
<tr class="even">
<td>4</td>
<td>Create model specification</td>
<td>Specify the model and engine to use in a model specification</td>
</tr>
<tr class="odd">
<td>5</td>
<td>Create workflow</td>
<td>Create a workflow that combines the recipe and model specification into a pipeline</td>
</tr>
<tr class="even">
<td>6</td>
<td>Fit workflow</td>
<td>Fit the workflow to the training data and evaluate its performance</td>
</tr>
<tr class="odd">
<td>7</td>
<td>Improve model</td>
<td>Explore ways to improve the model by assessing its performance and making changes to features, models, or hyperparameters</td>
</tr>
<tr class="even">
<td>8</td>
<td>Evaluate final model</td>
<td>Evaluate the final model’s performance on the testing data and analyze predictions, errors, and feature importance</td>
</tr>
</tbody>
</table>
</div>
<p>We will be using the <code>tidymodels</code> framework to perform this analysis. <code>tidymodels</code> is a metapackage, much like <code>tidyverse</code>, that provides a consistent interface for modeling and machine learning. The main packages unique to <code>tidymodels</code> are <code>parsnip</code>, <code>dials</code>, and <code>workflows</code>. <code>parsnip</code> provides a consistent interface for specifying models. <code>dials</code> provides a consistent interface for tuning hyperparameters. <code>workflows</code> provides a consistent interface for modeling pipelines. Since we are using text data, we will also be using the <code>textrecipes</code> package which provides a consistent interface for preprocessing text data.</p>
<p>After we have a baseline model, we will compare it to the null model to see if our model is better than the null model. Depending on the results, we will either move on to a more complex model or we will stop here. A more complex model may include changing the features, using a different model, or tuning the hyperparameters of the model. We will then evaluate the final model on the testing data to see how well it generalizes to new data. We will also analyze the predictions, errors, and feature importance of the final model.</p>
<section id="sec-pda-text-classification" class="level3" data-number="9.2.1"><h3 data-number="9.2.1" class="anchored" data-anchor-id="sec-pda-text-classification">
<span class="header-section-number">9.2.1</span> Text classification</h3>
<!-- Research question: outcome and features -->
<!-- [ ] include a rationale? citations? -->
<p>The goal of this analysis is to classify texts as either native or learner. This is a binary classification problem. As a first pass we will use a bag-of-words approach to classify texts where words are the features and the classes are native and learner.</p>
<!-- Models: simple to complex  -->
<p>Simple, computationally efficient, and interpretable models are preferred over complex, computationally expensive, and uninterpretable models, all things being equal. Only if the performance of the simple model is not good enough should we move on to a more complex model. With this end mind, we will start with a simple logistic regression model to see how well we can classify texts.</p>
<p>Let’s start by loading the packages we will need for this analysis and load the datasets we will be using.</p>
<div class="cell" data-hash="prediction_cache/html/pda-setup_b902080ce10aace6aeda0481c7645b19">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load packages</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidymodels.tidymodels.org">tidymodels</a></span><span class="op">)</span>   <span class="co"># modeling metapackage</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/tidymodels/textrecipes">textrecipes</a></span><span class="op">)</span>  <span class="co"># text preprocessing</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/sfirke/janitor">janitor</a></span><span class="op">)</span>      <span class="co"># data inspection</span></span>
<span></span>
<span><span class="co"># Set global options</span></span>
<span><span class="fu"><a href="https://tidymodels.tidymodels.org/reference/tidymodels_prefer.html">tidymodels_prefer</a></span><span class="op">(</span><span class="op">)</span>   <span class="co"># prefer tidymodels functions over other functions with the same name</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We will follow the steps in <a href="#tbl-pda-analysis-steps">Table&nbsp;<span>9.1</span></a> to peform this analysis. First up is preparing the corpus data. In <a href="#exm-pda-class-corpus">Example&nbsp;<span>9.1</span></a>, we will read in the two datasets, combine them into a single dataset, and create a corpus of texts with an outcome variable and a feature variable representing the text. Note that the <code>outcome</code> variable will be converted to a factor variable in preparation for modeling.</p>
<div id="exm-pda-class-corpus" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.1 </strong></span>&nbsp;</p>
<div class="cell" data-hash="prediction_cache/html/pda-class-corpus-show_fe035f8701184744b8f3a58ca51b1534">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Read in the datasets</span></span>
<span><span class="va">cedel2_learners_df</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu">read_csv</span><span class="op">(</span><span class="st">"../data/cedel2/cedel2_learners.csv"</span><span class="op">)</span> <span class="op">|&gt;</span>   <span class="co"># read in the learners dataset</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>outcome <span class="op">=</span> <span class="st">"learner"</span><span class="op">)</span> <span class="op">|&gt;</span>                      <span class="co"># create an outcome variable</span></span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">outcome</span>, <span class="va">text</span><span class="op">)</span>                               <span class="co"># select the text column</span></span>
<span></span>
<span><span class="va">cedel2_natives_df</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">read_csv</span><span class="op">(</span><span class="st">"../data/cedel2/cedel2_natives.csv"</span><span class="op">)</span> <span class="op">|&gt;</span>    <span class="co"># read in the natives dataset</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>outcome <span class="op">=</span> <span class="st">"native"</span><span class="op">)</span> <span class="op">|&gt;</span>                       <span class="co"># create an outcome variable</span></span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">outcome</span>, <span class="va">text</span><span class="op">)</span>                               <span class="co"># select the text column</span></span>
<span></span>
<span><span class="co"># Combine the datasets by row</span></span>
<span><span class="va">cedel2_cls_df</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu">bind_rows</span><span class="op">(</span>                                          <span class="co"># combine the datasets by row</span></span>
<span>    <span class="va">cedel2_learners_df</span>, </span>
<span>    <span class="va">cedel2_natives_df</span></span>
<span>  <span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>outcome <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">outcome</span><span class="op">)</span><span class="op">)</span>                   <span class="co"># convert to a factor variable</span></span>
<span></span>
<span><span class="co"># Preview </span></span>
<span><span class="va">cedel2_cls_df</span>  <span class="op">|&gt;</span> <span class="fu">glimpse</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-hash="prediction_cache/html/pda-class-corpus-run_9db5e20e213b636a2685795c3b97dbd7">
<div class="cell-output cell-output-stdout">
<pre><code>&gt; Rows: 2,957
&gt; Columns: 2
&gt; $ outcome &lt;fct&gt; learner, learner, learner, learner, learner, learner, learner,…
&gt; $ text    &lt;chr&gt; "Yo vivo es Alanta, Georgia. Atlanta es muy grande ciudad. Mi …</code></pre>
</div>
</div>
</div>
<p>The results of <a href="#exm-pda-class-corpus">Example&nbsp;<span>9.1</span></a> show that we have two variables, one for the outcome and the other for the text –from which we will derive our features for the classification model. This data frame has 2957 observations. To view the distribution of the outcome variable between the two levels we can use the <code><a href="https://sfirke.github.io/janitor/reference/tabyl.html">tabyl()</a></code> function from the <code>janitor</code> package, as seen in <a href="#exm-pda-class-corpus-tabyl">Example&nbsp;<span>9.2</span></a>.</p>
<div id="exm-pda-class-corpus-tabyl" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.2 </strong></span>&nbsp;</p>
<div class="cell" data-hash="prediction_cache/html/pda-class-corpus-tabyl_0b1bc425a9d8a0a66dab63e553f333b0">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># View the distribution of the outcome variable</span></span>
<span><span class="va">cedel2_cls_df</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://sfirke.github.io/janitor/reference/tabyl.html">tabyl</a></span><span class="op">(</span><span class="va">outcome</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://sfirke.github.io/janitor/reference/adorn_pct_formatting.html">adorn_pct_formatting</a></span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt;  outcome    n percent
&gt;  learner 1906   64.5%
&gt;   native 1051   35.5%</code></pre>
</div>
</div>
</div>
<p>So a little more than two-thirds of the texts are from learners. It is important to gauge the distribution of the outcome variable to see if it is balanced or imbalanced. The classes need not be perfectly balanced, but if they are wildly imbalanced it can cause problems for the model.</p>
<p>Moving on two step 2, we will split the data into training and testing sets. A typical approach in supervised machine learning is to allocate around 75-80% of the data to the training set and the remaining 20-25% to the testing set, depending on the number of observations. We have 2957 observations in our data set, so we can allocate 80% of the data to the training set and 20% of the data to the testing set.</p>
<p>We will use the <code>initial_split()</code> function from the <code>rsample</code> package to split the data into training and testing sets. The <code>initial_split()</code> function takes a data frame and a proportion and returns a <code>split</code> object which contains the training and testing sets. We will use the <code>strata</code> argument to stratify the data by the <code>outcome</code> variable. This will ensure that the training and testing sets have the same proportion of native and learner texts. The code is seen in <a href="#exm-pda-class-split">Example&nbsp;<span>9.3</span></a>.</p>
<div id="exm-pda-class-split" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.3 </strong></span>&nbsp;</p>
<div class="cell" data-hash="prediction_cache/html/pda-class-split_14af0b8415e20d804496366ac1e6049b">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Split the data into training and testing sets</span></span>
<span><span class="va">cedel2_cls_split</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">initial_split</span><span class="op">(</span></span>
<span>    data <span class="op">=</span> <span class="va">cedel2_cls_df</span>, </span>
<span>    prop <span class="op">=</span> <span class="fl">0.8</span>, </span>
<span>    strata <span class="op">=</span> <span class="va">outcome</span></span>
<span>    <span class="op">)</span></span>
<span></span>
<span><span class="co"># Create training set</span></span>
<span><span class="va">cedel2_cls_train</span> <span class="op">&lt;-</span> <span class="fu">training</span><span class="op">(</span><span class="va">cedel2_cls_split</span><span class="op">)</span>  <span class="co"># 80% of data</span></span>
<span></span>
<span><span class="co"># Create testing set</span></span>
<span><span class="va">cedel2_cls_test</span> <span class="op">&lt;-</span> <span class="fu">testing</span><span class="op">(</span><span class="va">cedel2_cls_split</span><span class="op">)</span>    <span class="co"># 20% of data</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>A confirmation of the distribution of the data across the training and testing sets as well as a break down of the outcome variable can be seen in <a href="#exm-pda-class-split-tabyl">Example&nbsp;<span>9.4</span></a>.</p>
<div id="exm-pda-class-split-tabyl" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.4 </strong></span>&nbsp;</p>
<div class="cell" data-hash="prediction_cache/html/pda-class-split-tabyl_26d29bb9bed09c11ec0d575b01bb67cf">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># View the distribution of the outcome variables</span></span>
<span><span class="va">cedel2_cls_train</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://sfirke.github.io/janitor/reference/tabyl.html">tabyl</a></span><span class="op">(</span><span class="va">outcome</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://sfirke.github.io/janitor/reference/adorn_totals.html">adorn_totals</a></span><span class="op">(</span><span class="st">"row"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://sfirke.github.io/janitor/reference/adorn_pct_formatting.html">adorn_pct_formatting</a></span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt;  outcome    n percent
&gt;  learner 1524   64.5%
&gt;   native  840   35.5%
&gt;    Total 2364  100.0%</code></pre>
</div>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cedel2_cls_test</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://sfirke.github.io/janitor/reference/tabyl.html">tabyl</a></span><span class="op">(</span><span class="va">outcome</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://sfirke.github.io/janitor/reference/adorn_totals.html">adorn_totals</a></span><span class="op">(</span><span class="st">"row"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://sfirke.github.io/janitor/reference/adorn_pct_formatting.html">adorn_pct_formatting</a></span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt;  outcome   n percent
&gt;  learner 382   64.4%
&gt;   native 211   35.6%
&gt;    Total 593  100.0%</code></pre>
</div>
</div>
</div>
<p>We can see that the split was successful. The training and testing sets have very similiar proportion of native and learner texts.</p>
<p>We are now ready to create a ‘recipe’, step 3 in our analysis. A recipe is a set of instructions or blueprint which specify the outcome variable and the feature variable and determines how to preprocess and engineer the feature variables.</p>
<p>We will use the <code><a href="https://recipes.tidymodels.org/reference/recipe.html">recipe()</a></code> function from the <code>recipes</code> package to create the recipe. The <code><a href="https://recipes.tidymodels.org/reference/recipe.html">recipe()</a></code> function minimally takes a formula and a data frame and returns a <code>recipe</code> object. The formula specifies the outcome variable (<span class="math inline">\(y\)</span>) and the feature variable(s) (<span class="math inline">\(x_1 .. x_n\)</span>). For example <code>y ~ x</code> can be read as “y is a function of x”. In our particular case, we will use the formula <code>outcome ~ text</code> to specify that the outcome variable is the <code>outcome</code> variable and the feature variable is the <code>text</code> variable. The code is seen in <a href="#exm-pda-class-recipe">Example&nbsp;<span>9.5</span></a>.</p>
<div id="exm-pda-class-recipe" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.5 </strong></span>&nbsp;</p>
<div class="cell" data-hash="prediction_cache/html/pda-class-recipe_9dd66d419f2fb7078c73bfd9c524e20d">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create a recipe</span></span>
<span><span class="va">cedel2_cls_rec</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu"><a href="https://recipes.tidymodels.org/reference/recipe.html">recipe</a></span><span class="op">(</span></span>
<span>    <span class="va">outcome</span> <span class="op">~</span> <span class="va">text</span>, </span>
<span>    data <span class="op">=</span> <span class="va">cedel2_cls_train</span></span>
<span>    <span class="op">)</span></span>
<span></span>
<span><span class="co"># Preview</span></span>
<span><span class="va">cedel2_cls_rec</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>The recipe object at this moment contains just one instruction, what the variables are and what their relationship is.</p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong><i class="fa-regular fa-hand-point-up" aria-label="hand-point-up"></i> Tip</strong></p>
<p>R formulas are a powerful way to specify relationships between variables and are used extensively in data modeling including exploratory, predictive, and inferential analysis. The basic formula syntax is <code>y ~ x</code> where <code>y</code> is the outcome variable and <code>x</code> is the feature variable. The formula syntax can be extended to include multiple feature variables, interactions, and transformations. For more information on R formulas, <a href="https://r4ds.github.io/bookclub-tmwr/r-formula-syntax.html">R for Data Science</a>.</p>
</div>
</div>
</div>
<p>The <code>recipes</code> package provides a wide range of <code>step_*()</code> functions which can be applied to the recipe to specify how to engineer the variables in our recipe call. These include functions to scale (<em>e.g</em> <code><a href="https://recipes.tidymodels.org/reference/step_center.html">step_center()</a></code>, <code><a href="https://recipes.tidymodels.org/reference/step_scale.html">step_scale()</a></code>, <em>etc.</em>) and transform (<em>e.g.</em> <code><a href="https://recipes.tidymodels.org/reference/step_log.html">step_log()</a></code>, <code><a href="https://recipes.tidymodels.org/reference/step_pca.html">step_pca()</a></code>, <em>etc.</em>) numeric variables, and functions to encode (<em>e.g.</em> <code><a href="https://recipes.tidymodels.org/reference/step_dummy.html">step_dummy()</a></code>, <code>step_labelencode()</code>, <em>etc.</em>) categorical variables.</p>
<p>These step functions are great when we have selected the variables we want to use in our model and we want to engineer them in a particular way. In our case, however, we need to derive features from the text in the <code>text</code> column of datasets before we engineer them. To ease this process, the <code>textrecipes</code> package provides a number of step functions for preprocessing text data. These include functions to tokenize (<em>e.g.</em> <code><a href="https://textrecipes.tidymodels.org/reference/step_tokenize.html">step_tokenize()</a></code>), remove stop words (<em>e.g.</em> <code><a href="https://textrecipes.tidymodels.org/reference/step_stopwords.html">step_stopwords()</a></code>), and to derive meta-features (<em>e.g.</em> <code><a href="https://textrecipes.tidymodels.org/reference/step_lemma.html">step_lemma()</a></code>, <code><a href="https://textrecipes.tidymodels.org/reference/step_stem.html">step_stem()</a></code>, <em>etc.</em>) <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Furthermore, there are functions to engineer features in ways that are particularly relevant to text data, such as feature weights (<em>e.g.</em> <code><a href="https://textrecipes.tidymodels.org/reference/step_tf.html">step_tf()</a></code>, <code><a href="https://textrecipes.tidymodels.org/reference/step_tfidf.html">step_tfidf()</a></code>, <em>etc.</em>) and token filtering (<em>e.g.</em> <code><a href="https://textrecipes.tidymodels.org/reference/step_tokenfilter.html">step_tokenfilter()</a></code>).</p>
<!-- Toy example: use prep(), bake() -->
</section><section id="sec-pda-text-regression" class="level3" data-number="9.2.2"><h3 data-number="9.2.2" class="anchored" data-anchor-id="sec-pda-text-regression">
<span class="header-section-number">9.2.2</span> Text regression</h3>
</section></section><section id="sec-pda-summary" class="level2" data-number="9.3"><h2 data-number="9.3" class="anchored" data-anchor-id="sec-pda-summary">
<span class="header-section-number">9.3</span> Summary</h2>
<ul>
<li>Supervised machine learning is an active area of research in linguistics with numerous applications and opportunities for further exploration.</li>
</ul>
<section id="pda-interpret" class="level4"><h4 class="anchored" data-anchor-id="pda-interpret">Interpret</h4>
<p>To either evaluate the training or testing set, the model is used to make predictions on the data in the set. The predictions are then compared to the actual values of the target variable in the set to evaluate the model’s performance. So how is the model’s performance evaluated?</p>
<section id="pda-workflow-classification" class="level5"><h5 class="anchored" data-anchor-id="pda-workflow-classification">Classification</h5>
<p>For classification, there are a number of metrics that can be used to evaluate the performance of a model, including accuracy, precision, recall, and F1 score. To understand these measures it is helpful to consider a confusion matrix, which is a table that describes the performance of a classification model on data for which the true values are known. The confusion matrix is a two-by-two matrix that shows the number of true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN), as seen in <a href="#tbl-pda-confusion-matrix">Table&nbsp;<span>9.2</span></a>.</p>
<div class="cell" data-hash="prediction_cache/html/tbl-pda-confusion-matrix_7fb9a9370f747df8bd80ba215f73cd64">
<div class="cell-output-display">
<div id="tbl-pda-confusion-matrix" class="anchored">
<table data-quarto-postprocess="true" class="table table-sm table-striped small">
<caption>Table&nbsp;9.2: A labeled confusion matrix</caption>
<thead><tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Predicted positive</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Predicted negative</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Actual positive</td>
<td style="text-align: left;">TP</td>
<td style="text-align: left;">FP</td>
</tr>
<tr class="even">
<td style="text-align: left;">Actual negative</td>
<td style="text-align: left;">FN</td>
<td style="text-align: left;">TN</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
<p>Now let’s fill this confusion matrix with hypothetical values, as seen in <a href="#tbl-pda-confusion-matrix-example">Table&nbsp;<span>9.3</span></a> to see how the metrics are calculated.</p>
<div class="cell" data-hash="prediction_cache/html/tbl-pda-confusion-matrix-example_38fe21d49417aa036c32ef84b6394fc8">
<div class="cell-output-display">
<div id="tbl-pda-confusion-matrix-example" class="anchored">
<table data-quarto-postprocess="true" class="table table-sm table-striped small">
<caption>Table&nbsp;9.3: Confusion matrix for a hypothetical model’s performance on a test set</caption>
<thead><tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Predicted positive</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Predicted negative</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Actual positive</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">10</td>
</tr>
<tr class="even">
<td style="text-align: left;">Actual negative</td>
<td style="text-align: right;">20</td>
<td style="text-align: right;">50</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
<ul>
<li>Accuracy is defined as the proportion of correct predictions made by the model.</li>
</ul>
<p><span id="eq-pda-accuracy"><span class="math display">\[
\text{Accuracy} = \frac{\text{Number of correct predictions}}{\text{Total number of predictions}}
\tag{9.1}\]</span></span></p>
<p>The number of correct predictions is the sum of true positives and true negatives. So in our case this is 100 + 50 = 150. The total number of predictions is the sum of all four cells in the confusion matrix, so in our case this is 100 + 10 + 20 + 50 = 180. So the accuracy of our hypothetical model is 150/180 = 0.833.</p>
<ul>
<li>Precision is defined as the proportion of positive predictions that are correct.</li>
</ul>
<p><span id="eq-pda-precision"><span class="math display">\[
\text{Precision} = \frac{\text{Number of true positives}}{\text{Number of true positives + false positives}}
\tag{9.2}\]</span></span></p>
<ul>
<li>Recall is defined as the proportion of actual positives that are correctly identified.</li>
</ul>
<p><span id="eq-pda-recall"><span class="math display">\[
\text{Recall} = \frac{\text{Number of true positives}}{\text{Number of true positives + false negatives}}
\tag{9.3}\]</span></span></p>
<ul>
<li>The F1 score is the harmonic mean of precision and recall.</li>
</ul>
<p><span id="eq-pda-f1"><span class="math display">\[
\text{F1 score} = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
\tag{9.4}\]</span></span></p>
<p>Area under the curve (AUC) is the area under the ROC (Receiver Operating Characteristic) curve, which is a graph of true positives (TPR) and false positives (FPR). The AUC is a measure of the model’s performance across all possible classification thresholds. The AUC is a number between 0 and 1, where 0.5 represents a model that is no better than random guessing, and 1 represents a perfect model.</p>
<p><strong>Feature importance</strong></p>
<ul>
<li>parallel coordinate visualization</li>
</ul>
<p>In a supervised text classification task, you can use parallel coordinate plots to visualize the distribution of class labels across different feature dimensions. This can help identify which features are most informative for distinguishing between classes and inform feature selection or dimensionality reduction techniques.</p>
<div class="cell" data-hash="prediction_cache/html/fig-pda-parallel-coordinates_e1ae3a92ed1c877612114d0a494f143d">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/juliasilge/tidytext">tidytext</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Faux data</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  text <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"I love cats"</span>, <span class="st">"Cats are amazing"</span>, <span class="st">"I hate dogs"</span>, <span class="st">"Dogs are annoying"</span><span class="op">)</span>,</span>
<span>  class <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"positive"</span>, <span class="st">"positive"</span>, <span class="st">"negative"</span>, <span class="st">"negative"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Tokenize data</span></span>
<span><span class="va">tokenized_data</span> <span class="op">&lt;-</span> <span class="va">data</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tidytext/man/unnest_tokens.html">unnest_tokens</a></span><span class="op">(</span><span class="va">word</span>, <span class="va">text</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/count.html">count</a></span><span class="op">(</span><span class="va">class</span>, <span class="va">word</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">ungroup</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/spread.html">spread</a></span><span class="op">(</span><span class="va">class</span>, <span class="va">n</span>, fill <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Normalize the term frequencies</span></span>
<span><span class="va">normalized_data</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">tokenized_data</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span></span>
<span>    positive <span class="op">=</span> <span class="va">positive</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">positive</span><span class="op">)</span>,</span>
<span>    negative <span class="op">=</span> <span class="va">negative</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">negative</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/gather.html">gather</a></span><span class="op">(</span><span class="va">class</span>, <span class="va">frequency</span>, <span class="op">-</span><span class="va">word</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Generate the parallel coordinate plot</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">normalized_data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">class</span>, y <span class="op">=</span> <span class="va">frequency</span>, group <span class="op">=</span> <span class="va">word</span>, color <span class="op">=</span> <span class="va">word</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>    title <span class="op">=</span> <span class="st">"Parallel Coordinate Visualization"</span>,</span>
<span>    subtitle <span class="op">=</span> <span class="st">"Text Classification Model Using Words as Features"</span>,</span>
<span>    x <span class="op">=</span> <span class="st">"Class"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Normalized Term Frequency"</span></span>
<span>  <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-pda-parallel-coordinates" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="prediction_files/figure-html/fig-pda-parallel-coordinates-1.png" class="img-fluid figure-img" width="384"></p>
<figcaption class="figure-caption">Figure&nbsp;9.1: A parallel coordinate plot showing the distribution of class labels across different feature dimensions</figcaption></figure>
</div>
</div>
</div>
<p>We can look at the parallel coordinate plot in <a href="#fig-pda-parallel-coordinates">Figure&nbsp;<span>9.1</span></a> to see that the words “cats” and “love” are more common in the positive class, while the words “dogs” and “hate” are more common in the negative class. This suggests that these words are good features for distinguishing between the two classes.</p>
</section><section id="pda-workflow-regression" class="level5"><h5 class="anchored" data-anchor-id="pda-workflow-regression">Regression</h5>
<p>For regression, the most common metric is the root mean squared error (RMSE). The RMSE is the square root of the mean of the squared differences between the predicted values and the actual values. The lower the RMSE, the better the model fits the data.</p>
<p>Supervised machine learning algorithms for regression are typically evaluated using measures of error such as mean squared error (MSE), root mean squared error (RMSE), and mean absolute error (MAE). MSE is used to measure the average of the squares of the errors, MAE is the average of the absolute differences between the prediction and the actual data, and RMSE is the square root of the mean squared error. For each of these statistics, the lower the value, the better the model fits the data. The differences between these statistics are shown in <a href="#tbl-pda-error-metrics">Table&nbsp;<span>9.4</span></a>.</p>
<div class="cell" data-hash="prediction_cache/html/tbl-pda-error-metrics_928e03e93f81e2e0387473d5323d4b04">
<div class="cell-output-display">
<div id="tbl-pda-error-metrics" class="anchored">
<table data-quarto-postprocess="true" class="table table-sm table-striped small">
<caption>Table&nbsp;9.4: A table showing the differences between mean squared error, root mean squared error, and mean absolute error</caption>
<thead><tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">error</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">formula</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">MSE</td>
<td style="text-align: left;">$$\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$</td>
<td style="text-align: left;">The average of the squared differences between the prediction and the actual data</td>
</tr>
<tr class="even">
<td style="text-align: left;">RMSE</td>
<td style="text-align: left;">$$\sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}$$</td>
<td style="text-align: left;">The square root of the mean squared error</td>
</tr>
<tr class="odd">
<td style="text-align: left;">MAE</td>
<td style="text-align: left;">$$\frac{1}{n} \sum_{i=1}^{n} \vert y_i - \hat{y}_i \vert$$</td>
<td style="text-align: left;">The average of the absolute differences between the prediction and the actual data</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
<p>The main advantages of using MSE, RMSE, and MAE are that they are all on the same scale as the dependent variable, and they are all differentiable, which makes them useful for optimization algorithms. MSE is the most commonly used metric for regression, but RMSE and MAE are also used. MSE is more sensitive to outliers than RMSE and MAE, so it is more useful when the data has outliers. RMSE and MAE are more useful when the data does not have outliers.</p>
<!-- See https://smltar.com/mlregression.html for more info on evaluation (and other aspects) of supervised machine learning regression models.  -->
<p>Plot the actual and predicted values to see how well the model fits the data.</p>
<div class="cell" data-hash="prediction_cache/html/pda-regression-plot_bdbb274808570facd81b070fdb52de6e">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="prediction_files/figure-html/pda-regression-plot-1.png" class="img-fluid figure-img" width="384"></p>
<figcaption class="figure-caption">A plot of the actual and predicted values for a regression model</figcaption></figure>
</div>
</div>
</div>
<p>We can now apply our error metrics to the <code>results</code> data to see how well the model fits the data.</p>
<div class="cell" data-hash="prediction_cache/html/pda-regression-error_60878b2b11969914a21f3a0859bb95ba">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">#|</span></span>
<span><span class="co"># Calculate the error metrics for the `results` data</span></span>
<span><span class="va">results</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>error <span class="op">=</span> <span class="va">actual</span> <span class="op">-</span> <span class="va">predicted</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># calculate the error</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarise</a></span><span class="op">(</span></span>
<span>    mse <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">error</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, <span class="co"># calculate the MSE</span></span>
<span>    rmse <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">mse</span><span class="op">)</span>, <span class="co"># calculate the RMSE</span></span>
<span>    mae <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">error</span><span class="op">)</span><span class="op">)</span>, <span class="co"># calculate the MAE</span></span>
<span>    n <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/context.html">n</a></span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># calculate the number of observations</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span></span>
<span>    mse <span class="op">=</span> <span class="va">mse</span> <span class="op">*</span> <span class="fl">1</span> <span class="op">/</span> <span class="va">n</span>, <span class="co"># multiply by 1/n to get the MSE for n observations</span></span>
<span>    rmse <span class="op">=</span> <span class="va">rmse</span> <span class="op">*</span> <span class="fl">1</span> <span class="op">/</span> <span class="va">n</span>, <span class="co"># multiply by 1/n to get the RMSE for n observations</span></span>
<span>    mae <span class="op">=</span> <span class="va">mae</span> <span class="op">*</span> <span class="fl">1</span> <span class="op">/</span> <span class="va">n</span></span>
<span>  <span class="op">)</span> <span class="co"># multiply by 1/n to get the MAE for n observations</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 1 × 4
&gt;      mse   rmse     mae     n
&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;
&gt; 1 0.0113 0.0106 0.00947   100</code></pre>
</div>
</div>
<p>Formula for calculating the MSE:</p>
<p><span id="eq-pda-mse"><span class="math display">\[
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\tag{9.5}\]</span></span></p>
<p>So we can implement this in R subtracting the actual values from the predicted values, squaring the differences, then taking the mean of the all the squared differences, and finally multiplying by <span class="math inline">\(1/n\)</span> to get the MSE for <span class="math inline">\(n\)</span> observations.</p>
<div class="cell" data-hash="prediction_cache/html/pda-regression-mse_969ae1af3e0622d2f79edb5b799a3000">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">results</span> <span class="op">|&gt;</span> <span class="co"># use the `results` data</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>error <span class="op">=</span> <span class="va">actual</span> <span class="op">-</span> <span class="va">predicted</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># calculate the error</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarise</a></span><span class="op">(</span></span>
<span>    mse <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">error</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, <span class="co"># calculate the MSE</span></span>
<span>    n <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/context.html">n</a></span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># calculate the number of observations</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>mse <span class="op">=</span> <span class="va">mse</span> <span class="op">*</span> <span class="fl">1</span> <span class="op">/</span> <span class="va">n</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># multiply by 1/n to get the MSE for n observations</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">mse</span><span class="op">)</span> <span class="co"># pull the MSE value out of the tibble</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; [1] 0.0113</code></pre>
</div>
</div>
<p>Formula for calculating the RMSE:</p>
<p><span id="eq-pda-rmse"><span class="math display">\[
\text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
\tag{9.6}\]</span></span></p>
</section></section></section><section id="pda-analysis" class="level2" data-number="9.4"><h2 data-number="9.4" class="anchored" data-anchor-id="pda-analysis">
<span class="header-section-number">9.4</span> Analysis</h2>
<p>Recap and introduction to the structure of the analysis subsection.</p>
<ul>
<li>Introduce an algorithm</li>
<li>Build a model
<ul>
<li>Preprocessing (tokenization, lemmatization, etc.)</li>
<li>Feature extraction (TF-IDF, word embeddings, etc.)</li>
<li>Model selection (logistic regression, SVM, etc.)</li>
<li>Model training</li>
</ul>
</li>
<li>Evaluate (and adjust) the model on the training data
<ul>
<li>Cross-validation</li>
<li>Evaluation metrics</li>
<li>Compare to null and/ or other models</li>
<li>Adjust the model (hyperparameters, regularization, etc.) as necessary</li>
</ul>
</li>
<li>Evaluate the model on the test data
<ul>
<li>Evaluation metrics</li>
<li>Evaluate feature importance</li>
<li>Evaluate the features of correct and incorrect predictions</li>
</ul>
</li>
</ul>
<section id="pda-classification" class="level3" data-number="9.4.1"><h3 data-number="9.4.1" class="anchored" data-anchor-id="pda-classification">
<span class="header-section-number">9.4.1</span> Classification</h3>
<p>We will first start with classification which is by far the most common text analysis approach in supervised machine learning. Again, classification is the task of predicting a categorical variable from a set of features. The features we use will be derived from the text but can take many forms. For example, we can use the raw text, the word counts, the TF-IDF values, or the word embeddings. We also will take into account the number of features we use. There is a trade-off, however, to the number of features: a) the more features we use, the more complex the model will be, and the more likely it will overfit the training data and b) the less features we use, the less complex the model will be, and the more likely it will underfit the training data. To find the optimal number of features we can use a technique called cross-validation.</p>
<p>The most common text classification algorithms are logistic regression, k-nearest neighbors, Naive Bayes, and support vector machines. We will start with logistic regression and k-nearest neighbors as they are the simplest to understand and implement. We will then move on to Naive Bayes and support vector machines as they are more complex and require more explanation.</p>
<p>Building a null model for classification we simply predict the most common class in the training data. This makes sense as we have seen earlier, with categorical data the central tendency is estimated by the mode –i.e.&nbsp;the most common value.</p>
<section id="pda-k-nearest-neighbors" class="level4"><h4 class="anchored" data-anchor-id="pda-k-nearest-neighbors">K-nearest neighbors</h4>
<p>K-nearest neighbors is a simple supervised machine learning method for classification. It is a non-parametric method, which means that it does not make any assumptions about the underlying distribution of the data. It is a lazy learning method, which means that it does not learn a discriminant function from the training data but instead stores the training data. It is a distance-based method, which means that it uses a distance metric to find the <span class="math inline">\(k\)</span> nearest neighbors to a new observation. It is a simple method, which means that it is easy to understand and implement.</p>
</section><section id="pda-logistic-regression" class="level4"><h4 class="anchored" data-anchor-id="pda-logistic-regression">Logistic regression</h4>
<p>Logistic regression is a supervised machine learning method for classification. It is a parametric method, which means that it makes assumptions about the underlying distribution of the data. It is an iterative method, which means that it uses an iterative algorithm to find the optimal parameters. To avoid overfitting it uses regularization such as ridge regression or lasso regression. These regularization methods penalize the model for having too many parameters. However, how does one know what the optimal number of parameters is? This is where cross-validation comes in.</p>
</section><section id="pda-naive-bayes" class="level4"><h4 class="anchored" data-anchor-id="pda-naive-bayes">Naive Bayes</h4>
<p>Naive Bayes is a supervised machine learning method for classification. It is a parametric method, which means that it makes assumptions about the underlying distribution of the data. It is a probabilistic method, which means that it uses Bayes’ theorem to calculate the probability of a class given the predictor variables. It is a generative method, which means that it learns the joint probability distribution of the predictor variables and the outcome variable. It is a simple method, which means that it makes the assumption that the predictor variables are independent of each other. This assumption is called the naive assumption. Now this assumption does not theoretically hold for language data as words are not independent of each other. However, in practice, Naive Bayes’ models still perform well on many text classification tasks.</p>
</section><section id="pda-decision-trees" class="level4"><h4 class="anchored" data-anchor-id="pda-decision-trees">Decision trees</h4>
<p>Decision trees for text classification are a supervised machine learning method for classification. They are a non-parametric method, which means that they do not make any assumptions about the underlying distribution of the data. They are a greedy method, which means that they use a greedy algorithm to find the optimal split of the predictor variables. They are a simple method, which means that they are easy to understand and implement.</p>
<p>In practical terms using decision trees for text classification can be very useful as they are easy to interpret. For example, we can see which words are most important for the classification of a text. However, they are prone to overfitting the training data. To avoid this we can use a technique called bagging. Bagging is a technique that uses multiple decision trees to make a prediction. The prediction is then the mode of the predictions of the individual decision trees. This is called a random forest.</p>
</section></section><section id="pda-regression" class="level3" data-number="9.4.2"><h3 data-number="9.4.2" class="anchored" data-anchor-id="pda-regression">
<span class="header-section-number">9.4.2</span> Regression</h3>
<p>In supervised machine learning regression tasks contrast to classification tasks as the outcome variable is continuous. A typical example outside of language would be to predict the price of a house given the number of bedrooms, the number of bathrooms, the size of the house, etc. For language this means that the labled outcome variable is a number, not a class. For example, we can predict the number of words in a text given the number of characters in the text, the number of sentences in the text, etc. Other applications of regression in text analysis are sentiment analysis (where the outcome is a scalar value) and topic modeling (where the outcome is a probability distribution over topics).</p>
<section id="pda-linear-regression" class="level4"><h4 class="anchored" data-anchor-id="pda-linear-regression">Linear regression</h4>
<p>Linear regression can be used to predict a continuous outcome variable from a set of features. It is a parametric method, which means that it makes assumptions about the underlying distribution of the data. It is an iterative method, which means that it uses an iterative algorithm to find the optimal parameters. To avoid overfitting it uses regularization such as ridge regression or lasso regression. These regularization methods penalize the model for having too many parameters. However, how does one know what the optimal number of parameters is? This is where cross-validation comes in.</p>
</section><section id="pda-decision-trees-regression" class="level4"><h4 class="anchored" data-anchor-id="pda-decision-trees-regression">Decision trees (regression)</h4>
<p>Decision trees for regression are a supervised machine learning method for regression. They are a non-parametric method, which means that they do not make any assumptions about the underlying distribution of the data. They are a greedy method, which means that they use a greedy algorithm to find the optimal split of the predictor variables. They are a simple method, which means that they are easy to understand and implement.</p>
</section><section id="pda-neural-networks" class="level4"><h4 class="anchored" data-anchor-id="pda-neural-networks">Neural networks</h4>
<p>Neural networks are a supervised machine learning method for regression and classification. They are a non-parametric method, which means that they do not make any assumptions about the underlying distribution of the data. They are an iterative method, which means that they use an iterative algorithm to find the optimal parameters. They are a complex method, which means that they are difficult to understand and implement. However, they are very powerful and can be used to solve a wide range of problems. However, they are expensive to train and require a lot of data. It is often the case that a simpler method will perform just as well as a neural network in certain contexts.</p>
</section></section></section><section id="pda-reporting" class="level2" data-number="9.5"><h2 data-number="9.5" class="anchored" data-anchor-id="pda-reporting">
<span class="header-section-number">9.5</span> Reporting</h2>
<p>When reporting the results of a supervised machine learning model it is important to report the evaluation metrics that are most relevant to the problem at hand. For example, if the problem is to predict a continuous outcome, then the most relevant evaluation metric is the mean squared error (MSE). It is often useful to report the root mean squared error (RMSE) as well.</p>
<p>However, if the problem is to predict the class, then the most relevant evaluation metric is the accuracy. Other evaluation metrics that are often reported are the precision, recall, and F1-score. It can also be useful to report the confusion matrix. The confusion matrix shows the number of true positives, false positives, true negatives, and false negatives.</p>
<p>If the research goal is focused on prediction accuracy, then these statistics are the most relevant. But in other cases, the supervised learning alogrithm is a means to guage a relationship between the outcome and the predictor variables, namely to guage the most important predictor variables. The model can then be used to identify those predictor variables that support accurate predictions and even to identify those predictor variables that do not support accurate predictions. Note, however, that some supervised learning algorithms are not able to identify the most important predictor variables. For example, neural networks are not able to identify the most important predictor variables. These ‘black box’ algorithms may lead to accurate predictions, but they do not provide any insight into the underlying relationship between the outcome and the predictor variables.</p>
</section><section id="pda-summary" class="level2" data-number="9.6"><h2 data-number="9.6" class="anchored" data-anchor-id="pda-summary">
<span class="header-section-number">9.6</span> Summary</h2>
<p>In this chapter we have learned about supervised machine learning. We have learned about the different types of supervised machine learning methods and how they can be used to predict and classify. We have also learned about the different types of data structures that are used in supervised machine learning. Finally, we have learned about the different types of evaluation metrics that are used to evaluate the performance of supervised machine learning models.</p>
</section><section id="activities" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="activities">Activities</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Recipe
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>What</strong>: <a href="https://lin380.github.io/tadr/articles/recipe_10.html">Predictive models: prep, train, test, and evaluate</a><br><strong>How</strong>: Read Recipe 10 and participate in the Hypothes.is online social annotation.<br><strong>Why</strong>: To illustrate some common coding strategies for preparing datasets for inferential data analysis, as well as the steps conduct descriptive assessment, statistical interrogation, and evaluation and reporting of results.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Lab
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>What</strong>: <a href="https://github.com/lin380/lab_10">Predictive Data Analysis</a><br><strong>How</strong>: Clone, fork, and complete the steps in Lab 10.<br><strong>Why</strong>: To gain experience working with coding strategies to prepare, feature engineer, train and test a predictive model, and evaluate results from a predictive data analysis, practice transforming datasets into new object formats and visualizing relationships, and implement organizational strategies for organizing and reporting results in a reproducible fashion.</p>
</div>
</div>
</section><section id="questions" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="questions">Questions</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Conceptual questions
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>What is the difference between a continuous and a categorical variable?</li>
<li>What is the difference between a regression and a classification model?</li>
<li>What is the difference between a training set and a testing set?</li>
<li>What is the difference between a hyperparameter and a parameter?</li>
<li>What is the difference between a supervised and an unsupervised machine learning model?</li>
<li>What advantages and disadvantages do supervised machine learning models have over traditional methods of text analysis?</li>
<li>What are some potential applications of supervised machine learning in linguistics?</li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Technical exercises
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>Write a program to build a classification model which uses a set of collected text features to predict a target variable.</li>
<li>Use the classification model to classify a series of documents and assess the accuracy of the model.</li>
<li>Develop a regression model which uses text features to predict a continuous target variable.</li>
<li>Create a text mining application to analyze a large body of text and discover correlations between variables.</li>
<li>Use a clustering algorithm to discover clusters in a large dataset, and create a visualization to present the identified clusters.</li>
<li>Analyze the structure of a text corpus and identify patterns in word usage and feature distributions.</li>
<li>Build a predictive model using text as an input and binary or categorical outcomes as the target.</li>
<li>Develop a natural language processing application which classifies text into predefined categories using a supervised learning algorithm.</li>
<li>Use a supervised learning algorithm to build a predictive model which classifies a set of unseen texts into predefined categories.</li>
<li>Develop a web application which allows users to easily explore a set of text documents, visualize the content of the documents, and generate predictive models from the text.</li>
</ol>
</div>
</div>

<!---

- Overview:
    - Research goals (predict, prescribe, verify)
    - Use of data
        - Partitioned: training (reusable) and test (reserved) sets
        - Outcome variable and predictor/ covariate variables
        - Fixed outcome and mutable predictor variables/ features
    - Methods
        - Supervised machine learning methods
            - Regression
            - Classification
    - Data types/ structures
        - Matrices
    - Interpreting results (quantitative)
        - Summary statistics: 
            - Accuracy
            - Precision
            - Recall
            - F1
            - Confusion matrix
- Supervised machine learning analysis
    - Methods: 
        - Regression (continuous outcome variable)
            - Linear regression
            - Decision trees
            - Neural networks
        - Classification (categorical outcome variable)
            - Logistic regression
            - Decision trees
            - Neural networks





Supervised machine learning is a type of artificial intelligence that involves training a model on a labeled dataset where the input data and desired output are both provided. The model is able to make predictions or classifications based on the input data by learning the relationships between the input and output data. Supervised machine learning is an important tool for linguists studying language and communication, as it allows them to analyze language data and identify patterns or trends in language use. There are two main types of supervised machine learning algorithms: classification, which is used to predict a categorical outcome such as the genre of a text, and regression, which is used to predict a continuous outcome such as the sentiment of a text. In order to use supervised machine learning, linguists must first prepare the data by cleaning and preprocessing it, and then split the data into training and testing sets. The model is then trained on the training data and evaluated on the testing data, and the hyperparameters of the model may be adjusted to optimize its performance. Some applications of supervised machine learning in linguistics include text classification, part-of-speech tagging, and language identification. Supervised machine learning is an active area of research in linguistics, with many potential applications and areas for further exploration.


I. Introduction to supervised machine learning
A. Definition of supervised machine learning
i. Supervised machine learning involves training a model on a labeled dataset where the input data and desired output are both provided
ii. The model is able to make predictions or classifications based on the input data by learning the relationships between the input and output data
B. Importance of supervised machine learning for linguistics
i. Supervised machine learning can be used to analyze language data and identify patterns or trends in language use
ii. Supervised machine learning can help linguists classify texts, predict language evolution, and identify language-specific features

II. Types of supervised machine learning algorithms
A. Classification
i. Classification algorithms are used to predict a categorical outcome, such as whether a text belongs to a particular genre
ii. Examples of classification algorithms include decision trees, logistic regression, and support vector machines
B. Regression
i. Regression algorithms are used to predict a continuous outcome, such as the sentiment of a text
ii. Examples of regression algorithms include linear regression and multiple linear regression

III. Preparing data for supervised machine learning
A. Data preprocessing
i. Data preprocessing involves cleaning and preparing the data for analysis
ii. This may include tasks such as removing missing values, scaling the data, and encoding categorical variables
B. Data splitting
i. Data splitting involves dividing the data into training and testing sets
ii. The training set is used to train the model, while the testing set is used to evaluate the model's performance

IV. Training and evaluating a supervised machine learning model
A. Training a model
i. Training a model involves providing the model with the training data and adjusting the model's parameters to minimize the error between the model's predictions and the true output
B. Evaluating a model
i. Evaluating a model involves using the testing data to measure the model's performance
ii. Common evaluation metrics for supervised machine learning include accuracy, precision, and recall
C. Tuning model hyperparameters
i. Hyperparameters are the parameters of the machine learning model that are set before training begins
ii. Tuning hyperparameters involves adjusting the values of the hyperparameters to optimize the model's performance

V. Applications of supervised machine learning in linguistics
A. Text classification
i. Text classification involves categorizing texts into predefined categories, such as genre or topic
ii. Supervised machine learning can be used to classify texts based on their content or linguistic features
B. Part-of-speech tagging
i. Part-of-speech tagging involves assigning a part of speech to each word in a text
ii. Supervised machine learning can be used to identify the part of speech of a word based on its context and other linguistic features
C. Language identification
i. Language identification involves determining the language of a text
ii. Supervised machine learning can be used to identify the language of a text based on its content or linguistic features

VI. Conclusion
A. Recap of key points
i. Supervised machine learning is a type of machine learning that involves training a model on a labeled dataset
ii. Supervised machine learning can be used to classify texts, predict language evolution, and identify language-specific features
B. Future directions for supervised machine learning in linguistics
i. Supervised machine learning is an active area of research in linguistics, with many potential applications and areas for further exploration
ii. Future research may focus on developing more sophisticated



Research

Strengths:
1. Neural networks are able to capture complex relationships between words and phrases in text.
2. Neural networks can learn from large amounts of data and can be trained to classify text with high accuracy.
3. Neural networks can be used to classify text into multiple categories.
4. Neural networks can be used to identify patterns in text that are not easily detected by traditional methods.

Weaknesses:
1. Neural networks require a large amount of data to train and can be computationally expensive.
2. Neural networks can be prone to overfitting if the data is not properly preprocessed.
3. Neural networks can be difficult to interpret and explain due to their complexity.
4. Neural networks can be sensitive to noise and outliers in the data.


Building and evaluating a predictive model for text classification requires multiple steps. Here are the key ones:

1. Data collection - Collect a set of labeled documents to be used in the model.

2. Data preprocessing - Clean the data and prepare it for the model by tokenizing, stemming, and removing stop words.

3. Feature extraction - Extract features from the data using methods such as bag of words, TF-IDF, word embeddings, and feature selection.

4. Model training - Train the model on the extracted features using methods such as Logistic Regression, Support Vector Machines, Naive Bayes, and Neural Networks.

5. Model evaluation - Evaluate the model using metrics such as accuracy, precision, recall, and F1-score.

6. Model tuning - Optimize the model by adjusting its parameters to obtain better results.


-->


</section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>Note that functions for meta-features require more sophisticated text analysis software to be installed on the computing environment (e.g.&nbsp;<code>spacyr</code> for <code><a href="https://textrecipes.tidymodels.org/reference/step_lemma.html">step_lemma()</a></code>, <code>step_pos()</code>, <em>etc.</em>). See the <code>textrecipes</code> package documentation for more information.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./exploration.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Exploration</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./inference.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Inference</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>
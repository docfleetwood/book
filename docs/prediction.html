<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Quantitative Text Analysis for Linguistics - 9&nbsp; Prediction</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./inference.html" rel="next">
<link href="./exploration.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script async="" src="https://hypothes.is/embed.js"></script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><link rel="stylesheet" href="assets/css/style.css">
</head>
<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./analysis.html">Analysis</a></li><li class="breadcrumb-item"><a href="./prediction.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Prediction</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Quantitative Text Analysis for Linguistics</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com" rel="" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./orientation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Orientation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./text-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Text analysis in context</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./understanding-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Understanding data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./approaching-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Approaching analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./framing-research.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Framing research</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./preparation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preparation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./acquire-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Acquire data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./curate-datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Curate data(sets)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./transform-datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Transform datasets</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Analysis</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./exploration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Exploration</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./prediction.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Prediction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Inference</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./communication.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Communication</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reporting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Reporting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./collaboration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Collaboration</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Data</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#pda-orientation" id="toc-pda-orientation" class="nav-link active" data-scroll-target="#pda-orientation"><span class="header-section-number">9.1</span> Orientation</a>
  <ul class="collapse">
<li><a href="#pda-research-goals" id="toc-pda-research-goals" class="nav-link" data-scroll-target="#pda-research-goals"><span class="header-section-number">9.1.1</span> Research goals</a></li>
  <li><a href="#pda-approaches" id="toc-pda-approaches" class="nav-link" data-scroll-target="#pda-approaches"><span class="header-section-number">9.1.2</span> Approaches</a></li>
  <li><a href="#pda-workflow" id="toc-pda-workflow" class="nav-link" data-scroll-target="#pda-workflow"><span class="header-section-number">9.1.3</span> Workflow</a></li>
  </ul>
</li>
  <li>
<a href="#pda-analysis" id="toc-pda-analysis" class="nav-link" data-scroll-target="#pda-analysis"><span class="header-section-number">9.2</span> Analysis</a>
  <ul class="collapse">
<li><a href="#pda-classification" id="toc-pda-classification" class="nav-link" data-scroll-target="#pda-classification"><span class="header-section-number">9.2.1</span> Classification</a></li>
  <li><a href="#pda-regression" id="toc-pda-regression" class="nav-link" data-scroll-target="#pda-regression"><span class="header-section-number">9.2.2</span> Regression</a></li>
  </ul>
</li>
  <li><a href="#pda-reporting" id="toc-pda-reporting" class="nav-link" data-scroll-target="#pda-reporting"><span class="header-section-number">9.3</span> Reporting</a></li>
  <li><a href="#pda-summary" id="toc-pda-summary" class="nav-link" data-scroll-target="#pda-summary"><span class="header-section-number">9.4</span> Summary</a></li>
  <li><a href="#activities" id="toc-activities" class="nav-link" data-scroll-target="#activities">Activities</a></li>
  <li><a href="#questions" id="toc-questions" class="nav-link" data-scroll-target="#questions">Questions</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title"><span id="sec-prediction" class="quarto-section-identifier"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Prediction</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><!-- 

Content:

Exercises:

- [ ] add concept questions to Activities
- [ ] add exercises to Activities
- [ ] add thought questions/ case studies to prose sections

Formatting:

--><blockquote class="blockquote">
<p>All models are wrong, but some are useful.</p>
<p>— George E.P. Box</p>
</blockquote>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Keys
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>…</li>
</ul>
</div>
</div>
<p>In this chapter I present an introduction to approaches to data analysis known as machine learning, specifically supervised learning. In a nutshell, the aim of supervised learning is to leverage a potential relationship between a target or outcome variable and a set of other variables (features) derived from text to create a statistical generalization (model) that can accurately predict the values of the target variable using the values of the feature variables. We consider practical tasks as well as theoretical applications of the statistical learning in text analysis highlighting the standard workflow for building predictive models, testing and evaluating models, working to improve model performance, and how to interpret and report findings.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Swirl
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>What</strong>: <a href="https://github.com/lin380/swirl">Supervised Learning</a><br><strong>How</strong>: In the R Console pane load <code>swirl</code>, run <code>swirl()</code>, and follow prompts to select the lesson.<br><strong>Why</strong>: …</p>
</div>
</div>
<section id="pda-orientation" class="level2" data-number="9.1"><h2 data-number="9.1" class="anchored" data-anchor-id="pda-orientation">
<span class="header-section-number">9.1</span> Orientation</h2>
<p>The aim of this section is to introduce the reader to the concept of supervised learning and to provide a brief overview of the workflow for building predictive models for text analysis.</p>
<section id="pda-research-goals" class="level3" data-number="9.1.1"><h3 data-number="9.1.1" class="anchored" data-anchor-id="pda-research-goals">
<span class="header-section-number">9.1.1</span> Research goals</h3>
<p>Supervised learning is a type of machine learning that involves training a model on a labeled dataset where the input data and desired output are both provided. The model is able to make predictions or classifications based on the input data by learning the relationships between the input and output data. Supervised machine learning is an important tool for linguists studying language and communication, as it allows them to analyze language data to identify patterns or trends in language use, verify hypotheses, and prescribe actions. Supervised machine learning is an active area of research in linguistics, with many potential applications and areas for further exploration.</p>
<p>Predictive analyses are more inductive than exploratory analyses, which are more deductive. This means that we are more interested in the relationship between a particular outcome variable and a set of predictor variables than we are in the relationship between the predictor variables themselves, as we would be in an exploratory analysis. In this sense, we have a particular outcome in mind from the outset. On the other hand, the input variables are mutable, meaning that they can be changed to see how they affect the outcome –which points to the exploratory aspect of predictive analyses.</p>
</section><section id="pda-approaches" class="level3" data-number="9.1.2"><h3 data-number="9.1.2" class="anchored" data-anchor-id="pda-approaches">
<span class="header-section-number">9.1.2</span> Approaches</h3>
<ul>
<li>Outcome variable and any number of predictor variables</li>
<li>Predictor variables are features derived from text and are mutable.</li>
</ul>
<section id="pda-analysis-types" class="level4"><h4 class="anchored" data-anchor-id="pda-analysis-types">Analysis types</h4>
<p>There are two main types of supervised machine learning algorithms: classification, which is used to predict a categorical outcome such as the genre of a text, and regression, which is used to predict a continuous outcome such as the sentiment of a text.</p>
<ul>
<li>Supervised learning
<ul>
<li>Classification
<ul>
<li>Categorical outcome variable</li>
</ul>
</li>
<li>Regression
<ul>
<li>Continuous outcome variable</li>
</ul>
</li>
</ul>
</li>
</ul></section></section><section id="pda-workflow" class="level3" data-number="9.1.3"><h3 data-number="9.1.3" class="anchored" data-anchor-id="pda-workflow">
<span class="header-section-number">9.1.3</span> Workflow</h3>
<p>Prerequisites: - A working research question or hypothesis - A dataset which aligns with the research question or hypothesis in terms of its sampling frame and the variables it contains or can be derived from the text and a target variable to be predicted. - A set of preliminary features to be derived from the text that are used to predict the target variable</p>
<!--- Move the sections above (Approaching analysis)/ Keep the sections below -->
<section id="pda-identify" class="level4"><h4 class="anchored" data-anchor-id="pda-identify">Identify</h4>
<p>Data cleaning and feature extraction are the first steps in the process of preparing data for supervised machine learning.</p>
<p>In order to use supervised machine learning, linguists must first identify measurable properties of the text use use as the input variables or features that are most likely to produce a model that performs well (i.e.&nbsp;that when used make accurate predictions). Once the feature types are identified, the data is processed to clean any extraneous elements and format the structure of the dataset given the requirements of the algorithm that will be used in subsequent steps.</p>
</section><section id="pda-inspect" class="level4"><h4 class="anchored" data-anchor-id="pda-inspect">Inspect</h4>
<p>The next step is to inspect the data:</p>
<p>Preprocess (missing, anomalies, outliers, transformations, etc.) Descriptive (summary statistics, visualizations, etc.)</p>
<p>Include dataset transformation to ensure that it is in the correct format for the machine learning algorithm that will be used.</p>
</section><section id="pda-interrogate" class="level4"><h4 class="anchored" data-anchor-id="pda-interrogate">Interrogate</h4>
<p>Model training is the next step towards building a predictive model.</p>
<p>In this step, the data is split into training and testing sets. The training set is used to train the model, and the testing set is used to evaluate the model’s performance. The testing set is reserved and not used to train the model, so that the model’s performance can be evaluated on data that it has not seen before.</p>
<p>The model is then trained on the training data and evaluated on the testing data. The results are then evaluated and the hyperparameters of the model may be adjusted to optimize its performance.</p>
<p>and the hyperparameters of the model may be adjusted to optimize its performance.</p>
<p>Hyperparameters are variables that are set prior to running a machine learning algorithm whose values influence the final result. In supervised machine learning, hyperparameters are typically used to control the learning process such as the learning rate, momentum, and batch size.</p>
<p>Some applications of supervised machine learning in linguistics include text classification, part-of-speech tagging, and language identification. Supervised machine learning is an active area of research in linguistics, with many potential applications and areas for further exploration.</p>
</section><section id="pda-interpret" class="level4"><h4 class="anchored" data-anchor-id="pda-interpret">Interpret</h4>
<p>To either evaluate the training or testing set, the model is used to make predictions on the data in the set. The predictions are then compared to the actual values of the target variable in the set to evaluate the model’s performance. So how is the model’s performance evaluated?</p>
<section id="pda-workflow-classification" class="level5"><h5 class="anchored" data-anchor-id="pda-workflow-classification">Classification</h5>
<p>For classification, there are a number of metrics that can be used to evaluate the performance of a model, including accuracy, precision, recall, and F1 score. To understand these measures it is helpful to consider a confusion matrix, which is a table that describes the performance of a classification model on data for which the true values are known. The confusion matrix is a two-by-two matrix that shows the number of true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN), as seen in <a href="#tbl-pda-confusion-matrix">Table&nbsp;<span>9.1</span></a>.</p>
<div class="cell" data-layout-align="center" data-hash="prediction_cache/html/tbl-pda-confusion-matrix_bf061669d28d07c17bc1fefff6cec7a7">
<div class="cell-output-display">
<div id="tbl-pda-confusion-matrix" class="anchored">
<table class="table table-sm table-striped small">
<caption>Table&nbsp;9.1: A labeled confusion matrix</caption>
<thead><tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Predicted positive</th>
<th style="text-align: left;">Predicted negative</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Actual positive</td>
<td style="text-align: left;">TP</td>
<td style="text-align: left;">FP</td>
</tr>
<tr class="even">
<td style="text-align: left;">Actual negative</td>
<td style="text-align: left;">FN</td>
<td style="text-align: left;">TN</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Now let’s fill this confusion matrix with hypothetical values, as seen in <a href="#tbl-pda-confusion-matrix-example">Table&nbsp;<span>9.2</span></a> to see how the metrics are calculated.</p>
<div class="cell" data-layout-align="center" data-hash="prediction_cache/html/tbl-pda-confusion-matrix-example_aea9a479e95bc4ed94f014f27e7b6a32">
<div class="cell-output-display">
<div id="tbl-pda-confusion-matrix-example" class="anchored">
<table class="table table-sm table-striped small">
<caption>Table&nbsp;9.2: Confusion matrix for a hypothetical model’s performance on a test set</caption>
<thead><tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">Predicted positive</th>
<th style="text-align: right;">Predicted negative</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Actual positive</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">10</td>
</tr>
<tr class="even">
<td style="text-align: left;">Actual negative</td>
<td style="text-align: right;">20</td>
<td style="text-align: right;">50</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<ul>
<li>Accuracy is defined as the proportion of correct predictions made by the model.</li>
</ul>
<p><span id="eq-pda-accuracy"><span class="math display">\[
\text{Accuracy} = \frac{\text{Number of correct predictions}}{\text{Total number of predictions}}
\tag{9.1}\]</span></span></p>
<p>The number of correct predictions is the sum of true positives and true negatives. So in our case this is 100 + 50 = 150. The total number of predictions is the sum of all four cells in the confusion matrix, so in our case this is 100 + 10 + 20 + 50 = 180. So the accuracy of our hypothetical model is 150/180 = 0.833.</p>
<ul>
<li>Precision is defined as the proportion of positive predictions that are correct.</li>
</ul>
<p><span id="eq-pda-precision"><span class="math display">\[
\text{Precision} = \frac{\text{Number of true positives}}{\text{Number of true positives + false positives}}
\tag{9.2}\]</span></span></p>
<ul>
<li>Recall is defined as the proportion of actual positives that are correctly identified.</li>
</ul>
<p><span id="eq-pda-recall"><span class="math display">\[
\text{Recall} = \frac{\text{Number of true positives}}{\text{Number of true positives + false negatives}}
\tag{9.3}\]</span></span></p>
<ul>
<li>The F1 score is the harmonic mean of precision and recall.</li>
</ul>
<p><span id="eq-pda-f1"><span class="math display">\[
\text{F1 score} = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
\tag{9.4}\]</span></span></p>
<p>Area under the curve (AUC) is the area under the ROC (Receiver Operating Characteristic) curve, which is a graph of true positives (TPR) and false positives (FPR). The AUC is a measure of the model’s performance across all possible classification thresholds. The AUC is a number between 0 and 1, where 0.5 represents a model that is no better than random guessing, and 1 represents a perfect model.</p>
<p><strong>Feature importance</strong></p>
<ul>
<li>parallel coordinate visualization</li>
</ul>
<p>In a supervised text classification task, you can use parallel coordinate plots to visualize the distribution of class labels across different feature dimensions. This can help identify which features are most informative for distinguishing between classes and inform feature selection or dimensionality reduction techniques.</p>
<div class="cell" data-layout-align="center" data-hash="prediction_cache/html/fig-pda-parallel-coordinates_b3082c17a7497cc9e016b8dfc5c63841">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/juliasilge/tidytext">tidytext</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Faux data</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  text <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"I love cats"</span>, <span class="st">"Cats are amazing"</span>, <span class="st">"I hate dogs"</span>, <span class="st">"Dogs are annoying"</span><span class="op">)</span>,</span>
<span>  class <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"positive"</span>, <span class="st">"positive"</span>, <span class="st">"negative"</span>, <span class="st">"negative"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Tokenize data</span></span>
<span><span class="va">tokenized_data</span> <span class="op">&lt;-</span> <span class="va">data</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tidytext/man/unnest_tokens.html">unnest_tokens</a></span><span class="op">(</span><span class="va">word</span>, <span class="va">text</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/count.html">count</a></span><span class="op">(</span><span class="va">class</span>, <span class="va">word</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">ungroup</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/spread.html">spread</a></span><span class="op">(</span><span class="va">class</span>, <span class="va">n</span>, fill <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Normalize the term frequencies</span></span>
<span><span class="va">normalized_data</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">tokenized_data</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span></span>
<span>    positive <span class="op">=</span> <span class="va">positive</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">positive</span><span class="op">)</span>,</span>
<span>    negative <span class="op">=</span> <span class="va">negative</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">negative</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/gather.html">gather</a></span><span class="op">(</span><span class="va">class</span>, <span class="va">frequency</span>, <span class="op">-</span><span class="va">word</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Generate the parallel coordinate plot</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">normalized_data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">class</span>, y <span class="op">=</span> <span class="va">frequency</span>, group <span class="op">=</span> <span class="va">word</span>, color <span class="op">=</span> <span class="va">word</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>    title <span class="op">=</span> <span class="st">"Parallel Coordinate Visualization"</span>,</span>
<span>    subtitle <span class="op">=</span> <span class="st">"Text Classification Model Using Words as Features"</span>,</span>
<span>    x <span class="op">=</span> <span class="st">"Class"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Normalized Term Frequency"</span></span>
<span>  <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-pda-parallel-coordinates" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="prediction_files/figure-html/fig-pda-parallel-coordinates-1.png" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;9.1: A parallel coordinate plot showing the distribution of class labels across different feature dimensions</figcaption></figure>
</div>
</div>
</div>
<p>We can look at the parallel coordinate plot in <a href="#fig-pda-parallel-coordinates">Figure&nbsp;<span>9.1</span></a> to see that the words “cats” and “love” are more common in the positive class, while the words “dogs” and “hate” are more common in the negative class. This suggests that these words are good features for distinguishing between the two classes.</p>
</section><section id="pda-workflow-regression" class="level5"><h5 class="anchored" data-anchor-id="pda-workflow-regression">Regression</h5>
<p>For regression, the most common metric is the root mean squared error (RMSE). The RMSE is the square root of the mean of the squared differences between the predicted values and the actual values. The lower the RMSE, the better the model fits the data.</p>
<p>Supervised machine learning algorithms for regression are typically evaluated using measures of error such as mean squared error (MSE), root mean squared error (RMSE), and mean absolute error (MAE). MSE is used to measure the average of the squares of the errors, MAE is the average of the absolute differences between the prediction and the actual data, and RMSE is the square root of the mean squared error. For each of these statistics, the lower the value, the better the model fits the data. The differences between these statistics are shown in <a href="#tbl-pda-error-metrics">Table&nbsp;<span>9.3</span></a>.</p>
<div class="cell" data-layout-align="center" data-hash="prediction_cache/html/tbl-pda-error-metrics_1fe0c05ae27a24a5435972b98c8b9007">
<div class="cell-output-display">
<div id="tbl-pda-error-metrics" class="anchored">
<table class="table table-sm table-striped small">
<caption>Table&nbsp;9.3: A table showing the differences between mean squared error, root mean squared error, and mean absolute error</caption>
<colgroup>
<col style="width: 4%">
<col style="width: 39%">
<col style="width: 56%">
</colgroup>
<thead><tr class="header">
<th style="text-align: left;">error</th>
<th style="text-align: left;">formula</th>
<th style="text-align: left;">description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">MSE</td>
<td style="text-align: left;"><span class="math display">\[\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2\]</span></td>
<td style="text-align: left;">The average of the squared differences between the prediction and the actual data</td>
</tr>
<tr class="even">
<td style="text-align: left;">RMSE</td>
<td style="text-align: left;"><span class="math display">\[\sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}\]</span></td>
<td style="text-align: left;">The square root of the mean squared error</td>
</tr>
<tr class="odd">
<td style="text-align: left;">MAE</td>
<td style="text-align: left;"><span class="math display">\[\frac{1}{n} \sum_{i=1}^{n} \vert y_i - \hat{y}_i \vert\]</span></td>
<td style="text-align: left;">The average of the absolute differences between the prediction and the actual data</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>The main advantages of using MSE, RMSE, and MAE are that they are all on the same scale as the dependent variable, and they are all differentiable, which makes them useful for optimization algorithms. MSE is the most commonly used metric for regression, but RMSE and MAE are also used. MSE is more sensitive to outliers than RMSE and MAE, so it is more useful when the data has outliers. RMSE and MAE are more useful when the data does not have outliers.</p>
<!-- See https://smltar.com/mlregression.html for more info on evaluation (and other aspects) of supervised machine learning regression models.  -->
<p>Plot the actual and predicted values to see how well the model fits the data.</p>
<div class="cell" data-layout-align="center" data-hash="prediction_cache/html/pda-regression-plot_7bba958c2217b14a3f6ceebb759cc812">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="prediction_files/figure-html/pda-regression-plot-1.png" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption class="figure-caption">A plot of the actual and predicted values for a regression model</figcaption></figure>
</div>
</div>
</div>
<p>We can now apply our error metrics to the <code>results</code> data to see how well the model fits the data.</p>
<div class="cell" data-layout-align="center" data-hash="prediction_cache/html/pda-regression-error_d15e02836fa2b626aaeac0ecc8e494bb">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">#|</span></span>
<span><span class="co"># Calculate the error metrics for the `results` data</span></span>
<span><span class="va">results</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>error <span class="op">=</span> <span class="va">actual</span> <span class="op">-</span> <span class="va">predicted</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># calculate the error</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarise</a></span><span class="op">(</span></span>
<span>    mse <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">error</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, <span class="co"># calculate the MSE</span></span>
<span>    rmse <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">mse</span><span class="op">)</span>, <span class="co"># calculate the RMSE</span></span>
<span>    mae <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">error</span><span class="op">)</span><span class="op">)</span>, <span class="co"># calculate the MAE</span></span>
<span>    n <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/context.html">n</a></span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># calculate the number of observations</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span></span>
<span>    mse <span class="op">=</span> <span class="va">mse</span> <span class="op">*</span> <span class="fl">1</span> <span class="op">/</span> <span class="va">n</span>, <span class="co"># multiply by 1/n to get the MSE for n observations</span></span>
<span>    rmse <span class="op">=</span> <span class="va">rmse</span> <span class="op">*</span> <span class="fl">1</span> <span class="op">/</span> <span class="va">n</span>, <span class="co"># multiply by 1/n to get the RMSE for n observations</span></span>
<span>    mae <span class="op">=</span> <span class="va">mae</span> <span class="op">*</span> <span class="fl">1</span> <span class="op">/</span> <span class="va">n</span></span>
<span>  <span class="op">)</span> <span class="co"># multiply by 1/n to get the MAE for n observations</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; # A tibble: 1 × 4
&gt;      mse   rmse     mae     n
&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;
&gt; 1 0.0113 0.0106 0.00947   100</code></pre>
</div>
</div>
<p>Formula for calculating the MSE:</p>
<p><span id="eq-pda-mse"><span class="math display">\[
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\tag{9.5}\]</span></span></p>
<p>So we can implement this in R subtracting the actual values from the predicted values, squaring the differences, then taking the mean of the all the squared differences, and finally multiplying by <span class="math inline">\(1/n\)</span> to get the MSE for <span class="math inline">\(n\)</span> observations.</p>
<div class="cell" data-layout-align="center" data-hash="prediction_cache/html/pda-regression-mse_3680bb2ab2763f4e52144dcee946679f">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">results</span> <span class="op">|&gt;</span> <span class="co"># use the `results` data</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>error <span class="op">=</span> <span class="va">actual</span> <span class="op">-</span> <span class="va">predicted</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># calculate the error</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarise</a></span><span class="op">(</span></span>
<span>    mse <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">error</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, <span class="co"># calculate the MSE</span></span>
<span>    n <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/context.html">n</a></span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># calculate the number of observations</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>mse <span class="op">=</span> <span class="va">mse</span> <span class="op">*</span> <span class="fl">1</span> <span class="op">/</span> <span class="va">n</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># multiply by 1/n to get the MSE for n observations</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/pull.html">pull</a></span><span class="op">(</span><span class="va">mse</span><span class="op">)</span> <span class="co"># pull the MSE value out of the tibble</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&gt; [1] 0.0113</code></pre>
</div>
</div>
<p>Formula for calculating the RMSE:</p>
<p><span id="eq-pda-rmse"><span class="math display">\[
\text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
\tag{9.6}\]</span></span></p>
</section></section></section></section><section id="pda-analysis" class="level2" data-number="9.2"><h2 data-number="9.2" class="anchored" data-anchor-id="pda-analysis">
<span class="header-section-number">9.2</span> Analysis</h2>
<p>Recap and introduction to the structure of the analysis subsection.</p>
<ul>
<li>Introduce an algorithm</li>
<li>Build a model
<ul>
<li>Preprocessing (tokenization, lemmatization, etc.)</li>
<li>Feature extraction (TF-IDF, word embeddings, etc.)</li>
<li>Model selection (logistic regression, SVM, etc.)</li>
<li>Model training</li>
</ul>
</li>
<li>Evaluate (and adjust) the model on the training data
<ul>
<li>Cross-validation</li>
<li>Evaluation metrics</li>
<li>Compare to null and/ or other models</li>
<li>Adjust the model (hyperparameters, regularization, etc.) as necessary</li>
</ul>
</li>
<li>Evaluate the model on the test data
<ul>
<li>Evaluation metrics</li>
<li>Evaluate feature importance</li>
<li>Evaluate the features of correct and incorrect predictions</li>
</ul>
</li>
</ul>
<section id="pda-classification" class="level3" data-number="9.2.1"><h3 data-number="9.2.1" class="anchored" data-anchor-id="pda-classification">
<span class="header-section-number">9.2.1</span> Classification</h3>
<p>We will first start with classification which is by far the most common text analysis approach in supervised machine learning. Again, classification is the task of predicting a categorical variable from a set of features. The features we use will be derived from the text but can take many forms. For example, we can use the raw text, the word counts, the TF-IDF values, or the word embeddings. We also will take into account the number of features we use. There is a trade-off, however, to the number of features: a) the more features we use, the more complex the model will be, and the more likely it will overfit the training data and b) the less features we use, the less complex the model will be, and the more likely it will underfit the training data. To find the optimal number of features we can use a technique called cross-validation.</p>
<p>The most common text classification algorithms are logistic regression, k-nearest neighbors, Naive Bayes, and support vector machines. We will start with logistic regression and k-nearest neighbors as they are the simplest to understand and implement. We will then move on to Naive Bayes and support vector machines as they are more complex and require more explanation.</p>
<p>Building a null model for classification we simply predict the most common class in the training data. This makes sense as we have seen earlier, with categorical data the central tendency is estimated by the mode –i.e.&nbsp;the most common value.</p>
<section id="pda-k-nearest-neighbors" class="level4"><h4 class="anchored" data-anchor-id="pda-k-nearest-neighbors">K-nearest neighbors</h4>
<p>K-nearest neighbors is a simple supervised machine learning method for classification. It is a non-parametric method, which means that it does not make any assumptions about the underlying distribution of the data. It is a lazy learning method, which means that it does not learn a discriminant function from the training data but instead stores the training data. It is a distance-based method, which means that it uses a distance metric to find the <span class="math inline">\(k\)</span> nearest neighbors to a new observation. It is a simple method, which means that it is easy to understand and implement.</p>
</section><section id="pda-logistic-regression" class="level4"><h4 class="anchored" data-anchor-id="pda-logistic-regression">Logistic regression</h4>
<p>Logistic regression is a supervised machine learning method for classification. It is a parametric method, which means that it makes assumptions about the underlying distribution of the data. It is an iterative method, which means that it uses an iterative algorithm to find the optimal parameters. To avoid overfitting it uses regularization such as ridge regression or lasso regression. These regularization methods penalize the model for having too many parameters. However, how does one know what the optimal number of parameters is? This is where cross-validation comes in.</p>
</section><section id="pda-naive-bayes" class="level4"><h4 class="anchored" data-anchor-id="pda-naive-bayes">Naive Bayes</h4>
<p>Naive Bayes is a supervised machine learning method for classification. It is a parametric method, which means that it makes assumptions about the underlying distribution of the data. It is a probabilistic method, which means that it uses Bayes’ theorem to calculate the probability of a class given the predictor variables. It is a generative method, which means that it learns the joint probability distribution of the predictor variables and the outcome variable. It is a simple method, which means that it makes the assumption that the predictor variables are independent of each other. This assumption is called the naive assumption. Now this assumption does not theoretically hold for language data as words are not independent of each other. However, in practice, Naive Bayes’ models still perform well on many text classification tasks.</p>
</section><section id="pda-decision-trees" class="level4"><h4 class="anchored" data-anchor-id="pda-decision-trees">Decision trees</h4>
<p>Decision trees for text classification are a supervised machine learning method for classification. They are a non-parametric method, which means that they do not make any assumptions about the underlying distribution of the data. They are a greedy method, which means that they use a greedy algorithm to find the optimal split of the predictor variables. They are a simple method, which means that they are easy to understand and implement.</p>
<p>In practical terms using decision trees for text classification can be very useful as they are easy to interpret. For example, we can see which words are most important for the classification of a text. However, they are prone to overfitting the training data. To avoid this we can use a technique called bagging. Bagging is a technique that uses multiple decision trees to make a prediction. The prediction is then the mode of the predictions of the individual decision trees. This is called a random forest.</p>
</section></section><section id="pda-regression" class="level3" data-number="9.2.2"><h3 data-number="9.2.2" class="anchored" data-anchor-id="pda-regression">
<span class="header-section-number">9.2.2</span> Regression</h3>
<p>In supervised machine learning regression tasks contrast to classification tasks as the outcome variable is continuous. A typical example outside of language would be to predict the price of a house given the number of bedrooms, the number of bathrooms, the size of the house, etc. For language this means that the labled outcome variable is a number, not a class. For example, we can predict the number of words in a text given the number of characters in the text, the number of sentences in the text, etc. Other applications of regression in text analysis are sentiment analysis (where the outcome is a scalar value) and topic modeling (where the outcome is a probability distribution over topics).</p>
<section id="pda-linear-regression" class="level4"><h4 class="anchored" data-anchor-id="pda-linear-regression">Linear regression</h4>
<p>Linear regression can be used to predict a continuous outcome variable from a set of features. It is a parametric method, which means that it makes assumptions about the underlying distribution of the data. It is an iterative method, which means that it uses an iterative algorithm to find the optimal parameters. To avoid overfitting it uses regularization such as ridge regression or lasso regression. These regularization methods penalize the model for having too many parameters. However, how does one know what the optimal number of parameters is? This is where cross-validation comes in.</p>
</section><section id="pda-decision-trees-regression" class="level4"><h4 class="anchored" data-anchor-id="pda-decision-trees-regression">Decision trees (regression)</h4>
<p>Decision trees for regression are a supervised machine learning method for regression. They are a non-parametric method, which means that they do not make any assumptions about the underlying distribution of the data. They are a greedy method, which means that they use a greedy algorithm to find the optimal split of the predictor variables. They are a simple method, which means that they are easy to understand and implement.</p>
</section><section id="pda-neural-networks" class="level4"><h4 class="anchored" data-anchor-id="pda-neural-networks">Neural networks</h4>
<p>Neural networks are a supervised machine learning method for regression and classification. They are a non-parametric method, which means that they do not make any assumptions about the underlying distribution of the data. They are an iterative method, which means that they use an iterative algorithm to find the optimal parameters. They are a complex method, which means that they are difficult to understand and implement. However, they are very powerful and can be used to solve a wide range of problems. However, they are expensive to train and require a lot of data. It is often the case that a simpler method will perform just as well as a neural network in certain contexts.</p>
</section></section></section><section id="pda-reporting" class="level2" data-number="9.3"><h2 data-number="9.3" class="anchored" data-anchor-id="pda-reporting">
<span class="header-section-number">9.3</span> Reporting</h2>
<p>When reporting the results of a supervised machine learning model it is important to report the evaluation metrics that are most relevant to the problem at hand. For example, if the problem is to predict a continuous outcome, then the most relevant evaluation metric is the mean squared error (MSE). It is often useful to report the root mean squared error (RMSE) as well.</p>
<p>However, if the problem is to predict the class, then the most relevant evaluation metric is the accuracy. Other evaluation metrics that are often reported are the precision, recall, and F1-score. It can also be useful to report the confusion matrix. The confusion matrix shows the number of true positives, false positives, true negatives, and false negatives.</p>
<p>If the research goal is focused on prediction accuracy, then these statistics are the most relevant. But in other cases, the supervised learning alogrithm is a means to guage a relationship between the outcome and the predictor variables, namely to guage the most important predictor variables. The model can then be used to identify those predictor variables that support accurate predictions and even to identify those predictor variables that do not support accurate predictions. Note, however, that some supervised learning algorithms are not able to identify the most important predictor variables. For example, neural networks are not able to identify the most important predictor variables. These ‘black box’ algorithms may lead to accurate predictions, but they do not provide any insight into the underlying relationship between the outcome and the predictor variables.</p>
</section><section id="pda-summary" class="level2" data-number="9.4"><h2 data-number="9.4" class="anchored" data-anchor-id="pda-summary">
<span class="header-section-number">9.4</span> Summary</h2>
<p>In this chapter we have learned about supervised machine learning. We have learned about the different types of supervised machine learning methods and how they can be used to predict and classify. We have also learned about the different types of data structures that are used in supervised machine learning. Finally, we have learned about the different types of evaluation metrics that are used to evaluate the performance of supervised machine learning models.</p>
</section><section id="activities" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="activities">Activities</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Recipe
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>What</strong>: <a href="https://lin380.github.io/tadr/articles/recipe_10.html">Predictive models: prep, train, test, and evaluate</a><br><strong>How</strong>: Read Recipe 10 and participate in the Hypothes.is online social annotation.<br><strong>Why</strong>: To illustrate some common coding strategies for preparing datasets for inferential data analysis, as well as the steps conduct descriptive assessment, statistical interrogation, and evaluation and reporting of results.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Lab
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>What</strong>: <a href="https://github.com/lin380/lab_10">Predictive Data Analysis</a><br><strong>How</strong>: Clone, fork, and complete the steps in Lab 10.<br><strong>Why</strong>: To gain experience working with coding strategies to prepare, feature engineer, train and test a predictive model, and evaluate results from a predictive data analysis, practice transforming datasets into new object formats and visualizing relationships, and implement organizational strategies for organizing and reporting results in a reproducible fashion.</p>
</div>
</div>
</section><section id="questions" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="questions">Questions</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Conceptual questions
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>What is the difference between a continuous and a categorical variable?</li>
<li>What is the difference between a regression and a classification model?</li>
<li>What is the difference between a training set and a testing set?</li>
<li>What is the difference between a hyperparameter and a parameter?</li>
<li>What is the difference between a supervised and an unsupervised machine learning model?</li>
<li>What advantages and disadvantages do supervised machine learning models have over traditional methods of text analysis?</li>
<li>What are some potential applications of supervised machine learning in linguistics?</li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Technical exercises
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>Write a program to build a classification model which uses a set of collected text features to predict a target variable.</li>
<li>Use the classification model to classify a series of documents and assess the accuracy of the model.</li>
<li>Develop a regression model which uses text features to predict a continuous target variable.</li>
<li>Create a text mining application to analyze a large body of text and discover correlations between variables.</li>
<li>Use a clustering algorithm to discover clusters in a large dataset, and create a visualization to present the identified clusters.</li>
<li>Analyze the structure of a text corpus and identify patterns in word usage and feature distributions.</li>
<li>Build a predictive model using text as an input and binary or categorical outcomes as the target.</li>
<li>Develop a natural language processing application which classifies text into predefined categories using a supervised learning algorithm.</li>
<li>Use a supervised learning algorithm to build a predictive model which classifies a set of unseen texts into predefined categories.</li>
<li>Develop a web application which allows users to easily explore a set of text documents, visualize the content of the documents, and generate predictive models from the text.</li>
</ol>
</div>
</div>

<!---

- Overview:
    - Research goals (predict, prescribe, verify)
    - Use of data
        - Partitioned: training (reusable) and test (reserved) sets
        - Outcome variable and predictor/ covariate variables
        - Fixed outcome and mutable predictor variables/ features
    - Methods
        - Supervised machine learning methods
            - Regression
            - Classification
    - Data types/ structures
        - Matrices
    - Interpreting results (quantitative)
        - Summary statistics: 
            - Accuracy
            - Precision
            - Recall
            - F1
            - Confusion matrix
- Supervised machine learning analysis
    - Methods: 
        - Regression (continuous outcome variable)
            - Linear regression
            - Decision trees
            - Neural networks
        - Classification (categorical outcome variable)
            - Logistic regression
            - Decision trees
            - Neural networks





Supervised machine learning is a type of artificial intelligence that involves training a model on a labeled dataset where the input data and desired output are both provided. The model is able to make predictions or classifications based on the input data by learning the relationships between the input and output data. Supervised machine learning is an important tool for linguists studying language and communication, as it allows them to analyze language data and identify patterns or trends in language use. There are two main types of supervised machine learning algorithms: classification, which is used to predict a categorical outcome such as the genre of a text, and regression, which is used to predict a continuous outcome such as the sentiment of a text. In order to use supervised machine learning, linguists must first prepare the data by cleaning and preprocessing it, and then split the data into training and testing sets. The model is then trained on the training data and evaluated on the testing data, and the hyperparameters of the model may be adjusted to optimize its performance. Some applications of supervised machine learning in linguistics include text classification, part-of-speech tagging, and language identification. Supervised machine learning is an active area of research in linguistics, with many potential applications and areas for further exploration.


I. Introduction to supervised machine learning
A. Definition of supervised machine learning
i. Supervised machine learning involves training a model on a labeled dataset where the input data and desired output are both provided
ii. The model is able to make predictions or classifications based on the input data by learning the relationships between the input and output data
B. Importance of supervised machine learning for linguistics
i. Supervised machine learning can be used to analyze language data and identify patterns or trends in language use
ii. Supervised machine learning can help linguists classify texts, predict language evolution, and identify language-specific features

II. Types of supervised machine learning algorithms
A. Classification
i. Classification algorithms are used to predict a categorical outcome, such as whether a text belongs to a particular genre
ii. Examples of classification algorithms include decision trees, logistic regression, and support vector machines
B. Regression
i. Regression algorithms are used to predict a continuous outcome, such as the sentiment of a text
ii. Examples of regression algorithms include linear regression and multiple linear regression

III. Preparing data for supervised machine learning
A. Data preprocessing
i. Data preprocessing involves cleaning and preparing the data for analysis
ii. This may include tasks such as removing missing values, scaling the data, and encoding categorical variables
B. Data splitting
i. Data splitting involves dividing the data into training and testing sets
ii. The training set is used to train the model, while the testing set is used to evaluate the model's performance

IV. Training and evaluating a supervised machine learning model
A. Training a model
i. Training a model involves providing the model with the training data and adjusting the model's parameters to minimize the error between the model's predictions and the true output
B. Evaluating a model
i. Evaluating a model involves using the testing data to measure the model's performance
ii. Common evaluation metrics for supervised machine learning include accuracy, precision, and recall
C. Tuning model hyperparameters
i. Hyperparameters are the parameters of the machine learning model that are set before training begins
ii. Tuning hyperparameters involves adjusting the values of the hyperparameters to optimize the model's performance

V. Applications of supervised machine learning in linguistics
A. Text classification
i. Text classification involves categorizing texts into predefined categories, such as genre or topic
ii. Supervised machine learning can be used to classify texts based on their content or linguistic features
B. Part-of-speech tagging
i. Part-of-speech tagging involves assigning a part of speech to each word in a text
ii. Supervised machine learning can be used to identify the part of speech of a word based on its context and other linguistic features
C. Language identification
i. Language identification involves determining the language of a text
ii. Supervised machine learning can be used to identify the language of a text based on its content or linguistic features

VI. Conclusion
A. Recap of key points
i. Supervised machine learning is a type of machine learning that involves training a model on a labeled dataset
ii. Supervised machine learning can be used to classify texts, predict language evolution, and identify language-specific features
B. Future directions for supervised machine learning in linguistics
i. Supervised machine learning is an active area of research in linguistics, with many potential applications and areas for further exploration
ii. Future research may focus on developing more sophisticated



Research

Strengths:
1. Neural networks are able to capture complex relationships between words and phrases in text.
2. Neural networks can learn from large amounts of data and can be trained to classify text with high accuracy.
3. Neural networks can be used to classify text into multiple categories.
4. Neural networks can be used to identify patterns in text that are not easily detected by traditional methods.

Weaknesses:
1. Neural networks require a large amount of data to train and can be computationally expensive.
2. Neural networks can be prone to overfitting if the data is not properly preprocessed.
3. Neural networks can be difficult to interpret and explain due to their complexity.
4. Neural networks can be sensitive to noise and outliers in the data.


Building and evaluating a predictive model for text classification requires multiple steps. Here are the key ones:

1. Data collection - Collect a set of labeled documents to be used in the model.

2. Data preprocessing - Clean the data and prepare it for the model by tokenizing, stemming, and removing stop words.

3. Feature extraction - Extract features from the data using methods such as bag of words, TF-IDF, word embeddings, and feature selection.

4. Model training - Train the model on the extracted features using methods such as Logistic Regression, Support Vector Machines, Naive Bayes, and Neural Networks.

5. Model evaluation - Evaluate the model using metrics such as accuracy, precision, recall, and F1-score.

6. Model tuning - Optimize the model by adjusting its parameters to obtain better results.


-->


</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./exploration.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Exploration</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./inference.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Inference</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>
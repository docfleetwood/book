---
execute: 
  echo: true
---

# Exploration {#sec-exploration}

```{r}
#| label: setup-options
#| child: "_common.qmd"
#| cache: false
```

::: {.callout-caution title="Caution"}
Under development.
:::

<!--

Content:

Exercises:

- [ ] add concept questions to Activities
- [ ] add exercises to Activities
- [ ] add thought questions/ case studies to prose sections

Formatting:

-->

> The real voyage of discovery consists not in seeking new landscapes, but in having new eyes.
> 
> --- Marcel Proust


> The data speaks for itself, but only if we are willing to listen. 
> 
> --- Nate Silver

::: {.callout}
**{{< fa regular list-alt >}} Outcomes**

<!-- Remember and understand verbs: https://tips.uark.edu/blooms-taxonomy-verb-chart/ -->

- Identify when an exploratory data analysis approach is the best fit for a given research project.
- Describe the fundamental methods of descriptive analysis and unsupervised learning, recognizing their utility in revealing patterns and summarizing data.
- Interpret the basic insights gained from data summarization and pattern recognition, considering how these insights could guide further questions or research.
:::

```{r}
#| label: exploration-data-packages
#| echo: false
#| message: false

```

In this chapter we examine a wide range of strategies for deriving insight from data in cases where the researcher does not start with a preconceived hypothesis or prediction, but rather the researcher aims to uncover patterns and associations from data allowing the data to guide the trajectory of the analysis. The chapter outlines two main branches of exploratory data analysis: 1) descriptive analysis which statistically and/ or visually summarizes a dataset and 2) unsupervised learning which is a machine learning approach that does not assume any particular relationship between variables in a dataset. Either through unsupervised learning or descriptive methods, exploratory data analysis employs quantitative methods to summarize, reduce, and sort complex datasets and statistically and visually interrogate a dataset in order to provide the researcher novel perspective to be qualitatively assessed.

<!-- This chapter provides an introduction to exploratory data analysis (EDA) for linguists, with a focus on descriptive methods such as frequency analysis and co-occurence analysis, as well as unsupervised learning approaches such as clustering, topic modelling, and word embedding. It will also discuss the use cases of these methods in linguistics. 

The chapter is organized as follows: ...

We wil work with the State of the Union (SOTU) corpus, which contains the full text of all State of the Union addresses from 1790 to 2019. The corpus is available in the `quanteda.corpora` package, and can be loaded as follows: -->

```{r}
#| eval: false
#| label: load-sotu
#| echo: false

sotu_corpus <-
  quanteda.corpora::data_corpus_sotu # load corpus
``` 


::: {.callout}
**{{< fa terminal >}} Lessons**

<!-- Remember and understand verbs: https://tips.uark.edu/blooms-taxonomy-verb-chart/ -->

<!-- [ ] lesson: update the why -->

**What**: [Matrices](https://github.com/qtalr/lessons)\
**How**: In the R Console pane load `swirl`, run `swirl()`, and follow prompts to select the lesson.\
**Why**: Learn how to work with matrices to store and analyze numeric data.
:::

## Orientation {#sec-eda-orientation}

<!-- ADD

- Research goals
  - Approaches
		- Analysis types
- Workflow: Identify, Inspect, Interrogate, Interpret
  - Add a few words on the common aspects with other research approaches
  - And point out the differences (use of data, results, interpretation, etc.)

-->


The aim of this section is to provide an overview of exploratory data analysis (EDA). We will delve into various descriptive methods, such as frequency analysis and co-occurrence analysis, which are fundamental tools in linguistic research. However, our exploration won't stop there. We will also integrate modern exploratory methods from unsupervised learning approaches, including clustering, topic modeling, and vector space modeling. This may sound overwhelming, but I will strive to keep explanations clear and concise, ensuring their practicality and relevance to your linguistic inquiries is apparent. To this end, we will provide real-world examples to exemplify the applicability of these methodologies. 

### Research goals {#sec-eda-research-goals}

The goal of exploratory data analysis is to discover, describe, and posit new hypotheses. The researcher does not start with a preconceived hypothesis or prediction, but rather the researcher aims to uncover patterns and associations from data allowing the data to guide the trajectory of the analysis. This analysis approach is best-suited for research where the literature on a research question is limited, or where the researcher is interested in exploring a new research question. Since the researcher does not start with a preconceived hypothesis, the researcher is not able to test a hypothesis and generalize to a population, but rather the researcher is able to describe the data and provide a new perspective to be qualitatively assessed. This is achieved through an iterative and inductive process of data exploration, where the researcher uses quantitative methods to summarize, reduce, and sort complex datasets and statistically and visually interrogate a dataset letting the data guide the analysis. 

### Approaches {#sec-eda-approaches}

- Can be understood as quantitative supported qualitative research as the results of exploratory analysis are interpreted qualitatively, by and large. The results, however, can be used to inform the development of a hypothesis or to inform the design of a machine learning model. It allows for leaving pre-conceived notions behind and letting the data speak for itself, under researcher-guided intuition and knowledge.
- There is no fixed outcome variable rather there is only a set of predictors or covariates. 
- The data is mutable, meaning that the data can be changed or modified as needed to address the research question.

#### Analysis types {#sec-eda-analysis-types}

There are two main types of exploratory analysis: 1) descriptive analysis which statistically and/ or visually summarizes a dataset and 2) unsupervised learning which is a machine learning approach that does not assume any particular relationship between variables in a dataset. Either or both of these approaches can be used to explore a dataset.

### Workflow {#sec-eda-workflow}

Prerequisites: 
- A working research question
- A dataset which aligns with the research question or hypothesis in terms of its sampling frame and the variables it contains or can be derived from the text
- A set of preliminary interests and/ or linguistic variables to explore in the dataset that align with the research question

Process: 
- Identify and extract the variables of interest in the dataset
- Interrogate the dataset using descriptive analysis and/ or unsupervised learning
- 

<!--- Move the sections above (Approaching analysis)/ Keep the sections below -->

#### Identify {#sec-eda-identify}

- With the research question in mind, identify the variables of interest in the dataset
- Identify the linguistic variables that can be derived from the text (i.e. liguistic units: words, n-grams, sentences, etc.)
- Consider the operational measures of the variables derived from the text (i.e. frequency, dispersion, co-occurrence, etc.)
- Consider the other variables in the dataset that may be target for grouping or filtering the dataset (i.e. speaker information, document information, linguistic unit information, etc.)

#### Inspect {#sec-eda-inspect}

Inspect your data to ensure the quality of your data and understand its characteristics. 

#### Interrogate {#sec-eda-interrogate}

Descriptive analysis:

- Frequency analysis
- Co-occurrence analysis

Unsupervised learning:

- Clustering
- Topic modeling
- Word embedding

#### Interpret {#sec-eda-interpret}

Exploratory methods will produce a set of statistical and/ or visual results. The researcher must interpret these results to determine if they are meaningful and if they provide a new perspective on the research question. Many times the results from one method will lead to new questions which can be explored with other methods. In some cases, the results may not be meaningful and the researcher may need to return to the data preparation stage to modify the dataset or the variables of interest. As the aim of exploratory analysis is just that, to explore, the researcher can pivot the approach to explore new questions and new variables. Ultimately, what is meaningful is determined by the researcher in the light of the research question and the potential insight obtained from the results.

## Analysis {#sec-eda-analysis}

<!-- Short intro to the purpose of this section

This section will discuss exploratory data analysis (EDA) for linguists, with a focus on descriptive methods such as frequency analysis and co-occurence analysis, as well as unsupervised learning approaches such as clustering, topic modelling, and word embedding. It will also discuss the use cases of these methods in linguistics.

-->

### Descriptive analysis {#sec-eda-descriptive} 


<!--

Point out the focus in this section will be onn descriptive analysis. Descriptive analysis is an approach where the researcher does not start with a preconceived hypothesis or prediction, but rather the researcher aims to uncover patterns and associations from data allowing the data to guide the trajectory of the analysis. 

-->

#### Frequency analysis {#sec-eda-frequency}

<!-- (L2 acquisition, Language and culture studies) -->

Frequency analysis is a descriptive method that counts the number of times a linguistic unit (i.e. word, n-gram, sentence, etc.) occurs in a dataset. The results of frequency analysis can be used to describe the dataset and to identify linguistic units that are distinctive to a particular group or sub-group in the dataset.

- Raw frequency (counting)
    - Linguistic units (characters, words, n-grams, sentences, etc.)
    - Raw frequency (absolute frequency)
    - Zipf's law (rank-frequency)
    - Issues with raw frequency ($f$): 
        - Incomparable across sub-corpora, corpora, and time
- Term frequency (normalization)
    - Relative frequency (proportional frequency)
    - Makes samples (more) comparable (divergence of corpus sizes can influences validity of comparison)
    - Issues with term frequency ($tf$): 
        - Does not reveal the distribution of terms across a text or set of texts
        - Does not highlight distinctive words
            - One way to address this is to filter out 'stop words' (i.e. the, a, an, etc.)
- Adjusted frequency (relevance)
    - Dispersion (distribution)
        - $idf$ (inverse document frequency)
        - ... Juilland's $D$ (equal/ non-equal parts)
        - Gries' $DP$ Deviation of Proportions (DP)
    - Weights
        - $tf-idf$ (term frequency-inverse document frequency)
            - Distinctive words (Used to identify the most relevant keywords in a given text.)
            - Issues with $tf-idf$: Does not reveal the context of terms, Does not reveal the relationship between terms
        - weighted log odds ([`tidylo` package](https://juliasilge.r-universe.dev/articles/tidylo/tidylo.html))
            - Distinctive words (Used to identify the most relevant keywords in a given text.)
            - Advantage over $tf-idf$: does a better job dealing with different combinations of words and documents having different counts.

#### Co-occurrence analysis {#sec-eda-co-occurrence}

<!-- (grammaticalization, syntactic alternations, discourse analysis, etc.) -->

- Concordance
    - KWIC (keyword in context)
    This section will discuss keyword in context (KWIC) analyses, which is used to identify meaningful keywords in a given text. It will discuss various ways to analyse a text and extract keywords, as well as discuss various practical applications of KWIC in linguistics.
- Collocation
    - PMI (pointwise mutual information)
    - Dice's coefficient
    - ...

### Unsupervised learning {#sec-eda-unsupervised}

#### Clustering {#sec-eda-clustering}

This section will discuss clustering techniques, which are used to partition data into clusters based on similarity. It will discuss various approaches to clustering, such as k-means and hierarchical clustering, as well as discuss their use cases in linguistics.

- K-means (pre-defined number of clusters)
- Hierarchical clustering (dendrogram)

#### Dimensionality reduction {#sec-eda-dimensionality-reduction}

- PCA (principal component analysis)
- MDS (multidimensional scaling)

#### Topic modeling {#sec-eda-topic-modeling}

This section will discuss topic modeling techniques, which are used to identify and group semantically similar topics in unstructured data. It will discuss various approaches to topic modelling, such as Latent Dirichlet Allocation (LDA), and discuss their applications in linguistics.

- LDA (latent Dirichlet allocation)
- LSA (latent semantic analysis)

#### Word embedding {#sec-eda-word-embedding}

This section will discuss word embedding techniques, which are used to represent words in a vector space. It will discuss various approaches to word embedding, such as Word2Vec and GloVe, and discuss their applications in linguistics.

- Word2vec (skip-gram)
- GloVe (global vectors for word representation)

## Summary 

Exploratory data analysis is a set of methods that can be used to explore a dataset and to identify new questions and new variables of interest. The methods can be used to describe a dataset and to identify linguistic units that are distinctive to a particular group or sub-group in the dataset. The methods can also be used to identify semantically similar topics in unstructured data. The results of exploratory analysis can be used to inform the development of a hypothesis or to inform the design of a machine learning model. 

## Activities {.unnumbered}

<!-- [ ] Add description of the activites -->


::: {.callout}
**{{< fa regular file-code >}} Recipe**

**What**: [Exploratory methods: descriptive and unsupervised learning analysis methods](https://lin380.github.io/tadr/articles/recipe_11.html)\
**How**: Read Recipe 10 and participate in the Hypothes.is online social annotation.\
**Why**: To illustrate how to prepare a dataset for descriptive and unsupervised machine learning methods and evaluate the results for exploratory data analysis.
:::

::: {.callout}
**{{< fa flask >}} Lab**

<!-- Analyze, evaluate, and create verbs: https://tips.uark.edu/blooms-taxonomy-verb-chart/ -->

<!-- [ ] update lab -->

**What**: [Exploratory Data Analysis](https://github.com/lin380/lab_11)\
**How**: Clone, fork, and complete the steps in Lab 9.\
**Why**: To gain experience working with coding strategies to prepare, feature engineer, explore, and evaluate results from exploratory data analyses, practice transforming datasets into new object formats and visualizing relationships, and implement organizational strategies for organizing and reporting results in a reproducible fashion.
:::

## Questions {.unnumbered}

::: {.callout}
{{< fa wrench >}} **Conceptual questions**

1. What is exploratory data analysis?
2. How can exploratory data analysis be used to uncover patterns and associations?
3. Describe the workflow of exploratory data analysis?
4. What are the advantages and disadvantages of descriptive analysis?
5. What are the advantages and disadvantages of unsupervised learning?
6. What is the difference between supervised and unsupervised learning?
7. How does exploratory data analysis differ from traditional hypothesis testing?

:::

::: {.callout}
{{< fa wrench >}} **Technical questions**

1. Write a function in R to conduct a hierarchical cluster analysis on a dataset.
2. Implement a k-means algorithm in R to identify clusters within a dataset.
3. Implement a Principal Component Analysis (PCA) algorithm in R to identify patterns and associations within a dataset.
4. Write a function in R to produce a descriptive summary of a dataset.
5. Conduct a correlation analysis in R to identify relationships between variables in a dataset.
6. Load a dataset into R and conduct a frequency analysis on the dataset.
7. Load a dataset into R and conduct a keyword in context analysis on the dataset.
8. Load a dataset into R and conduct a keyword analysis on the dataset.
9. Load a dataset into R and conduct a sentiment analysis on the dataset.
10. Load a dataset into R and conduct a topic modelling analysis on the dataset.
:::
